-- MySQL dump 10.13  Distrib 5.6.24, for osx10.8 (x86_64)
--
-- Host: 52.68.174.105    Database: jips_k_org
-- ------------------------------------------------------
-- Server version	5.5.45

/*!40101 SET @OLD_CHARACTER_SET_CLIENT=@@CHARACTER_SET_CLIENT */;
/*!40101 SET @OLD_CHARACTER_SET_RESULTS=@@CHARACTER_SET_RESULTS */;
/*!40101 SET @OLD_COLLATION_CONNECTION=@@COLLATION_CONNECTION */;
/*!40101 SET NAMES utf8 */;
/*!40103 SET @OLD_TIME_ZONE=@@TIME_ZONE */;
/*!40103 SET TIME_ZONE='+00:00' */;
/*!40014 SET @OLD_UNIQUE_CHECKS=@@UNIQUE_CHECKS, UNIQUE_CHECKS=0 */;
/*!40014 SET @OLD_FOREIGN_KEY_CHECKS=@@FOREIGN_KEY_CHECKS, FOREIGN_KEY_CHECKS=0 */;
/*!40101 SET @OLD_SQL_MODE=@@SQL_MODE, SQL_MODE='NO_AUTO_VALUE_ON_ZERO' */;
/*!40111 SET @OLD_SQL_NOTES=@@SQL_NOTES, SQL_NOTES=0 */;

--
-- Table structure for table `jipsdb`
--

DROP TABLE IF EXISTS `jipsdb`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `jipsdb` (
  `num` int(10) unsigned NOT NULL,
  `year` int(10) unsigned NOT NULL,
  `volume` int(10) unsigned NOT NULL,
  `number` int(10) unsigned NOT NULL,
  `page` int(10) unsigned NOT NULL,
  `endpage` int(11) unsigned NOT NULL DEFAULT '0',
  `title` varchar(450) NOT NULL,
  `keyword` varchar(450) NOT NULL,
  `authors` varchar(450) NOT NULL,
  `filesrc` varchar(450) NOT NULL,
  `abstract` varchar(5000) NOT NULL,
  `doi` varchar(450) DEFAULT NULL,
  `hit` int(10) unsigned NOT NULL,
  `downhit` int(10) unsigned NOT NULL,
  `fp` int(11) DEFAULT NULL,
  `of` int(4) DEFAULT '0',
  `uploaddate` date DEFAULT NULL,
  `epub` varchar(450) DEFAULT NULL,
  PRIMARY KEY (`num`)
) ENGINE=InnoDB DEFAULT CHARSET=latin1;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `jipsdb`
--

LOCK TABLES `jipsdb` WRITE;
/*!40000 ALTER TABLE `jipsdb` DISABLE KEYS */;
INSERT INTO `jipsdb` VALUES (1,2005,1,1,1,0,'A Study on the Design of the Monitoring Architecture for Embedded Kernels based on LTT','Monitoring tool, NFS, LTT, MONETA 2.0','Ji-Hye Bae, Yoon-Young Park, and Jung-Ho Park','dlibrary/JIPS_v01_no1_paper1.pdf','Embedded systems are used in many fields such as home appliances, terminals, controls, communications, etc. So, to manage, control, and test these embedded systems, monitoring programs have been developed variously. In this paper, to overcome the characteristic faults of embedded systems which have resource restrictions, we implemented a development environment based on NFS and designed a monitoring tool that can evaluate and analyze kernel performance in embedded equipment by using LTT(Linux Trace Toolkit). Also, we designed a method to show monitoring data collected by using a monitoring tool, called MONETA 2.0, through the web-page.','',869,422,0,0,NULL,NULL),(2,2005,1,1,9,0,'Robust Real-time Intrusion Detection System','real-time IDS, kernel PCA. LS-SVM','Byung-Joo Kim, and Il-Kon Kim','dlibrary/JIPS_v01_no1_paper2.pdf','Computer security has become a critical issue with the rapid development of business and other ftansaction systems over the Intemet. The application of atlificial intelligence, machine learning and data mining techdques to intrusion detection systems has been increasing recently. But most research is focused on improving the classification performaace of a classifier. Selecting important features from input data leads to simplification olthe problem, and faster and more accuate detection rates. Thus selecting important features is ar impofiant issue in intrusion detection. Alother issue in intrusion detection is that inost of the intrusion detection systems are performed by offJine and it is not a suitable method for a real-time intrusion detection system. In this paper, we develop the real-time intrusion detection system, which combines an online feature extraction method with the Least Squares Suppofi Vector Machine classifier. Applying the proposed system to KDD CUP 99 data, experimental results show that it has a remarkable feature extraction and classification performance compared to existing off-line intntsion detection systems.','',831,399,0,0,NULL,NULL),(3,2005,1,1,14,0,'A Multiple Instance Learning Problem Approach Model to Anomaly Network Intrusion Detection','Multiple Instance Learning Problem, Network Intrusion Detection, Anomaly Detection','Ill-Young Weon, Doo-Heon Song, Sung-Bum Ko, and Chang-Hoon Lee','dlibrary/JIPS_v01_no1_paper3.pdf','Even though mainly statistical methods have been used in anomaly network intrusion detection, to detect various attack types, machine learning based anomaly detection was introduced. Machine learning based anomaly detection started from research applying traditional learning algorithms of artificial intelligence to intrusion detection. However, detection rates of these methods are not satisfactory. Especially, high false positive and repeated alarms about the same attack are problems. The main reason for this is that one packet is used as a basic learning unit. Most attacks consist of more than one packet. In addition, an attack does not lead to a consecutive packet stream. Therefore, with grouping of related packets, a new approach of group-based learning and detection is needed. This type of approach is similar to that of multiple-instance problems in the artificial intelligence community, which cannot clearly classify one instance, but classification of a group is possible. We suggest group generation algorithm grouping related packets, and a learning algorithm based on a unit of such group. To verify the usefulness of the suggested algorithm, 1998 DARPA data was used and the results show that our approach is quite useful.','',815,362,0,0,NULL,NULL),(4,2005,1,1,22,0,'A Hierarchical Text Rating System for Objectionable Documents','Objectionable documents, document analysis, text classification, hierarchical system, SVM','Chi Yoon Jeong, Seung Wan Han, and Taek Yong Nam','dlibrary/JIPS_v01_no1_paper4.pdf','In this paper, we classified the objectionable texts into four rates according to their harmfulness and proposed the hierarchical text rating system for objectionable documents. Since the documents in the same category have similarities in used words, expressions and structure of the document, the text rating system, which uses a single classification model, has low accuracy. To solve this problem, we separate objectionable documents into several subsets by using their properties, and then classify the subsets hierarchically. The proposed system consists of three layers. In each layer, we select features using the chi-square statistics, and then the weight of the features, which is calculated by using the TF-IDF weighting scheme, is used as an input of the non-linear SVM classifier. By means of a hierarchical scheme using the different features and the different number of features in each layer, we can characterize the objectionability of documents more effectively and expect to improve the performance of the rating system. We compared the performance of the proposed system and performance of several text rating systems and experimental results show that the proposed system can archive an excellent classification performance.','',768,368,0,0,NULL,NULL),(5,2005,1,1,27,0,'A Hardware/Software Codesign for Image Processing in a Processor Based Embedded System for Vehicle Detection','Embedded System, ITS, Image Processing, Vehicle Detect','Hosun Moon, Sunghwan Moon, Youngbin Seo, and Yongdeak Kim','dlibrary/JIPS_v01_no1_paper5.pdf','Vehicle detector system based on image processing technology is a significant domain of ITS (Intelligent Transportation System) applications due to its advantages such as low installation cost and it does not obstruct traffic during the installation of vehicle detection systems on the road[1]. In this paper, we propose architecture for vehicle detection by using image processing. The architecture consists of two main parts such as an image processing part, using high speed FPGA, decision and calculation part using CPU. The CPU part takes care of total system control and synthetic decision of vehicle detection. The FPGA part assumes charge of input and output image using video encoder and decoder, image classification and image memory control.','',932,359,0,0,NULL,NULL),(6,2005,1,1,32,0,'Wavelet-based Image Denoising with Optimal Filter','Image Denoising, Noise Reduction Wavelet','Yong-Hwan Lee, and Sang-Burm Rhee','dlibrary/JIPS_v01_no1_paper6.pdf','Image denoising is basic work for image processing, analysis and computer vision. This paper proposes a novel algorithm based on wavelet threshold for image denoising, which is combined with the linear CLS (Constrained Least Squares) filtering and thresholding methods in the transform domain. We demonstrated through simulations with images contaminated by white Gaussian noise that our scheme exhibits better performance in both PSNR (Peak Signal-to-Noise Ratio) and visual effect.','',721,378,0,0,NULL,NULL),(7,2005,1,1,36,0,'Simulation of the Digital Image Processing Algorithm for the Coating Thickness Automatic Measurement of the TRISO-coated Fuel Particle','TRISO-coated Fuel Particle, Coating Thickness, X-ray CT, Computed Tomography, Filtered Backprojection, Automatic Measurement','Woong-Ki Kim, Young-Woo Lee, and Sung-Woong Ra','dlibrary/JIPS_v01_no1_paper7.pdf','TRISO (Tri-Isotropic)-coated fuel particle is widely applied due to its higher stability at high temperature and its efficient retention capability for fission products in the HTGR (high temperature gas-cooled reactor), one of the highly efficient Generation IV reactors. The typical balltype TRISO-coated fuel particle with a diameter of about 1 mm is composed of a nuclear fuel particle as a kernel and of outer coating layers. The coating layers consist of a buffer PyC, inner PyC, SiC, and outer PyC layer. In this study, a digital image processing algorithm is proposed to automatically measure the thickness of the coating layers. An FBP (filtered backprojection) algorithm was applied to reconstruct the CT image using virtual X-ray radiographic images for a simulated TRISO-coated fuel particle. The automatic measurement algorithm was developed to measure the coating thickness for the reconstructed image with noises. The boundary lines were automatically detected, then the coating thickness was circularly by the algorithm. The simulation result showed that the measurement error rate was less than 1.4%.','',903,390,0,0,NULL,NULL),(8,2005,1,1,41,0,'PC-KIMMO-based Description of Mongolian Morphology','natural language processing, two-level morphological rule, Mongolian morphology, finite-state transducers, computational linguistics','Purev Jaimai, Tsolmon Zundui, Altangerel Chagnaa, and Cheol-Young Ock','dlibrary/JIPS_v01_no1_paper8.pdf','This paper presents the development of a morphological processor for the Mongolian language, based on the two-level morphological model which was introduced by Koskenniemi. The aim of the study is to provide Mongolian syntactic parsers with more effective information on word structure of Mongolian words. First hand written rules that are the core of this model are compiled into finite-state transducers by a rule tool. Output of the compiler was edited to clarity by hand whenever necessary. The rules file and lexicon presented in the paper describe the morphology of Mongolian nouns, adjectives and verbs. Although the rules illustrated are not sufficient for accounting all the processes of Mongolian lexical phonology, other necessary rules can be easily added when new words are supplemented to the lexicon file. The theoretical consideration of the paper is concluded in representation of the morphological phenomena of Mongolian by the general, language-independent framework of the two-level morphological model.','',823,362,0,0,NULL,NULL),(9,2005,1,1,49,0,'A Cluster-Based Energy-Efficient Routing Protocol without Location Information for Sensor Networks','Wireless sensor networks, ubiquitous sensor networks, cluster-based routing protocol, energy-efficient routing','Giljae Lee, Jonguk Kong, Minsun Lee, and Okhwan Byeon','dlibrary/JIPS_v01_no1_paper9.pdf','With the recent advances in Micro Electro Mechanical System (MEMS) technology, low cost and low power consumption wireless micro sensor nodes have become available. However, energy-efficient routing is one of the most important key technologies in wireless sensor networks as sensor nodes are highly energy-constrained. Therefore, many researchers have proposed routing protocols for sensor networks, especially cluster-based routing protocols, which have many advantages such as reduced control messages, bandwidth re-usability, and improved power control. Some protocols use information on the locations of sensor nodes to construct clusters efficiently. However, it is rare that all sensor nodes know their positions. In this article, we propose another cluster-based routing protocol for sensor networks. This protocol does not use information concerning the locations of sensor nodes, but uses the remaining energy of sensor networks and the desirable number of cluster heads according to the circumstances of the sensor networks. From performance simulation, we found that the proposed protocol shows better performance than the low-energy adaptive clustering hierarchy (LEACH).','',834,363,0,0,NULL,NULL),(10,2005,1,1,55,0,'Performance Analysis of the Distributed Location Management Scheme in Large Mobile Networks','Distributed Location Management, LMN, Performance Analysis, IMT-2000','Dong Chun Lee, Hong-Jin Kim, Jong Chan Lee, and Yi Bing Lin','dlibrary/JIPS_v01_no1_paper10.pdf','In this paper we propose a distributed location management scheme to reduce the bottleneck problem of HLR in Large Mobile Networks (LMN). Using analytical modeling and numerical simulation, we show that replicating location information is both appropriate and efficient for small mobile networks. Then, we extend the scheme in a hierarchical environment to reduce the overhead traffic and scale to LMN. In numerical results, we show the superiority of our scheme compared to the current IS-95 standard scheme in IMT-2000 networks.','',747,346,0,0,NULL,NULL),(11,2005,1,1,62,0,'A Performance Analysis Model of PC-based Software Router Supporting IPv6-IPv4 Translation for Residential Gateway','Performance analysis model, Software PC router, IPv6-IPv4 translator, M/G/1/K, MMPP-2/G/1/K, residential gateway','Ssang-Hee Seo, and In-Yeup Kong','dlibrary/JIPS_v01_no1_paper11.pdf','This paper presents a queuing analysis model of a PC-based software router supporting IPv6-IPv4 translation for residential gateway. The proposed models are M/G/1/K or MMPP-2/G/1/K by arrival process of the software PC router. M/G/1/K is a model of normal traffic and MMPP-2/G/1/K is a model of burst traffic. In M/G/1/K, the arriving process is assumed to be a Poisson process, which is independent and identically distributed. In MMPP-2/G/1/K, the arriving process is assumed to be two-state Markov Modulated Poisson Process (MMPP) which is changed from one state to another state with intensity. The service time distribution is general distribution and the service discipline of the server is processor sharing. Also, the total number of packets that can be processed at one time is limited to K. We obtain performance metrics of PC-based software router for residential gateway such as system sojourn time, blocking probability and throughput based on the proposed model. Compared to other models, our model is simpler and it is easier to estimate model parameters. Validation results show that the model estimates the performance of the target system.','',789,377,0,0,NULL,NULL),(12,2005,1,1,70,0,'The Comparison of RBS and TDP for the Sensor Networks Synchronization','Sensor Network, RBS, TDP, Time Synchronization','Hyojung Lee, Byungchul Kim, and Youngmi Kwon','dlibrary/JIPS_v01_no1_paper12.pdf','Sensor networks have emerged as an interesting and important research area in the last few years. These networks require that time be synchronized more precisely than in traditional Internet applications. In this paper, we compared and analyzed the performance of the RBS and TDP mechanisms in the view of the number of generated messages and the synchronization accuracy. The reason that we chose the RBS ad the TDP mechanism to be compared is because the RBS is an innovative method to achieve the high accurate synchronization. And TDP is a new method taking over the NTP method which has been used widely in the Internet. We simulated the performance of two methods assuming the IEEE 802.11 CSMA/CA MAC. As for the number of nodes in the sensor networks, two situations of 25 (for the small size network) and 100 (for the large size network) nodes are used. In the aspect of the number of messages generated for the synchronization, TDP is far better than RBS. But, the synchronization accuracy of RBS is far higher than that of TDP. We can conclude that in a small size sensor networks requiring very high accuracy, such as an application of very high speed objects tracking in a confined space, the RBS is more proper than TDP even though the RBS may generate more traffic than TDP. But, in a wide range sensor networks with a large number of nodes, TDP is more realistic though the accuracy is somewhat worse than RBS because RBS may make so many synchronization messages, and then consume more energies at each node. So, two mechanisms may be used selectively according to the required environments, without saying that the one method is always better than the other.','',764,349,0,0,NULL,NULL),(13,2005,1,1,75,0,'The Plan and Tools for Vulnerability Testing in Information Software-Based System','Risk Analysis, Vulnerability, Asset, Threat','Injung Kim, Younggyo Lee, and Dongho Won','dlibrary/JIPS_v01_no1_paper13.pdf','Although many tests for stabilization of the software have been done, vulnerability test for a system run by combination of the software of various products has not been conducted enough. This has led to increased threats and vulnerability of system. Especially, web-based software system, which is public, has inherent possibility of exposure to attacks and is likely to be seriously damaged by an accident. Consequently, comprehensive and systematic test plans and techniques are required. Moreover, it is necessary to establish a procedure for managing and handling the results of vulnerability test. This paper proposes vulnerability test plans and designs for implementing automated tools, both of which can be complied with on web-based software systems.','',753,379,0,0,NULL,NULL),(14,2005,1,1,79,0,'Two-Dimensional Qualitative Asset Analysis Method based on Business Process-Oriented Asset Evaluation','Risk management, Risk Analysis, Asset analysis, 2-dimensional qualitative analysis','Jung-Ho Eom, Seon-Ho Park, Tae-Kyung Kim, and Tai-Myoung Chung','dlibrary/JIPS_v01_no1_paper14.pdf','In this paper, we dealt with substantial asset analysis methodology applied to twodimensional asset classification and qualitative evaluation method according to the business process. Most of the existent risk analysis methodology and tools presented classification by asset type and physical evaluation by a quantitative method. We focused our research on qualitative evaluation with 2-dimensional asset classification. It converts from quantitative asset value with purchase cost, recovery and exchange cost, etc. to qualitative evaluation considering specific factors related to the business process. In the first phase, we classified the IT assets into tangible and intangible assets, including human and information data asset, and evaluated their value. Then, we converted the quantitative asset value to the qualitative asset value using a conversion standard table. In the second phase, we reclassified the assets using 2-dimensional classification factors reflecting the business process, and applied weight to the first evaluation results. This method is to consider the organization characteristics, IT asset structure scheme and business process. Therefore, we can evaluate the concrete and substantial asset value corresponding to the organization business process, even if they are the same asset type.','',835,378,0,0,NULL,NULL),(15,2005,1,1,86,0,'Trusted Certificate Validation Scheme for Open LBS Application Based on XML Web Services','Location-based service, Open LBS security, XKMS, XML security, XML web services','Kiyoung Moon, Namje Park, Kyoil Chung, Sungwon Sohn, and Jaecheol Ryou','dlibrary/JIPS_v01_no1_paper15.pdf','Location-based services or LBS refer to value-added service by processing information utilizing mobile user location. With the rapidly increasing wireless Internet subscribers and world LBS market, the various location based applications are introduced such as buddy finder, proximity and security services. As the killer application of the wireless Internet, the LBS have reconsidered technology about location determination technology, LBS middleware server for various application, and diverse contents processing technology. However, there are fears that this new wealth of personal location information will lead to new security risks, to the invasion of the privacy of people and organizations. This paper describes a novel security approach on open LBS service to validate certificate based on current LBS platform environment using XKMS (XML Key Management Specification) and SAML (Security Assertion Markup Language), XACML (extensible Access Control Markup Language) in XML security mechanism.','',817,358,0,0,NULL,NULL),(16,2005,1,1,96,0,'A Study on RFID System with Secure Service Availability for Ubiquitous Computing','RFID, Service Availability, Secure Communication, Network Management Ubiquitous Computing','Dae-Hee Seo, and Im-Yeong Lee','dlibrary/JIPS_v01_no1_paper16.pdf','Spotlighted as an innovative information technology environment, ubiquitous computing has been actively researched on recently. Especially, domestic and global researches focus on the RFID system, which is being eyed to replace the existing bar-code system. As an essential technology for ubiquitous computing, the RFID system can be applied for various purposes. The security issues of the RFID system focus on how the low-priced tag type could have reasonable price competitiveness. The Auto-ID Center in the U.S. is spearheading the research on distribution service and omnidirectional security. As for Japan, the researches on omni-directional security and EPC application are necessary in securing the technology for ubiquitous computing with support from the Ministry of Public Management Home Affairs, Posts, and Telecommunication. In this paper, a method of ensuring the availability of the RFID system service will be presented based on the ubiquitous computing environment with the existing omni-directional security and user-friendly interface. While the existing researches focus on the RF reader system and tag-based security, this paper\'s suggestion also considers the availability of a service to suggest ways of increasing the practical usage of a low-priced RF tag.',NULL,826,383,0,0,NULL,NULL),(17,2005,1,1,102,0,'A Statistic Correlation Analysis Algorithm Between Land Surface Temperature and Vegetation Index','LST, NDVI, Correlation Analysis, Landsat ETM+','Hyung Moo Kim, Beob Kyun Kim, and Kang Soo You','dlibrary/JIPS_v01_no1_paper17.pdf','As long as the effective contributions of satellite images in the continuous monitoring of the wide area and long range of time period, Landsat TM and Landsat ETM+ satellite images are surveyed. After quantization and classification of the deviations between TM and ETM+ images based on approved thresholds such as gains and biases or offsets, a correlation analysis method for the compared calibration is suggested in this paper. Four time points of raster data for 15 years of the highest group of land surface temperature and the lowest group of vegetation of the Kunsan city Chollabuk_do Korea located beneath the Yellow sea coast, are observed and analyzed their correlations for the change detection of urban land cover. This experiment based on proposed algorithm detected strong and proportional correlation relationship between the highest group of land surface temperature and the lowest group of vegetation index which exceeded R=(+)0.9478, so the proposed Correlation Analysis Model between the highest group of land surface temperature and the lowest group of vegetation index will be able to give proof an effective suitability to the land cover change detection and monitoring.','',745,371,0,0,NULL,NULL),(18,2005,1,1,107,0,'Prototyping a Student Model for Educational Games','edutainment, pedagogical agents, emotion generation, student modeling, Intelligent Tutoring Systems, dynamic Bayesian networks','YoungMee Choi, MoonWon Choo, and SeongAh Chin','dlibrary/JIPS_v01_no1_paper18.pdf','When a pedagogical agent system aims to provide students with interactive help, it needs to know what knowledge the student has and what goals the student is currently trying to achieve. That is, it must do both assessment and plan recognition. These modeling tasks involve a high level of uncertainty when students are allowed to follow various lines of reasoning and are not required to show all their reasoning explicitly. In this paper, the student model for interactive edutainment applications is proposed. This model is based on Bayesian Networks to expose constructs and parameters of rules and propositions pertaining to game and problem solving activities. This student model could be utilized as the emotion generation model for student and agent as well.','',771,347,0,0,NULL,NULL),(19,2006,2,1,1,0,'A Timing Constraint Search Technique for a TMO based Real-time Process','Timing Constraint Search Technique, TMO Real-Time Process Load Model, Network Load Model','Yoon-Seok Jeong, Tae-Wan Kim, Sun Young Han, and Chun-Hyon Chang','dlibrary/JIPS_v02_no1_paper1.pdf','Finding a valid timing constraint is one of the most important issues in the real-time monitoring area. To get the valid timing constraint, a developer executes a real-time process and changes the constraint on a regular basis. This is an exhaustive and time-consuming process. To improve this approach, we propose a timing constraint search technique. This technique uses two load models and one condition proposed in this paper to support the developer in determining the valid timing constraint range in an easy and systematic manner.','',476,259,0,0,NULL,NULL),(20,2006,2,1,6,0,'Server Selection Schemes Considering Node Status For a Fault-Tolerant Streaming Service on a Peer-to-Peer Network','Peer-to-peer network, Fault-tolerant streaming services','Hyunjoo Kim, Sooyong Kang, and Heon Y. Yeom','dlibrary/JIPS_v02_no1_paper2.pdf','Peer-to-Peer (P2P) networks are attracting considerable research interest because of their scalability and high performance relative to cost. One of the important services on a P2P network is the streaming service. However, because each node in the P2P network is autonomous, it is difficult to provide a stable streaming service on the network. Therefore, for a stable streaming service on the P2P network, a fault-tolerant scheme must be provided. In this paper, we propose two new node selection schemes, Playback Node First (PNF) and Playback Node First with Prefetching (PNF-P) that can be used for a service migration-based fault-tolerant streaming service. The proposed schemes exploit the fact that the failure probability of a node currently being served is lower than that of a node not being served. Simulation results show that the proposed schemes outperform traditional node selection schemes.','',499,271,0,0,NULL,NULL),(21,2006,2,1,13,0,'An Efficient Audio Watermark Extraction in Time Domain','audio watermarking, blind detection Wavelet','Heawon Kang, and Sung-Hwan Jung','dlibrary/JIPS_v02_no1_paper3.pdf','In this paper, we propose an audio extraction method to decrease the influence of the original signal by modifying the watermarking detection system proposed by P. Bassia et al. In the extraction of the watermark, we employ a simple mean filter to remove the influence of the original signal as a preprocessing of extraction and the repetitive insertion of the watermark. As the result of the experiment, for which we used about 20 kinds of actual audio data, we obtain a watermark detection rate of about 95% and a good performance even after the various signal processing attacks.','',543,260,0,0,NULL,NULL),(22,2006,2,1,18,0,'Scenario-based 3D Objects Synthesizing System Design','3D Editing, 3D Synthesizing, 3D Object Reuse','Ji-Seung Nam, Hui Gao, Mi-Young Kang, Kyoung-Tae Kim, Seung-Chul Son, Chung-Ung Pom, and Kwon Heo','dlibrary/JIPS_v02_no1_paper4.pdf','This paper proposes the framework of the scenario-based 3D image synthesizing system that allows common users who envision a scenario in their mind to realize it into the segments of cool animation. We focused on utilization of the existing motions to synthesize new motions for the objects. The framework is useful to build a 3D animation in game programming with a limited set of 3D objects. We also propose a practical algorithm to reuse and expand the objects. This algorithm is based on motion path modification rules. Both linear and nonlinear curve-fitting algorithms were applied to modify an animation by key frame interpolation and to make the motion appear realistic.','',507,260,0,0,NULL,NULL),(23,2006,2,1,23,0,'A Feature Selection Technique based on Distributional Differences','Feature Selection, Distributional Differences','Sung-Dong Kim','dlibrary/JIPS_v02_no1_paper5.pdf','This paper presents a feature selection technique based on distributional differences for efficient machine learning. Initial training data consists of data including many features and a target value. We classified them into positive and negative data based on the target value. We then divided the range of the feature values into 10 intervals and calculated the distribution of the intervals in each positive and negative data. Then, we selected the features and the intervals of the features for which the distributional differences are over a certain threshold. Using the selected intervals and features, we could obtain the reduced training data. In the experiments, we will show that the reduced training data can reduce the training time of the neural network by about 40%, and we can obtain more profit on simulated stock trading using the trained functions as well.','',467,269,0,0,NULL,NULL),(24,2006,2,1,28,0,'A Universal Model for Policy-Based Access Control-enabled Ubiquitous Computing','Access control, Ubiquitous computing, Task computing, Context-awareness','Yixin Jing, Jinhyung Kim, and Dongwon Jeong','dlibrary/JIPS_v02_no1_paper6.pdf','The initial research of Task Computing in the ubiquitous computing (UbiComp) environment revealed the need for access control of services. Context-awareness of service requests in ubiquitous computing necessitates a well-designed model to enable effective and adaptive invocation. However, nowadays little work is being undertaken on service access control under the UbiComp environment, which makes the exposed service suffer from the problem of ill-use. One of the research focuses is how to handle the access to the resources over the network. Policy-Based Access Control is an access control method. It adopts a security policy to evaluate requests for resources but has a lightweight combination of the resources. Motivated by the problem above, we propose a universal model and an algorithm to enhance service access control in UbiComp. We detail the architecture of the model and present the access control implementation.','',527,299,0,0,NULL,NULL),(25,2006,2,1,34,0,'Decision of Maximum Congestion Window Size for TCP Performance Improvement by Bandwidth and RTT Measurement in Wireless Multi-Hop Networks','wireless multi-hop network, TCP, congestion window','In Huh, Jae Yong Lee, and Byung Chul Kim','dlibrary/JIPS_v02_no1_paper7.pdf','In the wireless network, TCP performs poorly because it was originally designed for wired networks and does not take into consideration wireless characteristics such as mobility, high-loss probability, and hidden-terminal problems. In particular, in the wireless multi-hop networks, a large congestion window increases the probability of contention and packet losses, and TCP performance is degraded severely as a result. So, it is necessary to limit the TCP congestion window size in order keep the probability of contention loss in the system to a minimum. In this paper, we propose a new scheme for determining the maximum congestion window size based on the measured bandwidth and Round-Trip-Time (RTT). Using ns-2 simulation, we show that the proposed scheme reduces the probability of packet contention and improves TCP performance.','',481,282,0,0,NULL,NULL),(26,2006,2,1,39,0,'TASL: A Traffic-Adapted Sleep/Listening MAC Protocol for Wireless Sensor Network','Wireless Sensor Network, MAC protocol, traffic aware, sleep/wake mechanism','Yuan Yang, Fu Zhen, Tae-Seok Lee, and Myong-Soon Park','dlibrary/JIPS_v02_no1_paper8.pdf','In this paper, we proposed TASL-MAC, a medium-access control (MAC) protocol for wireless sensor networks. In wireless sensor networks, sensor nodes are usually deployed in a special environment, are assigned with long-term work, and are supported by a limited battery. As such, reducing the energy consumption becomes the primary concern with regard to wireless sensor networks. At the same time, reducing the latency in multi-hop data transmission is also very important. In the existing research, sensor nodes are expected to be switched to the sleep mode in order to reduce energy consumption. However, the existing proposals tended to assign the sensors with a fixed Sleep/Listening schedule, which causes unnecessary idle listening problems and conspicuous transmission latency due to the diversity of the traffic-load in the network. TASL-MAC is designed to dynamically adjust the duty listening time based on traffic load. This protocol enables the node with a proper data transfer rate to satisfy the application¡¯s requirements. Meanwhile, it can lead to much greater power efficiency by prolonging the nodes¡¯ sleeping time when the traffic load of the network decreases. We evaluate our implementation of TASL-MAC in NS-2. The evaluation result indicates that our proposal could explicitly reduce packet delivery latency, and that it could also significantly prolong the lifetime of the entire network when traffic is low.','',541,239,0,0,NULL,NULL),(27,2006,2,1,44,0,'Distance Functions to Detect Changes in Data Streams','change detection, distance functions.','Ulziitugs Bud, and JongTae Lim','dlibrary/JIPS_v02_no1_paper9.pdf','One of the critical issues in a sensor network concerns the detection of changes in data streams. Recently presented change detection schemes primarily use a sliding window model to detect changes. In such a model, a distance function is used to compare two sliding windows. Therefore, the performance of the change detection scheme is greatly influenced by the distance function. With regard to sensor nodes, however, energy consumption constitutes a critical design concern because the change detection scheme is implemented in a sensor node, which is a small battery-powered device. In this paper, we present a comparative study of various distance functions in terms of execution time, energy consumption, and detecting accuracy through simulation of speech signal data. The simulation result demonstrates that the Euclidean distance function has the highest performance while consuming a low amount of power. We believe our work is the first attempt to undertake a comparative study of distance functions in terms of execution time, energy consumption, and accuracy detection.','',490,248,0,0,NULL,NULL),(28,2006,2,1,48,0,'Secure Key Management Protocol in the Wireless Sensor Network','Cluster, Key Management Protocol, WSN','Yoon-Su Jeong, and Sang-Ho Lee','dlibrary/JIPS_v02_no1_paper10.pdf','To achieve security in wireless sensor networks (WSN), it is important to be able to encrypt messages sent among sensor nodes. We propose a new cryptographic key management protocol, which is based on the clustering scheme but does not depend on the probabilistic key. The protocol can increase the efficiency to manage keys since, before distributing the keys by bootstrap, the use of public keys shared among nodes can eliminate the processes to send or to receive keys among the sensors. Also, to find any compromised nodes safely on the network, it solves safety problems by applying the functions of a lightweight attack-detection mechanism.','',523,285,0,0,NULL,NULL),(29,2006,2,1,52,0,'Vehicle Classification by Road Lane Detection and Model Fitting Using a Surveillance Camera','Vehicle Type classification, Road Lane Detection, Model fitting, Vanishing Point, Machine Learning','Wook-Sun Shin, Doo-Heon Song, and Chang-Hun Lee','dlibrary/JIPS_v02_no1_paper11.pdf','One of the important functions of an Intelligent Transportation System (ITS) is to classify vehicle types using a vision system. We propose a method using machine-learning algorithms for this classification problem with 3-D object model fitting. It is also necessary to detect road lanes from a fixed traffic surveillance camera in preparation for model fitting. We apply a background mask and line analysis algorithm based on statistical measures to Hough Transform (HT) in order to remove noise and false positive road lanes. The results show that this method is quite efficient in terms of quality.','',649,292,0,0,NULL,NULL),(30,2006,2,1,58,0,'Monitoring Systems for Embedded Equipment in Ubiquitous Environments','Ubiquitous Computing, Monitoring System, Sensor Network','Ji-Hye Bae, Hee-Kuk Kang, Yoon-Young Park, and Jung-Ho Park','dlibrary/JIPS_v02_no1_paper12.pdf','Accurate and efficient monitoring of dynamically changing environments is one of the most important requirements for ubiquitous network environments. Ubiquitous computing provides intelligent environments which are aware of spatial conditions and can provide timely and useful information to users or devices. Also, the growth of embedded systems and wireless communication technology has made it possible for sensor network environments to develop on a large scale and at low-cost. In this paper, we present the design and implementation of a monitoring system that collects, analyzes, and controls the status information of each sensor, following sensor data extracted from each sensor node. The monitoring system adopts Web technology for the implementation of a simple but efficient user interface that allows an operator to visualize any of the processes, elements, or related information in a convenient graphic form.','',504,286,0,0,NULL,NULL),(31,2006,2,2,67,0,'ASVMRT: Materialized View Selection Algorithm in Data Warehouse','Materialized views, Data Warehouse, and Clustering','Jin-Hyuk Yang, and In-Jeong Chung','dlibrary/JIPS_v02_no2_paper1.pdf','In order to acquire a precise and quick response to an analytical query, proper selection of the views to materialize in the data warehouse is crucial. In traditional view selection algorithms, all relations are considered for selection as materialized views. However, materializing all relations rather than a part results in much worse performance in terms of time and space costs. Therefore, we present an improved algorithm for selection of views to materialize using the clustering method to overcome the problem resulting from conventional view selection algorithms. In the presented algorithm, ASVMRT (Algorithm for Selection of Views to Materialize using Reduced Table), we first generate reduced tables in the data warehouse using clustering based on attribute-values density, and then we consider the combination of reduced tables as materialized views instead of a combination of the original base relations. For the justification of the proposed algorithm, we reveal the experimental results in which both time and space costs are approximately 1.8 times better than conventional algorithms.','',670,307,0,0,NULL,NULL),(32,2006,2,2,76,0,'An Evaluation of Multimedia Data Downstream with PDA in an Infrastructure Network','Multimedia data, downstream, PDA, TCP window size, inter-packet delay','Youn-Sik Hong, and Hye-Sun Hur','dlibrary/JIPS_v02_no2_paper2.pdf','A PDA is used mainly for downloading data from a stationary server such as a desktop PC in an infrastructure network based on wireless LAN. Thus, the overall performance depends heavily on the performance of such downloading with PDA. Unfortunately, for a PDA the time taken to receive data from a PC is longer than the time taken to send it by 53%. Thus, we measured and analyzed all possible factors that could cause the receiving time of a PDA to be delayed with a test bed system. There are crucial factors: the TCP window size, file access time of a PDA, and the inter-packet delay that affects the receiving time of a PDA. The window size of a PDA during the downstream is reduced dramatically to 686 bytes from 32,581 bytes. In addition, because flash memory is embedded into a PDA, writing data into the flash memory takes twice as long as reading the data from it. To alleviate these, we propose three distinct remedies: First, in order to keep the window size at a sender constant, both the size of a socket send buffer for a desktop PC and the size of a socket receive buffer for a PDA should be increased. Second, to shorten its internal file access time, the size of an application buffer implemented in an application should be doubled. Finally, the inter-packet delay of a PDA and a desktop PC at the application layer should be adjusted asymmetrically to lower the traffic bottleneck between these heterogeneous terminals.','',537,261,0,0,NULL,NULL),(33,2006,2,2,82,0,'Data-Hiding Method using Digital Watermark in the Public Multimedia Network','Digital Watermark, Scalable, Wavelet, Public Multimedia Network','Jung-Hee Seo, and Hung-Bog Park','dlibrary/JIPS_v02_no2_paper3.pdf','In spite of the rapid development of the public network, the variety of network-based developments currently raises numerous risks factors regarding copyright violation, the prohibition and distribution of digital media utilization, safe communication, and network security. Among these problems, multimedia data tend to increase in the distributed network environment. Hence, most image information has been transmitted in the form of digitalization. Therefore, the need for multimedia contents protection must be addressed. This paper is focused on possible solutions for multimedia contents security in the public network in order to prevent data modification by non-owners and to ensure safe communication in the distributed network environment. Accordingly, the Orthogonal Forward Wavelet Transform-based Scalable Digital Watermarking technique is proposed in this paper.','',562,275,0,0,NULL,NULL),(34,2006,2,2,88,0,'Determination of Optimal Cell Capacity for Initial Cell Planning in Wireless Cellular Networks','QoS, optimal cell capacity, cell planning, wireless cellular networks','Young Ha Hwang, Sung-Kee Noh, and Sang-Ha Kim','dlibrary/JIPS_v02_no2_paper4.pdf','In wireless cellular networks, previous researches on admission control policies and resource allocation algorithm considered the QoS (Quality of Service) in terms of CDP (Call Dropping Probability) and CBP (Call Blocking Probability). However, since the QoS was considered only within a predetermined cell capacity, the results indicated a serious overload problem of systems not guaranteeing both CDP and CBP constraints, especially in the hotspot cell. That is why a close interrelationship between CDP, CBP and cell capacity exists. Thus, it is indispensable to consider optimal cell capacity guaranteeing multiple QoS (CDP and CBP) at the time of initial cell planning for networks deployment. In this paper, we will suggest a distributed determination scheme of optimal cell capacity guaranteeing both CDP and CBP from a long-term perspective for initial cell planning. The cell-provisioning scheme is performed by using both the two-dimensional continuous-time Markov chain and an iterative method called the Gauss-Seidel method. Finally, numerical and simulation results will demonstrate that our scheme successfully determines an optimal cell capacity guaranteeing both CDP and CBP constraints for initial cell planning.','',542,358,0,0,NULL,NULL),(35,2006,2,2,95,0,'A Practical Security Risk Analysis Process and Tool for Information System','Risk Management, Asset, Threats, Vulnerability, Countermeasure','YoonJung Chung, InJung Kim, and DoHoon Lee','dlibrary/JIPS_v02_no2_paper5.pdf','While conventional business administration-based information technology management methods are applied to the risk analysis of information systems, no security risk analysis techniques have been used in relation to information protection. In particular, given the rapid diffusion of information systems and the demand for information protection, it is vital to develop security risk analysis techniques. Therefore, this paper will suggest an ideal risk analysis process for information systems. To prove the usefulness of this security risk analysis process, this paper will show the results of managed, physical and technical security risk analysis that are derived from investigating and analyzing the conventional information protection items of an information system.','',610,575,0,0,NULL,NULL),(36,2006,2,2,101,0,'The Design and Implementation of an Available Bandwidth Measurement Scheme in the KGrid System','KGrid, Globus Toolkit, Available Bandwidth Measurement, XML schema','Seong-il Hahm, Seongho Cho, Han Choi, Chong-kwon Kim, and Pillwoo Lee','dlibrary/JIPS_v02_no2_paper6.pdf','Grid computing is an emerging technology that enables global resource sharing. In Korea, the K*Grid provides an extremely powerful research environment to both industries and academia. As part of the K*Grid project, we have constructed, together with the Korea Institute of Science and Technology Information and a number of domestic universities, a supercomputer Grid test bed which connects several types of supercomputers based on the globus toolkit. To achieve efficient networking in this Grid testbed, we propose a novel method of available bandwidth measurement, called Decoupled Capacity measurement with Initial Gap (DCIG), using packet trains. DCIG can improve the network efficiency by selecting the best path among several candidates. Simulation results show that DCIG outperforms previous work in terms of accuracy and the required measurement time. We also define a new XML schema for DCIG request/response based on the schema defined by the Global Grid Forum (GGF) Network Measurement Working Group (NM-WG).','',596,266,0,0,NULL,NULL),(37,2006,2,2,107,0,'A New Fair Call Admission Control for Integrated Voice and Data Traffic in Wireless Mobile Networks','CAC, QoS, Fairness, Integrated service, Wireless mobile networks','Young Ha Hwang, Sung-Kee Noh, and Sang-Ha Kim','dlibrary/JIPS_v02_no2_paper7.pdf','It is essential to guarantee a handoff dropping probability below a predetermined threshold for wireless mobile networks. Previous studies have proposed admission control policies for integrated voice/data traffic in wireless mobile networks. However, since QoS has been considered only in terms of CDP (Call Dropping Probability), the result has been a serious CBP (Call Blocking Probability) unfairness problem between voice and data traffic. In this paper, we suggest a new admission control policy that treats integrated voice and data traffic fairly while maintaining the CDP constraint. For underprivileged data traffic, which requires more bandwidth units than voice traffic, the packet is placed in a queue when there are no available resources in the base station, instead of being immediately rejected. Furthermore, we have adapted the biased coin method concept to adjust unfairness in terms of CBP. We analyzed the system model of a cell using both a two-dimensional continuous-time Markov chain and the Gauss-Seidel method. Numerical results demonstrate that our CAC (Call Admission Control) scheme successfully achieves CBP fairness for voice and data traffic.','',643,301,0,0,NULL,NULL),(38,2006,2,2,114,0,'A Method for Automatic Generation of OWL-S Service Ontology','Ontology, Semantic Web, OWL-S, State-chart, and UML','Jin-Hyuk Yang, and In-Jeong Chung','dlibrary/JIPS_v02_no2_paper8.pdf','We present in this paper the methodology for automatic generation of OWL-S service model ontology along with the results and issues. First, we extract information related to atomic services and their properties such as IOPE from the UML class diagram, and retrieve information related to the composition of services from the UML state-chart diagram. Then, the XSLT applications utilize the acquired information to generate the OWL-S service model ontology through the predefined mappings between OWL-S constructs for composite services and UML state-chart primitives. For the justification of generated service ontology, several validation checks are performed. Our service ontology generation method is general and fully automatic, as well as effective, in that it is achieved in an environment familiar to developers, and information needed to generate service ontology is provided necessarily during service development. It is also noticeable to facilitate representing the condition with GUI rather than a complex language such as OCL.','',617,281,0,0,NULL,NULL),(39,2006,2,2,124,0,'A Knowledge Discovery Framework for Spatiotemporal Data Mining','spatiotemporal data mining, spatiotemporal knowledge discovery, spatiotemporal moving pattern, discovery framework','Jun-Wook Lee, and Yong-Joon Lee','dlibrary/JIPS_v02_no2_paper9.pdf','With the explosive increase in the generation and utilization of spatiotemporal data sets, many research efforts have been focused on the efficient handling of the large volume of spatiotemporal sets. With the remarkable growth of ubiquitous computing technology, mining from the huge volume of spatiotemporal data sets is regarded as a core technology which can provide real world applications with intelligence. In this paper, we propose a 3-tier knowledge discovery framework for spatiotemporal data mining. This framework provides a foundation model not only to define the problem of spatiotemporal knowledge discovery but also to represent new knowledge and its relationships. Using the proposed knowledge discovery framework, we can easily formalize spatiotemporal data mining problems. The representation model is very useful in modeling the basic elements and the relationships between the objects in spatiotemporal data sets, information and knowledge.','',599,270,0,0,NULL,NULL),(40,2006,2,2,130,0,'A Study of a Server Selection Model for Selecting a Replicated Server based on Downstream Measurement in the Server-side','server selection, replicated server, measurement','Seung-Hae Kim, Won-Hyuk Lee, and Gi-Hwan Cho','dlibrary/JIPS_v02_no2_paper10.pdf','In the distributed replicating server model, the provision of replicated services will improve the performance of the providing service and efficiency for clients. Efficiently composing the server selection algorithm decreases the retrieval time for replicated data. In this paper, we define the system model that selects and connects the replicated server that provides an optimal service using the server-side downstream measurement and propose a server selection algorithm.','',480,255,0,0,NULL,NULL),(41,2006,2,3,137,0,'Automatic Hardware/Software Interface Generation for Embedded System','Embedded System, Hardware Controller, Device Driver, Code Generation, Co-design','Choonho Son, Jeong-Han Yun, Hyun-Goo Kang, and Taisook Han','dlibrary/JIPS_v02_no3_paper1.pdf','A large portion of the embedded system development process involves the integration of hardware and software. Unfortunately, communication across the hardware/software boundary is tedious and error-prone to create. This paper presents an automatic hardware/software interface generation system. As the front-end of hardware/software co-design frameworks, a system designer defines XML specifications for hardware functions. Our system generates hardware/software interfaces including Device Driver, Driver API, and Device Controller from these specifications. Embedded software designers can easily use hardware just like system libraries. Our system reduces the mistakes and errors that can be occurred when a software programmer directly connects software to hardware, and supports balancing labors between hardware developers and software programmers. Moreover, this system can be used as the back-end for a hardware/software co-design framework.','',820,392,0,0,NULL,NULL),(42,2006,2,3,143,0,'Digital Controller of a Diesel Generator using an Embedded System','Diesel Generator, Embedded Controller, Remote Control','Kwang Seon Ahn','dlibrary/JIPS_v02_no3_paper2.pdf','We have designed an embedded controller for the control of a diesel generator using an embedded system. The generator is monitored and controlled remotely via the internet in real-time. The proposed digital controller is designed to handle precisely the distortions and noises of the signals emanating from the diesel generator, and enables abnormal operation of the diesel generator to be notified to the remote manager using the Short Message Service (SMS) of the Internet, which enables the appropriate personnel to take action by remote control according to the incoming messages.','',772,475,0,0,NULL,NULL),(43,2006,2,3,147,0,'Design of a NAND Flash Memory File System to Improve System Boot Time','Fast Mounting, Flash File System, NAND Flash Memory','Song-Hwa Park, Tae-Hoon Lee, and Ki-Dong Chung','dlibrary/JIPS_v02_no3_paper3.pdf','NAND flash memory-based embedded systems are becoming increasingly common. These embedded systems have to provide a fast boot time. In this paper, we have designed and proposed a flash file system for embedded systems that require fast booting. By using a Flash Image Area, which keeps the latest flash memory information such as types and status of all blocks, the file system mounting time can be reduced significantly. We have shown by experiments that our file system outperforms YAFFS and RFFS.','',758,380,0,0,NULL,NULL),(44,2006,2,3,153,0,'Design of an Image Interpolator for Low Computation Complexity','Interpolation, Interpolator, Cubic convolution , Linear function','Young-Hyun Jun, Jong-Ho Yun, Jin-Sung Park, and Myung-Ryul Choi','dlibrary/JIPS_v02_no3_paper4.pdf','In this paper, we propose an image interpolator for low computational complexity. The proposed image interpolator supports the image scaling using a modified cubic convolution interpolation between the input and output resolutions for a full screen display. In order to reduce the computational complexity, we use the difference in value of the adjacent pixels for selecting interpolation methods and linear function of the cubic convolution. The proposed image interpolator is compared with the conventional one for the computational complexity and image quality. The proposed image interpolator has been designed and verified by Verilog HDL(Hardware Description Language). It has been synthesized using the Xilinx VirtexE FPGA, and implemented using an FPGA-based prototype board.','',753,404,0,0,NULL,NULL),(45,2006,2,3,159,0,'Selection of a Competent Wireless Access Point for High Wireless Bandwidth','WLAN, AP, SNMP, Network Utilization','Ji Yeon Park and Kitae Hwang','dlibrary/JIPS_v02_no3_paper5.pdf','Wireless LANs are becoming more widespread because of the rapid advance of wireless technologies and mobile computers. In this paper, we present the design and implementation of a system to help mobile users to select the most competent AP. By monitoring the network traffic of APs within the local LAN in real time, this system offers the mobile user the network utilizations, locations, and signal strengths of APs online. Based on the information, the user can select a competent AP with a high wireless bandwidth. Finally, we verified the accuracy of monitoring and calculating with regard to the utilizations of APs through real experiments.','',698,321,0,0,NULL,NULL),(46,2006,2,3,163,0,'A Quality Assurance Process Model on Fault Management','TMN, fault management, ERP, UML, RUP','Hyo-Soo Kim, and Cheong Ho Baek','dlibrary/JIPS_v02_no3_paper6.pdf','So far, little research has been conducted into developing a QAPM (Quality Assurance Process Model) for telecommunications applications on the basis of TMN. This is the first trial of the design of TMN-based QAPM on fault management with UML. A key attribute of the QAPM is that it can easily identify current deficiencies in a legacy system on the basis of TMN architecture. Using an empirical comparison with the legacy systems of a common carrier validates the QAPM as the framework for a future mode of the operation process. The results indicate that this paper can be used to build ERP(Enterprise Resource Planning)for a telecommunications fault management solution that is one of the network management application building blocks. The future work of this paper will involve applying the QAPM to build ERP for RTE (Real Time Enterprise) fault management solution and more research on ERP design will be necessary to accomplish software reuse.','',746,425,0,0,NULL,NULL),(47,2006,2,3,170,0,'Design and Implementation of an RFID-based Enterprise Application Framework based on Abstract BP and Kerberos','RFID, EPCglobal Network, Framework, Business Process, Computer Security','Kyuhee An, Kiyeal Lee, and Mokdong Chung','dlibrary/JIPS_v02_no3_paper7.pdf','Recently, RFID technology has attracted considerable attention in many industry fields. The RFID environment requires a standard architecture for the smooth exchange of data between heterogeneous networks. The architecture should offer an efficient standard environment, such as a communication environment based on Web Services, PKI or Kerberos-based security, and abstract business processes which could be used in the diverse domains. Therefore, in this paper, we propose an Enterprise Application Framework (EAF) which includes a standard communication protocol, security functions, and abstract level business processes. The suggested architecture is expected to provide a more secure and flexible security management in the dynamic RFID application environments, and is expected to provide an abstract business event for the development of business processes which could apply RFID technology to the existing systems.','',769,373,0,0,NULL,NULL),(48,2006,2,3,178,0,'Metaphor and Typeface Based on Children’s Sensibilities for e-Learning','e-Learning, Sensibility Factor, Metaphor, Typeface, Collaborative Recommending','Miheon Jo, and Jeonghye Han','dlibrary/JIPS_v02_no3_paper8.pdf','Children exhibit different behaviors, skills, and motivations. The main aim of this research was to investigate children¡¯s sensibility factors for icons, and to look for the best typeface for application to Web-Based Instruction (WBI) for e-Learning. Three types of icons were used to assess children¡¯s sensibilities toward metaphors: text-image, representational, and spatial mapping. Through the factor analysis, we found that children exhibited more diverse reactions to the text-image and representational types of icons than to the spatial mapping type of icons. Children commonly showed higher sensibilities to the aesthetic-factor than to the familiarity-factor or the brevity-factor. In addition, we propose a collaborative-typeface system, which recommends the best typeface for children regarding the readability and aesthetic factor in WBI. Based on these results, we venture some suggestions on icon design and typeface selection for e-Learning.','',774,342,0,0,NULL,NULL),(49,2006,2,3,183,0,'A Light-weight and Dynamically Reconfigurable RMON Agent System','Network management, RMON agent system, Dynamic reconfiguration.','Jun-Hyung Lee, Zin-Won Park, and Myung-Kyun Kim','dlibrary/JIPS_v02_no3_paper9.pdf','A RMON agent system, which locates on a subnet, collects the network traffic information for management by retrieving and analyzing all of the packets on the subnet. The RMON agent system can miss some packets due to the high packet analyzing overhead when the number of packets on the subnet is huge. In this paper, we have developed a light-weight RMON agent system that can handle a large amount of packets without packet loss. Our RMON agent system has also been designed such that its functionality can be added dynamically when needed. To demonstrate the dynamic reconfiguration capability of our RMON agent system, a simple port scanning attack detection module is added to the RMON agent system. We have also evaluated the performance of our RMON agent system on a large network that has a huge traffic. The test result has shown our RMON agent system can analyze the network packets without packet loss.','',736,339,0,0,NULL,NULL),(50,2006,2,3,189,0,'Automatic Reading System for On-off Type DNA Chip','DNA chip, Automatic Reading, Report Generation, Image Processing, HPV DNA chip','Munho Ryu, Jong Dae Kim, and Jongwon Kim','dlibrary/JIPS_v02_no3_paper10.pdf','In this study we propose an automatic reading system for diagnostic DNA chips. We define a general specification for an automatic reading system and propose a possible implementation method. The proposed system performs the whole reading process automatically without any user intervention, covering image acquisition, image analysis, and report generation. We applied the system for the automatic report generation of a commercialized DNA chip for cervical cancer detection. The fluorescence image of the hybridization result was acquired with a GenePixTM scanner using its library running in HTML pages. The processing of the acquired image and the report generation were executed by a component object module programmed with Microsoft Visual C++ 6.0. To generate the report document, we made an HWP 2002 document template with marker strings that were supposed to be searched and replaced with the corresponding information such as patient information and diagnosis results. The proposed system generates the report document by reading the template and changing the marker strings with the resultant contents. The system is expected to facilitate the usage of a diagnostic DNA chip for mass screening by the automation of a conventional manual reading process, shortening its processing time, and quantifying the reading criteria.','',752,340,0,0,NULL,NULL),(51,2007,3,1,1,0,'A Scalable Multicasting with Group Mobility Support in Mobile Ad Hoc Networks','MANET Multicast Protocol, Overlay Multicast, Group Mobility','Kap-Dong Kim, Kwangil Lee, Jun-Hee Park, and Sang-Ha Kim','dlibrary/JIPS_v03_no1_paper1.pdf','In mobile ad hoc networks, an application scenario requires mostly collaborative mobility behavior. The key problem of those applications is scalability with regard to the number of multicast members as well as the number of the multicast group. To enhance scalability with group mobility, we have proposed a multicast protocol based on a new framework for hierarchical multicasting that is suitable for the group mobility model in MANET. The key design goal of this protocol is to solve the problem of reflecting the node¡¯s mobility in the overlay multicast tree, the efficient data delivery within the sub-group with group mobility support, and the scalability problem for the large multicast group size. The results obtained through simulations show that our approach supports scalability and efficient data transmission utilizing the characteristic of group mobility.','',592,308,0,0,NULL,NULL),(52,2007,3,1,8,0,'Membership Management based on a Hierarchical Ring for Large Grid Environments','P2P, Membership Overlay, Membership Management, Hierarchical Ring','Tae-Wan Gu, Seong-Jun Hong, Saangyong Uhmn, and Kwang-Mo Lee','dlibrary/JIPS_v03_no1_paper2.pdf','Grid environments provide the mechanism to share heterogeneous resources among nodes. Because of the similarity between grid environments and P2P networks, the structures of P2P networks can be adapted to enhance scalability and efficiency in deployment and to search for services. In this paper, we present a membership management based on a hierarchical ring which constructs P2P-like Grid environments. The proposed approach uses only a limited number of connections, reducing communication cost. Also, it only keeps local information for membership, which leads to a further reduction in management cost. This paper analyzes the performance of the approach by simulation and compares it with other approaches.','',524,266,0,0,NULL,NULL),(53,2007,3,1,16,0,'Interface Development for the Point-of-care device based on SOPC','Point-Of-Care, System-On-a-Programmable-Chip, Interface, Driver, Linux, ?C/OS-II','Hong Bum Son, Sung Gun Song, Jae Wook Jung, Chang Su Lee, and Seong Mo Park','dlibrary/JIPS_v03_no1_paper3.pdf','This paper describes the development of the sensor interface and driver program for a point of care (POC) device. The proposed POC device comprises an ARM9 embedded processor and eightchannel sensor input to measure various bio-signals. It features a user-friendly interface using a fullcolor TFT-LCD and touch-screen, and a bluetooth wireless communication module. The proposed device is based on the system on a programmable chip (SOPC). We use Altera¡¯s Excalibur device, which has an ARM9 and FPGA area on a chip, as a test bed for the development of interface hardware and driver software.','',554,277,0,0,NULL,NULL),(54,2007,3,1,21,0,'A Practical Privacy-Preserving Cooperative Computation Protocol without Oblivious Transfer for Linear Systems of Equations','SMC. Practical SMC, Privacy, Linear system of equations','Ju-Sung Kang and Dowon Hong ','dlibrary/JIPS_v03_no1_paper4.pdf','We propose several practical SMC protocols for privacy-preserving cooperative scientific computations. We consider two important scientific computations which involve linear equations: the linear systems of equations problem and the linear least-square problem. The protocols proposed in this paper achieve acceptable security in the sense of Du-Zhan¡¯s paradigm and t-wise collusionresistance, and their communication complexity is O(tm), where t is a security parameter and m is the total number of participants. The complexity of our protocol is significantly better than the previous result O(m©÷§¤¥ì) of [4], in which the oblivious transfer protocol is used as an important building block.','',482,275,0,0,NULL,NULL),(55,2007,3,1,26,0,'Static Type Assignment for SSA Form in CTOC','Bytecode, control flow graph, Static Single Assignment, Static Type Assignment','Ki-Tae Kim and Weon-Hee Yoo','dlibrary/JIPS_v03_no1_paper5.pdf','Although the Java bytecode has numerous advantages, it also has certain shortcomings such as its slow execution speed and difficulty of analysis. In order to overcome such disadvantages, a bytecode analysis and optimization must be performed. The control flow of the bytecode should be analyzed; next, information is required regarding where the variables are defined and used to conduct a dataflow analysis and optimization. There may be cases where variables with an identical name contain different values at different locations during execution, according to the value assigned to a given variable in each location. Therefore, in order to statically determine the value and type, the variables must be separated according to allocation. In order to achieve this, variables can be expressed using a static single assignment form. After transformation into a static single assignment form, the type information of each node expressed by each variable and expression must be configured to perform a static analysis and optimization. Based on the basic type information, this paper proposes a method for finding the related equivalent nodes, setting nodes with strong connection components, and efficiently assigning each node type','',477,252,0,0,NULL,NULL),(56,2007,3,1,33,0,'Feature Extraction of Concepts by Independent Component Analysis','Independent Component Analysis, Clustering, Latent Concepts.','Altangerel Chagnaa, Cheol-Young Ock, Chang-Beom Lee, and Purev Jaimai','dlibrary/JIPS_v03_no1_paper6.pdf','Semantic clustering is important to various fields in the modern information society. In this work we applied the Independent Component Analysis method to the extraction of the features of latent concepts. We used verb and object noun information and formulated a concept as a linear combination of verbs. The proposed method is shown to be suitable for our framework and it performs better than a hierarchical clustering in latent semantic space for finding out invisible information from the data.','',601,266,0,0,NULL,NULL),(57,2007,3,1,38,0,'An Efficient Functional Analysis Method for Micro-array Data Using Gene Ontology','Micro-array data, Functional analysis, Gene Ontology, Informative genes.','Dong-wan Hong, Jong-keun Lee, Sung-soo Park, Sang-kyoon Hong, and Jee-hee Yoon','dlibrary/JIPS_v03_no1_paper7.pdf','Microarray data includes tens of thousands of gene expressions simultaneously, so it can be effectively used in identifying the phenotypes of diseases. However, the retrieval of functional information from a large corpus of gene expression data is still a time-consuming task. In this paper, we propose an efficient method for identifying functional categories of differentially expressed genes from a micro-array experiment by using Gene Ontology (GO). Our method is as follows: (1) The expression data set is first filtered to include only genes with mean expression values that differ by at least 3-fold between the two groups. (2) The genes are then ranked based on the t-statistics. The 100 most highly ranked genes are selected as informative genes. (3) The t-value of each informative gene is imposed as a score on the associated GO terms. High-scoring GO terms are then listed with their associated genes and represent the functional category information of the micro-array experiment. A system called HMDA (Hallym Micro-array Data analysis) is implemented on publicly available microarray data sets and validated. Our results were also compared with the original analysis.','',520,281,0,0,NULL,NULL),(58,2007,3,2,43,0,'Addressing Mobile Agent Security through Agent Collaboration','Disk Striping, Multimedia System, Bandwidth','Evens Jean, Yu Jiao, and Ali R Hurson','dlibrary/JIPS_v03_no2_paper1.pdf','The use of agent paradigm in today¡¯s applications is hampered by the security concerns of agents and hosts alike. The agents require the presence of a secure and trusted execution environment; while hosts aim at preventing the execution of potentially malicious code. In general, hosts support the migration of agents through the provision of an agent server and managing the activities of arriving agents on the host. Numerous studies have been conducted to address the security concerns present in the mobile agent paradigm with a strong focus on the theoretical aspect of the problem. Various proposals in Intrusion Detection Systems aim at securing hosts in traditional client-server execution environments. The use of such proposals to address the security of agent hosts is not desirable since migrating agents typically execute on hosts as a separate thread of the agent server process. Agent servers are open to the execution of virtually any migrating agent; thus the intent or tasks of such agents cannot be known a priori. It is also conceivable that migrating agents may wish to hide their intentions from agent servers. In light of these observations, this work attempts to bridge the gap from theory to practice by analyzing the security mechanisms available in Aglet. We lay the foundation for implementation of application specific protocols dotted with access control, secured communication and ability to detect tampering of agent data. As agents exists in a distributed environment, our proposal also introduces a novel security framework to address the security concerns of hosts through collaboration and pattern matching even in the presence of differing views of the system. The introduced framework has been implemented on the Aglet platform and evaluated in terms of accuracy, false positive, and false negative rates along with its performance strain on the system.','',825,508,0,0,NULL,NULL),(59,2007,3,2,54,0,'Actual Condition and Issues for Mobile Security System','Mobile Security, Mobile Malware, Mobile DRM System, Mobile WiMAX Security, Group Key Management','Kouichi Sakurai and Kazuhide Fukushima','dlibrary/JIPS_v03_no2_paper2.pdf','The high-speed mobile Internet has recently been expanded, many attractive services are provided. However, these services require some form of security-related technology. This paper outlines Japanese mobile services and exposits some mobile security topics including mobile spam, mobile malware, mobile DRM system, mobile WiMAX security, and mobile key management.','',905,581,0,0,NULL,NULL),(60,2007,3,2,64,0,'Use of Mobile Devices in the Performance of Group Decision-Making under Contextual Pressure','Group Decision Making, Mobile Technology, Mobile Devices, Group Decision Support','Oh Byung Kwon, Tae Kyung Kim, and Choong Rhyun Kim','dlibrary/JIPS_v03_no2_paper3.pdf','Mobile technology appears promising as a method to promote group performance in circumstances dependent on time, but not member proximity. However, the success of mobile technology in group decision-making situations has not yet been proven. This paper aims to see how mobile technology affects the performance of group decision-making tasks that should be resolved urgently and/or sources of idea are disconnected with on-line network. Laboratory experiment was used to investigate the effects of mobile factors on group decision-making. The results from the experiment supported the proposition that pressures of time and location play a significant role in the assessment of group decision performance measures. We found that the adoption of mobile technology to group decision-making procedures might be competitive when group decision-making tasks are urgent and sources of idea are disconnected with on-line network, even though mobile technology is not a panacea on which to depend when designing group decision-making.','',756,484,0,0,NULL,NULL),(61,2007,3,2,73,0,'Optimization of Domain-Independent Classification Framework for Mood Classification','Text Classification, Mood Categorization, Information Retrieval, Feature Selection, Text Classification Application','Sung-Pil Choi, Yuchul Jung, and Sung-Hyon Myaeng','dlibrary/JIPS_v03_no2_paper4.pdf','In this paper, we introduce a domain-independent classification framework based on both k-nearest neighbor and Naïve Bayesian classification algorithms. The architecture of our system is simple and modularized in that each sub-module of the system could be changed or improved efficiently. Moreover, it provides various feature selection mechanisms to be applied to optimize the general-purpose classifiers for a specific domain. As for the enhanced classification performance, our system provides conditional probability boosting (CPB) mechanism which could be used in various domains. In the mood classification domain, our optimized framework using the CPB algorithm showed 1% of improvement in precision and 2% in recall compared with the baseline.','',838,35,0,0,NULL,NULL),(62,2007,3,2,82,0,'A Delegation Model based on Agent in Distributed Systems','XACML, SAML, Agent','Kyu Il Kim, Joo Chang Lee, Won Gil Choi, Eun Ju Lee, and Ung Mo Kim','dlibrary/JIPS_v03_no2_paper5.pdf','Web services are the new building block of today¡¯s Internet, and provides interoperability among heterogeneous distributed systems. Recently in web services environment, security has become one of the most critical issues. The hackers attack one of fragile point and can misuse legitimate user privilege because all of the connected devices provide services for the user control and monitoring in real time. Also, the users of web services must temporarily delegate some or all of their rights to agents in order to perform actions on their behalf. This fact risks the exposure of user privacy information. In this paper, we propose secure delegation model based on SAML that provides confidentiality and integrity about the user information in distributed systems. In order to support privacy protection, service confidentiality, and assertion integrity, encryption and a digital signature mechanism is deployed. We build web service management server based on XACML, in order to manage services and policies of web service providers.','',798,471,0,0,NULL,NULL),(63,2008,4,1,1,0,'Utilizing Fragmented Bandwidth in a Staggered Striping Multimedia System','Disk Striping, Multimedia System, Bandwidth','Wen-Chi Hou, Yang Pan, and Dunren Che','dlibrary/JIPS_v04_no1_paper1.pdf','In this paper, we discuss the use of fragmented bandwidth to improve the performance of staggered striping in a multimedia system. It is observed that potential disruptions can occur when nonconsecutive idle disks are used for displaying multimedia objects. We have identified useful retrieval patterns and shown that with proper selections of fragmented disks and a simple buffering scheme, disruptions can be easily eliminated.','10.3745/JIPS.2008.4.1.001',623,335,0,0,NULL,NULL),(64,2008,4,1,9,0,'Two-Tier Storage DBMS for High-Performance Query Processing','DBMS, Storage Management, Query Processing','Sang-Hun Eo, Yan Li, Ho-Seok Kim, and Hae-Young Bae','dlibrary/JIPS_v04_no1_paper2.pdf','This paper describes the design and implementation of a two-tier DBMS for handling massive data and providing faster response time. In the present day, the main requirements of DBMS are figured out using two aspects. The first is handling large amounts of data. And the second is providing fast response time. But in fact, Traditional DBMS cannot fulfill both the requirements. The disk-oriented DBMS can handle massive data but the response time is relatively slower than the memory-resident DBMS. On the other hand, the memory-resident DBMS can provide fast response time but they have original restrictions of database size. In this paper, to meet the requirements of handling large volumes of data and providing fast response time, a two-tier DBMS is proposed. The cold-data which does not require fast response times are managed by disk storage manager, and the hot-data which require fast response time among the large volumes of data are handled by memory storage manager as snapshots. As a result, the proposed system performs significantly better than diskoriented DBMS with an added advantage to manage massive data at the same time.','10.3745/JIPS.2008.4.1.009',584,719,0,0,NULL,NULL),(65,2008,4,1,17,0,'Inverted Index based Modified Version of KNN for Text Categorization','String Vector, K- Nearest Neighbor, Text Categorization','Taeho Jo','dlibrary/JIPS_v04_no1_paper3.pdf','This research proposes a new strategy where documents are encoded into string vectors and modified version of KNN to be adaptable to string vectors for text categorization. Traditionally, when KNN are used for pattern classification, raw data should be encoded into numerical vectors. This encoding may be difficult, depending on a given application area of pattern classification. For example, in text categorization, encoding full texts given as raw data into numerical vectors leads to two main problems: huge dimensionality and sparse distribution. In this research, we encode full texts into string vectors, and modify the supervised learning algorithms adaptable to string vectors for text categorization.','10.3745/JIPS.2008.4.1.017',571,264,0,0,NULL,NULL),(66,2008,4,1,27,0,'An Empirical Study of Qualities of Association Rules from a Statistical View Point','Data Mining, Association Rule Mining, Rule Evaluation, Chi-square Test','Maryann Dorn, Wen-Chi Hou, Dunren Che, and Zhewei Jiang','dlibrary/JIPS_v04_no1_paper4.pdf','Minimum support and confidence have been used as criteria for generating association rules in all association rule mining algorithms. These criteria have their natural appeals, such as simplicity; few researchers have suspected the quality of generated rules. In this paper, we examine the rules from a more rigorous point of view by conducting statistical tests. Specifically, we use contingency tables and chi-square test to analyze the data. Experimental results show that one third of the association rules derived based on the support and confidence criteria are not significant, that is, the antecedent and consequent of the rules are not correlated. It indicates that minimum support and minimum confidence do not provide adequate discovery of meaningful associations. The chi-square test can be considered as an enhancement or an alternative solution.','10.3745/JIPS.2008.4.1.027',573,530,0,0,NULL,NULL),(67,2008,4,1,33,0,'An Experiment of Traceability-Driven System Testing','Software Engineering, Software Testing, Traceability, UML-based Testing','Eun Man Choi and Kwang-Ik Seo','dlibrary/JIPS_v04_no1_paper5.pdf','Traceability has been held as an important factor in testing activities as well as modeldriven development. Vertical traceability affords us opportunities to improve manageability from models and test cases to a code in testing and debugging phase. This paper represents a vertical test method which connects a system test level and an integration test level in testing stage by using UML. An experiment how traceability works to effectively focus on error spots has been included by using concrete examples of tracing from models to the code.','10.3745/JIPS.2008.4.1.033',600,563,0,0,NULL,NULL),(68,2008,4,2,41,0,'MMMP: A MAC Protocol to Ensure QoS for Multimedia Traffic over Multi-hop Ad Hoc Networks','Medium Access Control, MAC, Ad Hoc Networks, Multi Hop, QoS, Multimedia','Sunil Kumar, Mahasweta Sarkar, Supraja Gurajala, and John D. Matyjas','dlibrary/JIPS_v04_no2_paper1.pdf','In this paper, we discuss a novel reservation-based, asynchronous MAC protocol called¡®Multi-rate Multi-hop MAC Protocol¡¯ (MMMP) for multi-hop ad hoc networks that provides QoS guarantees for multimedia traffic. MMMP achieves this by providing service differentiation for multirate real-time traffic (both constant and variable bit rate traffic) and guaranteeing a bounded end-to-end delay for the same while still catering to the throughput requirements of non real time traffic. In addition, it administers bandwidth preservation via a feature called ¡®Smart Drop¡¯ and implements efficient bandwidth usage through a mechanism called ¡®Release Bandwidth¡¯. Simulation results on the QualNet simulator indicate that MMMP outperforms IEEE 802.11 on all performance metrics and can efficiently handle a large range of traffic intensity. It also outperforms other similar state-of-the-art MAC protocols.','10.3745/JIPS.2008.4.2.041',735,303,0,0,NULL,NULL),(69,2008,4,2,53,0,'An Autonomic <K, D>-Interleaving Registry Overlay Network for Efficient Ubiquities Web Services Discovery Service','Ubiquities Web Service Discovery Service, Registry Overlay Network P2P.','Khaled Ragab','dlibrary/JIPS_v04_no2_paper2.pdf','The Web Services infrastructure is a distributed computing environment for service-sharing. Mechanisms for Web services Discovery proposed so far have assumed a centralized and peer-to-peer (P2P) registry. A discovery service with centralized architecture, such as UDDI, restricts the scalability of this environment, induces performance bottleneck and may result in single points of failure. A discovery service with P2P architecture enables a scalable and an efficient ubiquities web service discovery service that needs to be run in self-organized fashions. In this paper, we propose an autonomic -interleaving Registry Overlay Network (RgON) that enables web-services¡¯ providers/consumers to publish/discover services¡¯ advertisements, WSDL documents. The RgON, doubtless empowers consumers to discover web services associated with these advertisements within constant D logical hops over constant K physical hops with reasonable storage and bandwidth utilization as shown through simulation.','10.3745/JIPS.2008.4.2.053',542,321,0,0,NULL,NULL),(70,2008,4,2,61,0,'Developing Protege Plug-in: OWL Ontology Visualization using Social Network','OWL visualization, Protege, Protege plug-in','Minsoo Kim and Minkoo Kim','dlibrary/JIPS_v04_no2_paper3.pdf','In recent years, numerous studies have been attempted to exploit ontology in the area of ubiquitous computing. Especially, some kinds of ontologies written in OWL are proposed for major issues in ubiquitous computing such like context-awareness. OWL is recommended by W3C as a descriptive language for representing ontology with rich vocabularies. However, developers struggle to design ontology using OWL, because of the complex syntax of OWL. The research for OWL visualization aims to overcome this problem, but most of the existing approaches unfortunately do not provide efficient interface to visualize OWL ontology. Moreover, as the size of ontology grows bigger, each class and relation are difficult to represent on the editing window due to the small size limitation of screen. In this paper, we present OWL visualization scheme that supports class information in detail. This scheme is based on concept of social network, and we implement OWL visualization plug-in on Protégé that is the most famous ontology editor.','10.3745/JIPS.2008.4.2.061',541,680,0,0,NULL,NULL),(71,2008,4,2,67,0,'Inverted Index based Modified Version of K-Means Algorithm for Text Clustering','String Vector, K Means Algorithm, Text Clustering','Taeho Jo','dlibrary/JIPS_v04_no2_paper4.pdf','This research proposes a new strategy where documents are encoded into string vectors and modified version of k means algorithm to be adaptable to string vectors for text clustering. Traditionally, when k means algorithm is used for pattern classification, raw data should be encoded into numerical vectors. This encoding may be difficult, depending on a given application area of pattern classification. For example, in text clustering, encoding full texts given as raw data into numerical vectors leads to two main problems: huge dimensionality and sparse distribution. In this research, we encode full texts into string vectors, and modify the k means algorithm adaptable to string vectors for text clustering.','10.3745/JIPS.2008.4.2.067',595,601,0,0,NULL,NULL),(72,2008,4,2,77,0,'Neural Text Categorizer for Exclusive Text Categorization','Disk Neural Text Categorizer, Text Categorization, NewsPage.com','Taeho Jo','dlibrary/JIPS_v04_no2_paper5.pdf','This research proposes a new neural network for text categorization which uses alternative representations of documents to numerical vectors. Since the proposed neural network is intended originally only for text categorization, it is called NTC (Neural Text Categorizer) in this research. Numerical vectors representing documents for tasks of text mining have inherently two main problems: huge dimensionality and sparse distribution. Although many various feature selection methods are developed to address the first problem, the reduced dimension remains still large. If the dimension is reduced excessively by a feature selection method, robustness of text categorization is degraded. Even if SVM (Support Vector Machine) is tolerable to huge dimensionality, it is not so to the second problem. The goal of this research is to address the two problems at same time by proposing a new representation of documents and a new neural network using the representation for its input vector.','10.3745/JIPS.2008.4.2.077',501,506,0,0,NULL,NULL),(73,2008,4,3,87,0,'Analysis of Handover Latency for Mobile IPv6 and mSCTP','Mobile IPv6, mSCTP, handover latency, vertical handover, horizontal handover','Dong-Phil Kim and Seok-Joo Koh','dlibrary/JIPS_v04_no3_paper1.pdf','This paper analyzes the handover latency of Mobile IP and mobile SCTP over IPv6 networks. The analytical results are compared with the performance by experiment over Linux testbed. For analysis, we consider the two handover scenarios: horizontal handover and vertical handover. From the results, we see that mSCTP can provide smaller handover latency than Mobile IP. Moreover, mSCTP can give much smaller handover latency for vertical handover, compared to horizontal handover.','10.3745/JIPS.2008.4.3.087',647,515,0,0,NULL,NULL),(74,2008,4,3,97,0,'Comparison of Cultural Acceptability for Educational Robots between Europe and Korea','Cultural Acceptability, Educational Robot, Identification, Robot Contents','Jonghong Choi, Jongyun Lee and Jeonghye Han','dlibrary/JIPS_v04_no3_paper2.pdf','Europeans are much more rigid in their thinking on robots and especially have a negative view on robots as peers since they regard robots as labor machines. Recently, Korea invented several educational robots as peer tutors. Therefore, study was needed to determine the difference in cultural acceptability for educational robots between Korea and Europe (Spain). We found that Europe seems to be much more rigid in its thinking on robots and especially has a negative view on educational robots. Korean parents have a strong tendency to see robots as \'the friend of children,\' while on the other hand, European parents tend to see educational robots as \'machines or electronics\'. Meanwhile, the expectation of children on educational robots showing identification content was higher in Europe than in Korea since European children are familiar with costume parties. This result implied that we may find a Korean market for educational robots earlier than a European market, but European children will be eager to play with educational robots even though their parents have a negative view of them.','10.3745/JIPS.2008.4.3.97',587,314,0,0,NULL,NULL),(75,2008,4,3,103,0,'Policy Adjuster-driven Grid Workflow Management for Collaborative Heart Disease Identification System','Grid Worfklow, Collaborative Healthcare Platform, SLA, Policy Adjuster','Shengzhong Deng, Chan-Hyun Youn, Qi Liu, Hoe Young Kim, Taoran Yu and Young Hun Kim','dlibrary/JIPS_v04_no3_paper3.pdf','This paper proposes a policy adjuster-driven Grid workflow management system for collaborative healthcare platform, which supports collaborative heart disease diagnosis applications. To select policies according to service level agreement of users and dynamic resource status, we devised a policy adjuster to handle workflow management polices and resource management policies using policy decision scheme. We implemented this new architecture with workflow management functions based on policy quorum based resource management system for providing poincare geometrycharacterized ECG analysis and virtual heart simulation service. To evaluate our proposed system, we executed a heart disease identification application in our system and compared the performance to that of the general workflow system and PQRM system under different types of SLA.','10.3745/JIPS.2008.4.3.103',609,388,0,0,NULL,NULL),(76,2008,4,3,113,0,'Decision of Abnormal Quality Unit Lists from Claim Database','Claim, Production, Abnormal Quality, Decision Support','Sang-Hyun Lee, Sang-joon Lee, Kyung-li Moon and Byung-Ki Kim','dlibrary/JIPS_v04_no3_paper4.pdf','Most enterprises have controlled claim data related to marketing, production, trade and delivery. They can extract the engineering information needed to the reliability of unit from the claim data, and also detect critical and latent reliability problems. Existing method which could detect abnormal quality unit lists in early stage from claim database has three problems: the exclusion of fallacy probability in claim, the false occurrence of claim fallacy alarm caused by not reflecting inventory information and too many excessive considerations of claim change factors. In this paper, we propose a process and methods extracting abnormal quality unit lists to solve three problems of existing method. Proposed one includes data extraction process for reliability measurement, the calculation method of claim fallacy alarm probability, the method for reflecting inventory time in calculating claim reliability and the method for identification of abnormal quality unit lists. This paper also shows that proposed mechanism could be effectively used after analyzing improved effects taken from automotive company\'s claim data adaptation for two years.','10.3745/JIPS.2008.4.3.113',537,388,0,0,NULL,NULL),(77,2008,4,4,121,0,'Tester Structure Expression Language and Its Application to the Environment for VLSI Tester Program Development','VLST test, VLSI tester, ATE, tester language, GTL, Tester selection tool','Masayuki Sato, Hiroki Wakamatsu, Masayuki Arai, Kenichi Ichino, Kazuhiko Iwasaki and Takeshi Asakawa','dlibrary/JIPS_v04_no4_paper1.pdf','VLSI chips have been tested using various automatic test equipment (ATE). Although each ATE has a similar structure, the language for ATE is proprietary and it is not easy to convert a test program for use among different ATE vendors. To address this difficulty we propose a tester structure expression language, a tester language with a novel format. The developed language is called the general tester language (GTL). Developing an interpreter for each tester, the GTL program can be directly applied to the ATE without conversion. It is also possible to select a cost-effective ATE from the test program, because the program expresses the required ATE resources, such as pin counts, measurement accuracy, and memory capacity. We describe the prototype environment for the GTL and the tester selection tool. The software size of the prototype is approximately 27,800 steps and 15 manmonths were required. Using the tester selection tool, the number of man-hours required in order to select an ATE could be reduced to 1/10. A GTL program was successfully executed on actual ATE.','10.3745/JIPS.2008.4.4.121',871,1016,0,0,NULL,NULL),(78,2008,4,4,133,0,'Eager Data Transfer Mechanism for Reducing Communication Latency in User-Level Network Protocols','Data Transfer, Cache Coherence, User-Level, Low-Latency, Network Protocols, Message, VIA','Chulho Won, Ben Lee, Kyoung Park and Myung-Joon Kim','dlibrary/JIPS_v04_no4_paper2.pdf','Clusters have become a popular alternative for building high-performance parallel computing systems. Today¡¯s high-performance system area network (SAN) protocols such as VIA and IBA significantly reduce user-to-user communication latency by implementing protocol stacks outside of operating system kernel. However, emerging parallel applications require a significant improvement in communication latency. Since the time required for transferring data between host memory and network interface (NI) make up a large portion of overall communication latency, the reduction of data transfer time is crucial for achieving low-latency communication. In this paper, Eager Data Transfer (EDT) mechanism is proposed to reduce the time for data transfers between the host and network interface. The EDT employs cache coherence interface hardware to directly transfer data between the host and NI. An EDT-based network interface was modeled and simulated on the Linux-based, complete system simulation environment, Linux/SimOS. Our simulation results show that the EDT approach significantly reduces the data transfer time compared to DMA-based approaches. The EDTbased NI attains 17% to 38% reduction in user-to-user message time compared to the cache-coherent DMA-based NIs for a range of message sizes (64 bytes ~ 4 Kbytes) in a SAN environment.','10.3745/JIPS.2008.4.4.133',896,721,0,0,NULL,NULL),(79,2008,4,4,145,0,'Mobility Management Survey for Home-eNB Based 3GPP LTE Systems','Home-eNB, 3GPP LTE (Long Term Evolution), Mobility Management','Hyoungwon Kwak, Poongup Lee, Yohan Kim, Navrati Saxena and Jitae Shin','dlibrary/JIPS_v04_no4_paper3.pdf','The specification of the Home Evolved NodeB (Home-eNB), which is a small base station designed for use in residential or small business environment, is currently ongoing in 3GPP LTE (Long Term Evolution) systems. One of the key requirements for its feasibility in the LTE system is the mobility management in the deployment of the numerous Home-eNBs and other 3GPP network. In this paper, we overview the characteristic of Home-eNB and also describe the mobility management issues and the related approaches in 3GPP LTE based Home-eNB systems.','10.3745/JIPS.2008.4.4.145',825,592,0,0,NULL,NULL),(80,2008,4,4,153,0,'Geometric Fitting of Parametric Curves and Surfaces','Parametric Curve, Parametric Surface, Space Curve, Curve Fitting, Surface Fitting, Geometric Fitting, Geometric Distance, Least-Squares Approximation, Minimization, Parametric Model Recovery, Object Reconstruction','Sung Joon Ahn','dlibrary/JIPS_v04_no4_paper4.pdf','This paper deals with the geometric fitting algorithms for parametric curves and surfaces in 2-D/3-D space, which estimate the curve/surface parameters by minimizing the square sum of the shortest distances between the curve/surface and the given points. We identify three algorithmic approaches for solving the nonlinear problem of geometric fitting. As their general implementation we describe a new algorithm for geometric fitting of parametric curves and surfaces. The curve/surface parameters are estimated in terms of form, position, and rotation parameters. We test and evaluate the performances of the algorithms with fitting examples.','10.3745/JIPS.2008.4.4.153',854,1739,0,0,NULL,NULL),(81,2008,4,4,159,0,'Comparative Study on the Educational Use of Home Robots for Children','Human-Computer Interaction, Human-Robot Interaction, e-Learning, Educational Media, r-Learning, Web-Based Instruction','Jeonghye Han, Miheon Jo, Vicki Jones and Jun H Jo','dlibrary/JIPS_v04_no4_paper5.pdf','Human-Robot Interaction (HRI), based on already well-researched Human-Computer Interaction (HCI), has been under vigorous scrutiny since recent developments in robot technology. Robots may be more successful in establishing common ground in project-based education or foreign language learning for children than in traditional media. Backed by its strong IT environment and advances in robot technology, Korea has developed the world¡¯s first available e-Learning home robot. This has demonstrated the potential for robots to be used as a new educational media - robot-learning, referred to as ¡®r-Learning¡¯. Robot technology is expected to become more interactive and user-friendly than computers. Also, robots can exhibit various forms of communication such as gestures, motions and facial expressions. This study compared the effects of non-computer based (NCB) media (using a book with audiotape) and Web-Based Instruction (WBI), with the effects of Home Robot-Assisted Learning (HRL) for children. The robot gestured and spoke in English, and children could touch its monitor if it did not recognize their voice command. Compared to other learning programs, the HRL was superior in promoting and improving children¡¯s concentration, interest, and academic achievement. In addition, the children felt that a home robot was friendlier than other types of instructional media. The HRL group had longer concentration spans than the other groups, and the p-value demonstrated a significant difference in concentration among the groups. In regard to the children¡¯s interest in learning, the HRL group showed the highest level of interest, the NCB group and the WBI group came next in order. Also, academic achievement was the highest in the HRL group, followed by the WBI group and the NCB group respectively. However, a significant difference was also found in the children¡¯s academic achievement among the groups. These results suggest that home robots are more effective as regards children¡¯s learning concentration, learning interest and academic achievement than other types of instructional media (such as: books with audiotape and WBI) for English as a foreign language.','10.3745/JIPS.2008.4.4.159',983,369,0,0,NULL,NULL),(82,2009,5,1,1,0,'A New Variational Level Set Evolving Algorithm for Image Segmentation','Level Set Methods, Evolving Algorithm, without Re-initialization, Image Segmentation','Yang Fei and Jong Won Park','dlibrary/JIPS_v05_no1_paper1.pdf','Level set methods are the numerical techniques for tracking interfaces and shapes. They have been successfully used in image segmentation. A new variational level set evolving algorithm without re-initialization is presented in this paper. It consists of an internal energy term that penalizes deviations of the level set function from a signed distance function, and an external energy term that drives the motion of the zero level set toward the desired image feature. This algorithm can be easily implemented using a simple finite difference scheme. Meanwhile, not only can the initial contour can be shown anywhere in the image, but the interior contours can also be automatically detected.','10.3745/JIPS.2009.5.1.001',593,294,0,0,NULL,NULL),(83,2009,5,1,5,0,'SVD-LDA: A Combined Model for Text Classification','Latent Dirichlet Allocation, Singular Value Decomposition, Input Filtering, Text Classification, Data Preprocessing.','Nguyen Cao Truong Hai, Kyung-Im Kim and Hyuk-Ro Park','dlibrary/JIPS_v05_no1_paper2.pdf','Text data has always accounted for a major portion of the world¡¯s information. As the volume of information increases exponentially, the portion of text data also increases significantly. Text classification is therefore still an important area of research. LDA is an updated, probabilistic model which has been used in many applications in many other fields. As regards text data, LDA also has many applications, which has been applied various enhancements. However, it seems that no applications take care of the input for LDA. In this paper, we suggest a way to map the input space to a reduced space, which may avoid the unreliability, ambiguity and redundancy of individual terms as descriptors. The purpose of this paper is to show that LDA can be perfectly performed in a ¡°clean and clear¡± space. Experiments are conducted on 20 News Groups data sets. The results show that the proposed method can boost the classification results when the appropriate choice of rank of the reduced space is determined.','10.3745/JIPS.2009.5.1.005',677,756,0,0,NULL,NULL),(84,2009,5,1,11,0,'An Efficient Web Ontology Storage Considering Hierarchical Knowledge for Jena-based Applications','Ontology, Jena, OWL, Ontology, Storage, Hierarchical Structure','Dongwon Jeong, Heeyoung Shin, Doo-Kwon Baik and Young-Sik Jeong','dlibrary/JIPS_v05_no1_paper3.pdf','As well as providing various APIs for the development of inference engines and storage models, Jena is widely used in the development of systems or tools related with Web ontology management. However, Jena still has several problems with regard to the development of real applications, one of the most important being that its query processing performance is unacceptable. This paper proposes a storage model to improve the query processing performance of the original Jena storage. The proposed storage model semantically classifies OWL elements, and stores an ontology in separately classified tables according to the classification. In particular, the hierarchical knowledge is managed, which can make the processing performance of inferable queries enhanced and stores information. It enhances the query processing performance by using hierarchical knowledge. For this paper an experimental evaluation was conducted, the results of which showed that the proposed storage model provides a improved performance compared with Jena.','10.3745/JIPS.2009.5.1.011',617,273,0,0,NULL,NULL),(85,2009,5,1,19,0,'Privacy-Aware Adaptable Web Services Using Petri Nets','Privacy, Web Service, Petri Net, Context Framework','You-Jin Song and Jae-Geol Yim','dlibrary/JIPS_v05_no1_paper4.pdf','Many researchers have developed frameworks that are capable of handling context information and can be adapted and used by any Web service. However, no research involving the systematic analysis of existing frameworks has yet been conducted. This paper examines the Context Framework, an example of existing frameworks, using a Petri net, and analyzes its advantages and disadvantages. Then, a Petri net model – with its disadvantages removed - is introduced, and a new framework is presented on the basis of that model. The proposed PAWS (Privacy Aware Web Services) framework has a expandability for context management and communicates flexible context information for every session. The proposed framework can solve overhead problems of context in SOAP messages. It also protects user privacy according to user preferences.','10.3745/JIPS.2009.5.1.019',488,273,0,0,NULL,NULL),(86,2009,5,1,25,0,'Implementation of Advanced IP Network Technology for IPTV Service','IPTV, Premium Backbone, QoS, Multicast, High Availability, Security','Young-Do Joo','dlibrary/JIPS_v05_no1_paper5.pdf','It is absolutely essential to implement advanced IP network technologies such as QoS, Multicast, High Availability, and Security in order to provide real-time services like IPTV via IP backbone network. In reality, the existing commercial networks of internet service providers are subject to certain technical difficulties and limitations in embodying those technologies. On-going research efforts involve the experimental engineering works and implementation experience to trigger IPTV service on the premium-level IP backbone which has recently been developed. This paper introduces the core network technologies that will enable the deployment of a high-quality IPTV service, and then proposes a suitable methodology for application and deployment policies on each technology to lead the establishment and globalization of the IPTV service.','10.3745/JIPS.2009.5.1.025',628,821,0,0,NULL,NULL),(87,2009,5,1,33,0,'Dynamic Control of Random Constant Spreading Worm using Depth Distribution Characteristics','Worm, Random Constant Spreading, Dynamic Network, Depth Distribution Characteristic, Bandwidth Control','Byung-Gyu No, Doo-Soon Park, Min Hong, HwaMin Lee and Yoon Sok Park','dlibrary/JIPS_v05_no1_paper6.pdf','Ever since the network-based malicious code commonly known as a \'worm\' surfaced in the early part of the 1980\'s, its prevalence has grown more and more. The RCS (Random Constant Spreading) worm has become a dominant, malicious virus in recent computer networking circles. The worm retards the availability of an overall network by exhausting resources such as CPU capacity, network peripherals and transfer bandwidth, causing damage to an uninfected system as well as an infected system. The generation and spreading cycle of these worms progress rapidly. The existing studies to counter malicious code have studied the Microscopic Model for detecting worm generation based on some specific pattern or sign of attack, thus preventing its spread by countering the worm directly on detection. However, due to zero-day threat actualization, rapid spreading of the RCS worm and reduction of survival time, securing a security model to ensure the survivability of the network became an urgent problem that the existing solution-oriented security measures did not address. This paper analyzes the recently studied efficient dynamic network. Essentially, this paper suggests a model that dynamically controls the RCS worm using the characteristics of Power-Law and depth distribution of the delivery node, which is commonly seen in preferential growth networks. Moreover, we suggest a model that dynamically controls the spread of the worm using information about the depth distribution of delivery. We also verified via simulation that the load for each node was minimized at an optimal depth to effectively restrain the spread of the worm.','10.3745/JIPS.2009.5.1.033',649,554,0,0,NULL,NULL),(88,2009,5,2,41,0,'A Survey of Face Recognition Techniques','Face Recognition, Person Identification, Biometrics','Rabia Jafri and Hamid R Arabnia','dlibrary/JIPS_v05_no2_paper1.pdf','Face recognition presents a challenging problem in the field of image analysis and computer vision, and as such has received a great deal of attention over the last few years because of its many applications in various domains. Face recognition techniques can be broadly divided into three categories based on the face data acquisition methodology: methods that operate on intensity images; those that deal with video sequences; and those that require other sensory data such as 3D information or infra-red imagery. In this paper, an overview of some of the well-known methods in each of these categories is provided and some of the benefits and drawbacks of the schemes mentioned therein are examined. Furthermore, a discussion outlining the incentive for using face recognition, the applications of this technology, and some of the difficulties plaguing current systems with regard to this task has also been provided. This paper also mentions some of the most recent algorithms developed for this purpose and attempts to give an idea of the state of the art of face recognition technology.','10.3745/JIPS.2009.5.2.041',3590,952,1,0,NULL,NULL),(89,2009,5,2,69,0,'Autonomic Self Healing-Based Load Assessment for Load Division in OKKAM Backbone Cluster','Self Healing Systems, Load Estimation and Balancing, OKKAM, Entity Naming System','Junaid Ahsenali Chaudhry','dlibrary/JIPS_v05_no2_paper2.pdf','Self healing systems are considered as cognation-enabled sub form of fault tolerance system. But our experiments that we report in this paper show that self healing systems can be used for performance optimization, configuration management, access control management and bunch of other functions. The exponential complexity that results from interaction between autonomic systems and users (software and human users) has hindered the deployment and user of intelligent systems for a while now. We show that if that exceptional complexity is converted into self-growing knowledge (policies in our case), can make up for initial development cost of building an intelligent system. In this paper, we report the application of AHSEN (Autonomic Healing-based Self management Engine) to in OKKAM Project infrastructure backbone cluster that mimics the web service based architecture of u-Zone gateway infrastructure. The ¡®blind¡¯ load division on per-request bases is not optimal for distributed and performance hungry infrastructure such as OKKAM. The approach adopted assesses the active threads on the virtual machine and does resource estimates for active processes. The availability of a certain server is represented through worker modules at load server. Our simulation results on the OKKAM infrastructure show that the self healing significantly improves the performance and clearly demarcates the logical ambiguities in contemporary designs of self healing infrastructures proposed for large scale computing infrastructures.','10.3745/JIPS.2009.5.2.069',461,586,0,0,NULL,NULL),(90,2009,5,2,77,0,'A Scalable Wireless Body Area Network for Bio-Telemetry','Body Area Network, Plug-and-Play Biosensors, Telemedicine, Ubiquitous Computing, ECG Monitoring, ECG Feature Extraction','Adnan Saeed, Miad Faezipour, Mehrdad Nourani, Subhash Banerjee, Gil Lee, Gopal Gupta and Lakshman Tamil','dlibrary/JIPS_v05_no2_paper3.pdf','In this paper, we propose a framework for the real-time monitoring of wireless biosensors. This is a scalable platform that requires minimum human interaction during set-up and monitoring. Its main components include a biosensor, a smart gateway to automatically set up the body area network, a mechanism for delivering data to an Internet monitoring server, and automatic data collection, profiling and feature extraction from bio-potentials. Such a system could increase the quality of life and significantly lower healthcare costs for everyone in general, and for the elderly and those with disabilities in particular.','10.3745/JIPS.2009.5.2.077',639,300,0,0,NULL,NULL),(91,2009,5,2,87,0,'Bidding Strategically for Scheduling in Grid Systems','Grid Computing, Grid Scheduling, Resource Allocation, Auction Model','Babak-Naddaf and Jafar-Habibi','dlibrary/JIPS_v05_no2_paper4.pdf','Grid computing is a new technology which involves efforts to create a huge source of processing power by connecting computational resources throughout the world. The key issue of such environments is their resource allocation and the appropriate job scheduling strategy. Several approaches to scheduling in these environments have been proposed to date. Market driven scheduling as a decentralized solution for such complicated environments has introduced new challenges. In this paper the bidding problem with regard to resources in the reverse auction resource allocation model has been investigated and the new bidding strategies have been proposed and investigated.','10.3745/JIPS.2009.5.2.087',550,387,0,0,NULL,NULL),(92,2009,5,2,97,0,'Differentiated Services Based Admission Control and Multi Path Routing Algorithm for IPv6','Differentiated Services (DiffServ), Admission Control, IPv6, QoS Routing, QoS Architecture','Muhammad Omer Farooq and Sadia Aziz','dlibrary/JIPS_v05_no2_paper5.pdf','In this paper we propose a Differentiated Services Based Admission Control and Routing Algorithm for IPv6 (ACMRA). The basic DiffServ architecture lacks an admission control mechanism, the injection of more QoS sensitive traffic into the network can cause congestion at the core of the network. Our Differentiated Services Based Admission Control and Routing Algorithm for IPv6 combines the admission control phase with the route finding phase, and our routing protocol has been designed in a way to work alongside DiffServ based networks. The Differentiated Services Based Admission Control and Routing Algorithm for IPv6 constructs label switched paths in order to provide rigorous QoS provisioning. We have conducted extensive simulations to validate the effectiveness and efficiency of our proposed admission control and routing algorithm. Simulation Results show that the Differentiated Services Based Admission Control and Routing Algorithm for IPv6 provides an excellent packet delivery ratio, reduces the control packets¡¯ overhead, and makes use of the resources present on multiple paths to the destination network, while almost each admitted flow shows compliance with its Service Level Agreement.','10.3745/JIPS.2009.5.2.097',628,355,0,0,NULL,NULL),(93,2009,5,2,105,0,'GPU-based Stereo Matching Algorithm with the Strategy of Population-based Incremental Learning','Image filtering, Performance Evaluation, General-Purpose Computation Based on GPU, GPU, Population-Based Incremental Learning','Dong-Hu Nie, Kyu-Phil Han and Heng-Suk Lee','dlibrary/JIPS_v05_no2_paper6.pdf','To solve the general problems surrounding the application of genetic algorithms in stereo matching, two measures are proposed. Firstly, the strategy of simplified population-based incremental learning (PBIL) is adopted to reduce the problems with memory consumption search inefficiency£¬and a scheme for controlling the distance of neighbors for disparity smoothness is inserted to obtain a wide-area consistency of disparities. In addition, an alternative version of the proposed algorithm, without the use of a probability vector, is also presented for simpler set-ups. Secondly, programmable graphics-hardware (GPU) consists of multiple multi-processors and has a powerful parallelism which can perform operations in parallel at low cost. Therefore, in order to decrease the running time further, a model of the proposed algorithm, which can be run on programmable graphics-hardware (GPU), is presented for the first time. The algorithms are implemented on the CPU as well as on the GPU and are evaluated by experiments. The experimental results show that the proposed algorithm offers better performance than traditional BMA methods with a deliberate relaxation and its modified version in terms of both running speed and stability. The comparison of computation times for the algorithm both on the GPU and the CPU shows that the former has more speed-up than the latter, the bigger the image size is.','10.3745/JIPS.2009.5.2.105',604,466,0,0,NULL,NULL),(94,2009,5,3,117,0,'Providing Efficient Secured Mobile IPv6 by SAG and Robust Header Compression','SAG, RoHC, MIPv6, Handoff Latency, Early Binding Update','Tin-Yu Wu, Han-Chieh Chao and Chi-Hsiang Lo','dlibrary/JIPS_v05_no3_paper1.pdf','By providing ubiquitous Internet connectivity, wireless networks offer more convenient ways for users to surf the Internet. However, wireless networks encounter more technological challenges than wired networks, such as bandwidth, security problems, and handoff latency. Thus, this paper proposes new technologies to solve these problems. First, a Security Access Gateway (SAG) is proposed to solve the security issue. Originally, mobile terminals were unable to process high security calculations because of their low calculating power. SAG not only offers high calculating power to encrypt the encryption demand of SAG¡¯s domain, but also helps mobile terminals to establish a multiple safety tunnel to maintain a secure domain. Second, Robust Header Compression (RoHC) technology is adopted to increase the utilization of bandwidth. Instead of Access Point (AP), Access Gateway (AG) is used to deal with the packet header compression and de-compression from the wireless end. AG¡¯s high calculating power is able to reduce the load on AP. In the original architecture, AP has to deal with a large number of demands by header compression/de-compression from mobile terminals. Eventually, wireless networks must offer users ¡°Mobility¡± and ¡°Roaming¡±. For wireless networks to achieve ¡°Mobility¡± and ¡°Roaming,¡± we can use Mobile IPv6 (MIPv6) technology. Nevertheless, such technology might cause latency. Furthermore, how the security tunnel and header compression established before the handoff can be used by mobile terminals handoff will be another great challenge. Thus, this paper proposes to solve the problem by using Early Binding Updates (EBU) and Security Access Gateway (SAG) to offer a complete mechanism with low latency, low handoff mechanism calculation, and high security.','10.3745/JIPS.2009.5.3. 117',2818,847,2,0,NULL,NULL),(95,2009,5,3,131,0,'Principle of and Protection of Man-in-the-middle Attack Based on ARP Spoofing','Man-in-the-middle attack, ARP Spoofing, Session Hijack','Guo Hao and Guo Tao','dlibrary/JIPS_v05_no3_paper2.pdf','Man-in-the-middle attack is used wildly as a method of attacking the network. To discoverhow this type of attack works, this paper describes a method of man-in-the-middle attack based onARP spoofing, and proposes a method of preventing such attacks.','10.3745/JIPS.2009.5.3.131',489,591,0,0,NULL,NULL),(96,2009,5,3,135,0,'Study on Preemptive Real-Time Scheduling Strategy for Wireless Sensor Networks','Real-time Schedule, Wireless Sensor Networks, Two-level Priority, TinyOS, Dynamic Schedule','ZHAO Zhi-bin and GAO Fuxiang','dlibrary/JIPS_v05_no3_paper3.pdf','Most of the tasks in wireless sensor networks (WSN) are requested to run in a real-timeway. Neither EDF nor FIFO can ensure real-time scheduling in WSN. A real-time scheduling strategy(RTS) is proposed in this paper. All tasks are divided into two layers and endued diverse priorities.RTS utilizes a preemptive way to ensure hard real-time scheduling. The experimental results indicatethat RTS has a good performance both in communication throughput and over-load.','10.3745/JIPS.2009.5.3.135',550,627,0,0,NULL,NULL),(97,2009,5,3,145,0,'Topological Boundary Detection in Wireless Sensor Networks','Wireless sensor network, Hole, Boundary detection, 2-neighbor graph','Thanh Le Dinh','dlibrary/JIPS_v05_no3_paper4.pdf','The awareness of boundaries in wireless sensor networks has many benefits. The identification of boundaries is especially challenging since typical wireless sensor networks consist of low-capability nodes that are unaware of their geographic location. In this paper, we propose a simple, efficient algorithm to detect nodes that are near the boundary of the sensor field as well as near the boundaries of holes. Our algorithm relies purely on the connectivity information of the underlying communication graph and does not require any information on the location of nodes. We introduce the 2-neighbor graph concept, and then make use of it to identify nodes near boundaries. The results of our experiment show that our algorithm carries out the task of topological boundary detection correctly and efficiently.','10.3745/JIPS.2009.5.3.145',511,376,0,0,NULL,NULL),(98,2009,5,3,151,0,'Utility-based Rate Allocation Scheme for Mobile Video Streaming over Femtocell Networks','Utility, femtocell network, backhaul, cross-talk, video streaming','Shan Guo Quan, Jian Xu and Young Yong Kim','dlibrary/JIPS_v05_no3_paper5.pdf','This paper proposes a utility-based data rate allocation algorithm to provide high-quality mobile video streaming over femtocell networks. We first derive a utility function to calculate the optimal data rates for maximizing the aggregate utilities of all mobile users in the femtocell. The total sum of optimal data rates is limited by the link capacity of the backhaul connections. Furthermore, electromagnetic cross-talk poses a serious problem for the backhaul connections, and its influence passes on to mobile users, as well as causing data rate degradation in the femtocell networks. We also have studied a fixed margin iterative water-filling algorithm to achieve the target data rate of each backhaul connection as a counter-measure to the cross-talk problem. The results of our simulation show that the algorithm is capable of minimizing the transmission power of backhaul connections while guaranteeing a high overall quality of service for all users of the same binder. In particular, it can provide the target data rate required to maximize user satisfaction with the mobile video streaming service over the femtocell networks.','10.3745/JIPS.2009.5.3.151',571,294,0,0,NULL,NULL),(99,2009,5,3,159,0,'Automatic In-Text Keyword Tagging based on Information Retrieval','Automatic In-Text Keyword Tagging, Information Retrieval, Pattern Matching, Boyer-Moore-Horspool Algorithm, Keyword Dictionary, Cross-Referencing, in-text content link','Jinsuk Kim, Du-Seok Jin, KwangYoung Kim and Ho-Seop Choe','dlibrary/JIPS_v05_no3_paper6.pdf','As shown in Wikipedia, tagging or cross-linking through major keywords in a document collection improves not only the readability of documents but also responsive and adaptive navigation among related documents. In recent years, the Semantic Web has increased the importance of social tagging as a key feature of the Web 2.0 and, as its crucial phenotype, Tag Cloud has emerged to the public. In this paper we provide an efficient method of automated in-text keyword tagging based on large-scale controlled term collection or keyword dictionary, where the computational complexity of O(mN) – if a pattern matching algorithm is used – can be reduced to O(mlogN) – if an Information Retrieval technique is adopted – while m is the length of target document and N is the total number of candidate terms to be tagged. The result shows that automatic in-text tagging with keywords filtered by Information Retrieval','10.3745/JIPS.2009.5.3.159',610,315,0,0,NULL,NULL),(100,2009,5,4,167,0,'Black Bridge: A Scatternet Formation Algorithm for Solving a New Emerging Problem','Bluetooth, Statternet Formation, Bluetooth Communication Protocol','Minyi Guo, Yanqin Yang, Gongwei Zhang, Feilong Tang and Yao Shen','dlibrary/JIPS_v05_no4_paper1.pdf','Nowadays, it has become common to equip a device with Bluetooth. As such devices become pervasive in the world; much work has been done on forming them into a network, however, almost all the Bluetooth Scatternet Formation Algorithms assume devices are homogeneous. Even the exceptional algorithms barely mentioned a little about the different characteristics of devices like computational abilities, traffic loads for special nodes like bridge nodes or super nodes, which are usually the bottleneck in the scatternet. In this paper, we treat the devices differently not only based on the hardware characteristics, but also considering other conditions like different classes, different groups and so on. We use a two-phase Scatternet Formation Algorithm here: in the first phase, construct scatternets for a specified kind of devices; in the second phase, connect these scatternets by using least other kinds of devices as bridge nodes. Finally, we give some applications to show the benefit of classification.','10.3745/JIPS.2009.5.4.167',802,494,0,0,NULL,NULL),(101,2009,5,4,175,0,'On Effective Slack Reclamation in Task Scheduling for Energy Reduction','Scheduling, Energy Awareness, Green Computing, Dynamic Voltage and Frequency Scaling, Data Centers','Young Choon Lee and Albert Y Zomaya','dlibrary/JIPS_v05_no4_paper2.pdf','Power consumed by modern computer systems, particularly servers in data centers has almost reached an unacceptable level. However, their energy consumption is often not justifiable when their utilization is considered; that is, they tend to consume more energy than needed for their computing related jobs. Task scheduling in distributed computing systems (DCSs) can play a crucial role in increasing utilization; this will lead to the reduction in energy consumption. In this paper, we address the problem of scheduling precedence-constrained parallel applications in DCSs, and present two energyconscious scheduling algorithms. Our scheduling algorithms adopt dynamic voltage and frequency scaling (DVFS) to minimize energy consumption. DVFS, as an efficient power management technology, has been increasingly integrated into many recent commodity processors. DVFS enables these processors to operate with different voltage supply levels at the expense of sacrificing clock frequencies. In the context of scheduling, this multiple voltage facility implies that there is a trade-off between the quality of schedules and energy consumption. Our algorithms effectively balance these two performance goals using a novel objective function and its variant, which take into account both goals; this claim is verified by the results obtained from our extensive comparative evaluation study.','10.3745/JIPS.2009.5.4.175',797,364,0,0,NULL,NULL),(102,2009,5,4,187,0,'Design of Cryptographic Hardware Architecture for Mobile Computing','Trusted Computing, MTM, Cryptographic circuit, RSA, HASH, Mobile Computing','Mooseop Kim, Youngsae Kim and Hyunsook Cho','dlibrary/JIPS_v05_no4_paper3.pdf','This paper presents compact cryptographic hardware architecture suitable for the Mobile Trusted Module (MTM) that requires low-area and low-power characteristics. The built-in cryptographic engine in the MTM is one of the most important circuit blocks and contributes to the performance of the whole platform because it is used as the key primitive supporting digital signature, platform integrity and command authentication. Unlike personal computers, mobile platforms have very stringent limitations with respect to available power, physical circuit area, and cost. Therefore special architecture and design methods for a compact cryptographic hardware module are required. The proposed cryptographic hardware has a chip area of 38K gates for RSA and 12.4K gates for unified SHA-1 and SHA-256 respectively on a 0.25um CMOS process. The current consumption of the proposed cryptographic hardware consumes at most 3.96mA for RSA and 2.16mA for SHA computations under the 25MHz.','10.3745/JIPS.2009.5.4.187',826,838,0,0,NULL,NULL),(103,2009,5,4,197,0,'A Security Metrics Taxonomization Model for Software-Intensive Systems','Security Metrics, Security Objectives, Taxonomy, Correctness, Effectiveness, Efficiency','Reijo M Savola','dlibrary/JIPS_v05_no4_paper4.pdf','We introduce a novel high-level security metrics objective taxonomization model for softwareintensive systems. The model systematizes and organizes security metrics development activities. It focuses on the security level and security performance of technical systems while taking into account the alignment of metrics objectives with different business and other management goals. The model emphasizes the roles of security-enforcing mechanisms, the overall security quality of the system under investigation, and secure system lifecycle, project and business management. Security correctness, effectiveness and efficiency are seen as the fundamental measurement objectives, determining the directions for more detailed security metrics development. Integration of the proposed model with riskdriven security metrics development approaches is also discussed.','10.3745/JIPS.2009.5.4.197',813,344,0,0,NULL,NULL),(104,2009,5,4,207,0,'Dynamic Reservation Scheme of Physical Cell Identity for 3GPP LTE Femtocell Systems','Femtocell, Physical Cell Identity (PCI), Access Control, Long Term Evolution (LTE)','Poongup Lee, Jangkeun Jeong, Navrati Saxena and Jitae Shin','dlibrary/JIPS_v05_no4_paper5.pdf','TA large number of phone calls and data services will take place in indoor environments. In Long Term Evolution (LTE), femtocell, as a home base station for indoor coverage extension and wideband data service, has recently gained significant interests from operators and consumers. Since femtocell is frequently turned on and off by a personal owner, not by a network operator, one of the key issues is that femtocell should be identified autonomously without system information to support handover from macrocell to femtocell. In this paper, we propose a dynamic reservation scheme of Physical Cell Identities (PCI) for 3GPP LTE femtocell systems. There are several reserving types, and each type reserves a different number of PCIs for femtocell. The transition among the types depends on the deployed number of femtocells, or the number of PCI confusion events. Accordingly, flexible use of PCIs can decrease PCI confusion. This reduces searching time for femtocell, and it is helpful for the quick handover from macrocell to femtocell. Simulation results show that our proposed scheme reduces average delay for identifying detected cells, and increases network capacity within equal delay constraints.','10.3745/JIPS.2009.5.4.207',909,778,0,0,NULL,NULL),(105,2009,5,4,221,0,'Fault-tolerant ZigBee-based Automatic Meter Reading Infrastructure','AMR, AMI, Fault Tolerance, ZigBee','Kwang-il Hwang','dlibrary/JIPS_v05_no4_paper6.pdf','Due to low cost, low-power, and scalability, ZigBee is considered an efficient wireless AMR infrastructure. However, these characteristics of ZigBee can make the devices more vulnerable to unexpected error environments. In this paper, a fault-tolerant wireless AMR network (FWAMR) is proposed, which is designed to improve the robustness of the conventional ZigBee-based AMR systems by coping well with dynamic error environments. The experimental results demonstrate that the FWAMR is considerably fault-tolerant compared with the conventional ZigBee-based AMR network.','10.3745/JIPS.2009.5.4.221',796,395,0,0,NULL,NULL),(106,2009,5,4,229,0,'Spatial Query Processing Based on Minimum Bounding in Wireless Sensor Networks','Notification Message, Parent Selection Message, Spatial Query Process, Minimum Bounding Area','Sun Ok Yang and SungSuk Kim','dlibrary/JIPS_v05_no4_paper7.pdf','Sensors are deployed to gather physical, environmental data in sensor networks. Depending on scenarios, it is often assumed that it is difficult for batteries to be recharged or exchanged in sensors. Thus, sensors should be able to process users¡¯ queries in an energy-efficient manner. This paper proposes a spatial query processing scheme- Minimum Bounding Area Based Scheme. This scheme has a purpose to decrease the number of outgoing messages during query processing. To do that, each sensor has to maintain some partial information locally about the locations of descendent nodes.\r\nIn the initial setup phase, the routing path is established. Each child node delivers to its parent node the location information including itself and all of its descendent nodes. A parent node has to maintain several minimum bounding boxes per child node. This scheme can reduce unnecessary message propagations for query processing. Finally, the experimental results show the effectiveness of the proposed scheme.','10.3745/JIPS.2009.5.4.229',974,719,0,0,NULL,NULL),(107,2009,5,4,237,0,'A Geometrical Center based Two-way Search Heuristic Algorithm for Vehicle Routing Problem with Pickups and Deliveries','Vehicle Routing Problem, Heuristic Algorithm, Initial Solution','Kwangcheol Shin','dlibrary/JIPS_v05_no4_paper8.pdf','The classical vehicle routing problem (VRP) can be extended by including customers who want to send goods to the depot. This type of VRP is called the vehicle routing problem with pickups and deliveries (VRPPD). This study proposes a novel way to solve VRPPD by introducing a two-phase heuristic routing algorithm which consists of a clustering phase and uses the geometrical center of a cluster and route establishment phase by applying a two-way search of each route after applying the TSP algorithm on each route. Experimental results show that the suggested algorithm can generate better initial solutions for more computer-intensive meta-heuristics than other existing methods such as the giant-tour-based partitioning method or the insertion-based method.','10.3745/JIPS.2009.5.4.237',783,395,0,0,NULL,NULL),(108,2010,6,1,1,0,'TOSS: Telecom Operations Support Systems for Broadband Services','Operations Support System (OSS), New Generation Operations Systems and Software (NGOSS), enhanced Telecom Operations Map (eTOM), Internet Protocol Television (IPTV), IP-Virtual Private Network (IP-VPN)','Yuan-Kai Chen, Chang-Ping Hsu, Chung-Hua Hu, Rong-Syh Lin, Yi-Bing Lin, Jian-Zhi Lyu, Wudy Wu and Heychyi Young','dlibrary/JIPS_v06_no1_paper01.pdf','Due to the convergence of voice, data, and video, today’s telecom operators are facing the complexity of service and network management to offer differentiated value-added services that meet customer expectations. Without the operations support of well-developed Business Support System/Operations Support System (BSS/OSS), it is difficult to timely and effectively provide competitive services upon customer request. In this paper, a suite of NGOSS-based Telecom OSS (TOSS) is developed for the support of fulfillment and assurance operations of telecom services and IT services. Four OSS groups, TOSS-P (intelligent service provisioning), TOSS-N (integrated large-scale network management), TOSS-T (trouble handling and resolution), and TOSS-Q (end-to-end service quality management), are organized and integrated following the standard telecom operation processes (i.e., eTOM). We use IPTV and IP-VPN operation scenarios to show how these OSS groups co-work to support daily business operations with the benefits of cost reduction and revenue acceleration.','10.3745/JIPS.2010.6.1.001',3001,7430,3,0,NULL,NULL),(109,2010,6,1,21,0,'A Hybrid Approach for Regression Testing in Interprocedural Program','Regression Testing, Test Prioritization, Test Selection, Interprocedural','Yogesh Singh, Arvinder Kaur and Bharti Suri','dlibrary/JIPS_v06_no1_paper02.pdf','Software maintenance is one of the major activities of the software development life cycle. Due to the time and cost constraint it is not possible to perform exhaustive regression testing. Thus, there is a need for a technique that selects and prioritizes the effective and important test cases so that the testing effort is reduced. In an analogous study we have proposed a new variable based algorithm that works on variables using the hybrid technique. However, in the real world the programs consist of multiple modules. Hence, in this work we propose a regression testing algorithm that works on interprocedural programs. In order to validate and analyze this technique we have used various programs. The result shows that the performance and accuracy of this technique is very high.\r\n\r\n','10.3745/JIPS.2010.6.1.021',631,318,0,0,NULL,NULL),(110,2010,6,1,33,0,'GML Map Visualization on Mobile Devices','Map Visualization, DXF, DWG, SHP, GML, POI, Trace Monitoring','Eun-Ha Song and Young-Sik Jeong','dlibrary/JIPS_v06_no1_paper03.pdf','GIS can only be applied to certain areas by storing format. It is subordinate to a system when displaying geographic information data. It is therefore inevitable for GIS to use GML that supports efficient usage of various geographic information data and interoperability for integration and sharing. The paper constructs VisualGML that translates currently-used geographic information such as DXF (Drawing Exchange Format), DWG (DraWinG), or SHP (Shapefile) into GML format for visualization. VisualGML constructs an integrated map pre-process module, which filters geographic information data according to its tag and properties, to provide the flexibility of a mobile device. VisualGML also provides two major GIS services for the user and administrator. It can enable visualizing location search. This is applied with a 3-Layer POI structure for the user. It has trace monitoring visualization through moving information of mobile devices for the administrator.\r\n\r\n','10.3745/JIPS.2010.6.1.033',687,448,0,0,NULL,NULL),(111,2010,6,1,43,0,'Cryptanalysis on a Three Party Key Exchange Protocol-STPKE`','STPKE’ Protocol, The Proposed Protocol, Undetectable Online Password Guessing Attack','Shirisha Tallapally and R Padmavathy','dlibrary/JIPS_v06_no1_paper04.pdf','?In the secure communication areas, three-party authenticated key exchange protocol is an important cryptographic technique. In this protocol, two clients will share a human-memorable password with a trusted server, in which two users can generate a secure session key. On the other hand the protocol should resist all types of password guessing attacks. Recently, STPKE’ protocol has been proposed by Kim and Choi. An undetectable online password guessing attack on STPKE’ protocol is presented in the current study. An alternative protocol to overcome undetectable online password guessing attacks is proposed. The results show that the proposed protocol can resist undetectable online password guessing attacks. Additionally, it achieves the same security level with reduced random numbers and without XOR operations. The computational efficiency is improved by ? 30% for problems of size ? 2048 bits. The proposed protocol is achieving better performance efficiency and withstands password guessing attacks. The results show that the proposed protocol is secure, efficient and practical. \r\n\r\n','10.3745/JIPS.2010.6.1.043',520,326,0,0,NULL,NULL),(112,2010,6,1,53,0,'A Hexagon Tessellation Approach for the Transmission Energy Efficiency in Underwater Wireless Sensor Networks','UWSN, Hexagon Tessellation, Energy Efficiency, Hybrid','Sungun Kim, Hyunsoo Cheon, Sangbo Seo, Seungmi Song and Seonyeong Park','dlibrary/JIPS_v06_no1_paper05.pdf','The energy efficiency is a key design issue to improve the lifetime of the underwater sensor networks (UWSN) consisting of sensor nodes equipped with a small battery of limited energy resource. In this paper, we apply a hexagon tessellation with an ideal cell size to deploy the underwater sensor nodes for two-dimensional UWSN. Upon this setting, we propose an enhanced hybrid transmission method that forwards data packets in a mixed transmission way based on location dependent direct transmitting or uniform multi-hop forwarding. In order to select direct transmitting or uniform multi-hop forwarding, the proposed method applies the threshold annulus that is defined as the distance between the cluster head node and the base station (BS). Our simulation results show that the proposed method enhances the energy efficiency compared with the existing multi-hop forwarding methods and hybrid transmission methods\r\n\r\n','10.3745/JIPS.2010.6.1.053',616,784,0,0,NULL,NULL),(113,2010,6,1,67,0,'Approximate Clustering on Data Streams Using Discrete Cosine Transform','Grid Density-Based Clustering, Approximate Cluster Analysis, Discrete Cosine Transform, Sampling, Data Reconstruction, Data Compression','Feng Yu, Damalie Oyana, Wen-Chi Hou and Michael Wainer','dlibrary/JIPS_v06_no1_paper06.pdf','In this study, a clustering algorithm that uses DCT transformed data is presented. The algorithm is a grid density-based clustering algorithm that can identify clusters of arbitrary shape. Streaming data are transformed and reconstructed as needed for clustering. Experimental results show that DCT is able to approximate a data distribution efficiently using only a small number of coefficients and preserve the clusters well. The grid based clustering algorithm works well with DCT transformed data, demonstrating the viability of DCT for data stream clustering applications.\r\n\r\n','10.3745/JIPS.2010.6.1.067',616,301,0,0,NULL,NULL),(114,2010,6,1,79,0,'Mining Frequent Itemsets with Normalized Weight in Continuous Data Streams','Frequent Itemsets, Weighted Support, Window Sliding, Weighted Support FP-Tree, Data Stream, WSFI-Mine','Younghee Kim, Wonyoung Kim and Ungmo Kim','dlibrary/JIPS_v06_no1_paper07.pdf','A data stream is a massive unbounded sequence of data elements continuously generated at a rapid rate. The continuous characteristic of streaming data necessitates the use of algorithms that require only one scan over the stream for knowledge discovery. Data mining over data streams should support the flexible trade-off between processing time and mining accuracy. In many application areas, mining frequent itemsets has been suggested to find important frequent itemsets by considering the weight of itemsets. In this paper, we present an efficient algorithm WSFI (Weighted Support Frequent Itemsets)- Mine with normalized weight over data streams. Moreover, we propose a novel tree structure, called the Weighted Support FP-Tree (WSFP-Tree), that stores compressed crucial information about frequent itemsets. Empirical results show that our algorithm outperforms comparative algorithms under the windowed streaming model.\r\n\r\n','10.3745/JIPS.2010.6.1.079',638,292,0,0,NULL,NULL),(115,2010,6,1,91,0,'The ISDF Framework: Towards Secure Software Development','Security Patterns, Secure Development, Security Framework','Abdulaziz Alkussayer and William H Allen','dlibrary/JIPS_v06_no1_paper08.pdf','The rapid growth of communication and globalization has changed the software engineering process. Security has become a crucial component of any software system. However, software developers often lack the knowledge and skills needed to develop secure software. Clearly, the creation of secure software requires more than simply mandating the use of a secure software development lifecycle; the components produced by each stage of the lifecycle must be correctly implemented for the resulting system to achieve its intended goals. This study demonstrates that a more effective approach to the development of secure software can result from the integration of carefully selected security patterns into appropriate stages of the software development lifecycle to ensure that security designs are correctly implemented. The goal of this study is to provide developers with an Integrated Security Development Framework (ISDF) that can assist them in building more secure software.','10.3745/JIPS.2010.6.1.091',553,385,0,0,NULL,NULL),(116,2010,6,1,107,0,'IPv4 Address Trading Using Resource Certificate','IP Address Trading, Resource PKI, Routing Security, IP Address Management','Cheol-Soon Park, Jae-Cheol Ryou and Yong-Tae Park','dlibrary/JIPS_v06_no1_paper09.pdf','The Internet has been growing at unprecedented rates. The problem of an address shortage could act as a barrier on this growth. In principle, a new Internet standard, IPv6 solves the problem of the address shortage because it has a very large address space. But IPv6 is not yet compatible with the IPv4 and during the IPv4-to-IPv6 transition period IPv4 address will continue to be in demand. Thus for quite some time, the problem of IP address shortage will persist. To solve the problem, we propose the mechanism of secure IP address trading. This mechanism is based on the Resource PKI (RPKI). The RPKI is the working item of IETF. This proposed mechanism maximizes the trust of IP address trading using RPKI.','10.3745/JIPS.2010.6.1.107',569,369,0,0,NULL,NULL),(117,2010,6,1,121,0,'Strategic Information Systems Alignment: Alignment of IS/IT with Business Strategy','Information Systems, Information Systems, Business Planning, Planning Strategy, IT/IS Alignment.','Abdisalam Issa-Salwe, Munir Ahmed, Khalid Aloufi and Muhammad Kabir','dlibrary/JIPS_v06_no1_paper10.pdf','Using information systems effectively requires an understanding of the organisation, management, and the technology shaping the systems. All information systems can be described as organisational and management solutions to challenges posed by the environment. The advances in information systems have affect on our day-to day lives . As the technology is evolving immensely so are the opportunities in a healthy way to prepare the organisation in the competitive advantage environment In order to manage the IS/IT based systems, it is important to have an appropriate strategy that defines the systems and provide means to manage them. Strategic Information Systems Alignment (SISA) is an effective way of developing and maintaining the IS/IT systems that support the business operations. Alignment of the IS/IT plans and the business plans is essential for improved business performance, this research looks at the key features of SISA in the changing business circumstances in Saudi Arabia.','10.3745/JIPS.2010.6.1.121',1032,4512,0,0,NULL,NULL),(118,2010,6,2,129,0,'Challenges to Next Generation Services in IP Multimedia Subsystem','IP Multimedia Subsystems, Peer-to-Peer, Web Services, SCIM','Kai-Di Chang, Chi-Yuan Chen, Jiann-Liang Chen and Han-Chieh Chao','dlibrary/JIPS_v06_no2_paper01.pdf','The trend of Next Generation Networks’ (NGN) evolution is towards providing multiple and multimedia services to users through ubiquitous networks. The aim of IP Multimedia Subsystem (IMS) is to integrate mobile communication networks and computer networks. The IMS plays an important role in NGN services, which can be achieved by heterogeneous networks and different access technologies. IMS can be used to manage all service related issues such as Quality of Service (QoS), Charging, Access Control, User and Services Management. Nowadays, internet technology is changing with each passing day. New technologies yield new impact to IMS. In this paper, we perform a survey of IMS and discuss the different impacts of new technologies on IMS such as P2P, SCIM, Web Service and its security issues.','10.3745/JIPS.2010.6.2.129',2961,604,4,0,NULL,NULL),(119,2010,6,2,147,0,'A Fine-grained Localization Scheme Using A Mobile Beacon Node for Wireless Sensor Networks','Localization Algorithm, Mobile Beacon Node, Sensor Network, RS?','Kezhong Liu and Ji Xiong','dlibrary/JIPS_v06_no2_paper02.pdf','In this paper, we present a fine-grained localization algorithm for wireless sensor networks using a mobile beacon node. The algorithm is based on distance measurement using RSSI. The beacon node is equipped with a GPS sender and RF (radio frequency) transmitter. Each stationary sensor node is equipped with a RF. The beacon node periodically broadcasts its location information, and stationary sensor nodes perceive their positions as beacon points. A sensor node’s location is computed by measuring the distance to the beacon point using RSSI. Our proposed localization scheme is evaluated using OPNET 8.1 and compared with Ssu’s and Yu’s localization schemes. The results show that our localization scheme outperforms the other two schemes in terms of energy efficiency (overhead) and accuracy.','10.3745/JIPS.2010.6.2.147',551,285,0,0,NULL,NULL),(120,2010,6,2,163,0,'IMTAR: Incremental Mining of General Temporal Association Rules','Incremental Mining of General Temporal Association Rules, Incremental TFP-Tree','Anour F.A. Dafa-Alla, Ho Sun Shon, Khalid E.K. Saeed, Minghao Piao, Un-il Yun, Kyung Joo Cheoi and Keun Ho Ryu','dlibrary/JIPS_v06_no2_paper03.pdf','Nowadays due to the rapid advances in the field of information systems, transactional databases are being updated regularly and/or periodically. The knowledge discovered from these databases has to be maintained, and an incremental updating technique needs to be developed for maintaining the discovered association rules from these databases. The concept of Temporal Association Rules has been introduced to solve the problem of handling time series by including time expressions into association rules. In this paper we introduce a novel algorithm for Incremental Mining of General Temporal Association Rules (IMTAR) using an extended TFP-tree. The main benefits introduced by our algorithm are that it offers significant advantages in terms of storage and running time and it can handle the problem of mining general temporal association rules in incremental databases by building TFP-trees incrementally. It can be utilized and applied to real life application domains. We demonstrate our algorithm and its advantages in this paper.','10.3745/JIPS.2010.6.2.163',713,411,0,0,NULL,NULL),(121,2010,6,2,177,0,'The Wormhole Routing Attack in Wireless Sensor Networks (WSN)','Secure Routing, Routing Attacks, Routing Protocols, Wireless Sensor Networks (WSN), Wormhole Attack','Lukman Sharif and Munir Ahmed','dlibrary/JIPS_v06_no2_paper04.pdf','Secure routing is vital to the acceptance and use of Wireless Sensor Networks (WSN) for many applications. However, providing secure routing in WSNs is a challenging task due to the inherently constrained capabilities of sensor nodes. Although a wide variety of routing protocols have been proposed for WSNs, most do not take security into account as a main goal. Routing attacks can have devastating effects on WSNs and present a major challenge when designing robust security mechanisms for WSNs.\r\nIn this paper, we examine some of the most common routing attacks in WSNs. In particular, we focus on the wormhole routing attack in some detail. A variety of countermeasures have been proposed in the literature for such attacks. However, most of these countermeasures suffer from flaws that essentially render them ineffective for use in large scale WSN deployments. Due to the inherent constraints found in WSNs, there is a need for lightweight and robust security mechanisms. The examination of the wormhole routing attack and some of the proposed countermeasures makes it evident that it is extremely difficult to retrofit existing protocols with defenses against routing attacks. It is suggested that one of the ways to approach this rich field of research problems in WSNs could be to carefully design new routing protocols in which attacks such as wormholes can be rendered meaningless.','10.3745/JIPS.2010.6.2.177',716,714,0,0,NULL,NULL),(122,2010,6,2,185,0,'Development of Personal Information Protection Model using a Mobile Agent','Information Protect Model, Mobile Agent, Personal Information Protection, Privacy Protection Policy','Seong-Hee Bae and Jaejoon Kim','dlibrary/JIPS_v06_no2_paper05.pdf','This paper proposes a personal information protection model that allows a user to regulate his or her own personal information and privacy protection policies to receive services provided by a service provider without having to reveal personal information in a way that the user is opposed to. When the user needs to receive a service that requires personal information, the user will only reveal personal information that they find acceptable and for uses that they agree with. Users receive desired services from the service provider only when there is agreement between the user’s and the service provider’s security policies. Moreover, the proposed model utilizes a mobile agent that is transmitted from the user’s personal space, providing the user with complete control over their privacy protection. In addition, the mobile agent is itself a selfdestructing program that eliminates the possibility of personal information being leaked. The mobile agent described in this paper allows users to truly control access to their personal information.','10.3745/JIPS.2010.6.2.185',561,324,0,0,NULL,NULL),(123,2010,6,2,197,0,'Incremental Model-based Test Suite Reduction with Formal Concept Analysis','Test Suite Reduction, Model-based Testing, State Machine Model, Formal Concept Analysis','Pin Ng, Richard Y. K. Fung and Ray W. M. Kong','dlibrary/JIPS_v06_no2_paper06.pdf','Test scenarios can be derived based on some system models for requirements validation purposes. Model-based test suite reduction aims to provide a smaller set of test scenarios which can preserve the original test coverage with respect to some testing criteria. We are proposing to apply Formal Concept Analysis (FCA) in analyzing the association between a set of test scenarios and a set of transitions specified in a state machine model. By utilizing the properties of concept lattice, we are able to determine incrementally a minimal set of test scenarios with adequate test coverage.','10.3745/JIPS.2010.6.2.197',544,513,0,0,NULL,NULL),(124,2010,6,2,209,0,'Fast Fuzzy Control of Warranty Claims System','Warranty Claims, Age, Usage, Fuzzy Logic','Sang-Hyun Lee, Sung Eui Cho and Kyung-li Moon','dlibrary/JIPS_v06_no2_paper07.pdf','Classical warranty plans require crisp data obtained from strictly controlled reliability tests. However, in a real situation these requirements might not be fulfilled. In an extreme case, the warranty claims data come from users whose reports are expressed in a vague way. Furthermore, there are special situations where several characteristics are used together as criteria for judging the warranty eligibility of a failed product. This paper suggests a fast reasoning model based on fuzzy logic to handle multi-attribute and vague warranty data.','10.3745/JIPS.2010.6.2.209',627,484,0,0,NULL,NULL),(125,2010,6,2,219,0,'Developing Digital Games through Software Reuse','Games, Product Line, Software Reuse, Software Development','Beatriz Neto, Lucia Fernandes, Claudia Werner and Jano Moreira de Souza','dlibrary/JIPS_v06_no2_paper08.pdf','Gaming is an old humans’ habit. Games help in logical development and encourage learning of theoretical and practical concepts. Besides they offer entertainment and challenge. The advent of the personal computer changed this tradition. Every year new challenges arise in a digital format, which lead the young and adults to spend hours in front of a computer or TV screen in an attempt to overcome hurdles and reach an objective. Quality, sophistication, and constant innovation are attained through complex computer software that almost has an obligation to improve as each new title is released, due to this game development becomes a challenge. Considering that a game title is software and thus faces the same restrictions of business applications, this article intends to analyze, under the optics of reuse, if game development resorts to reuse, and where and how this happens.','10.3745/JIPS.2010.6.2.219',518,522,0,0,NULL,NULL),(126,2010,6,2,235,0,'A Regression Test Selection and Prioritization Technique','Regression Testing, Maintenance, Prioritization','Ruchika Malhotra, Arvinder Kaur and Yogesh Singh','dlibrary/JIPS_v06_no2_paper09.pdf','Regression testing is a very costly process performed primarily as a software maintenance activity. It is the process of retesting the modified parts of the software and ensuring that no new errors have been introduced into previously tested source code due to these modifications. A regression test selection technique selects an appropriate number of test cases from a test suite that might expose a fault in the modified program. In this paper, we propose both a regression test selection and prioritization technique. We implemented our regression test selection technique and demonstrated in two case studies that our technique is effective regarding selecting and prioritizing test cases. The results show that our technique may significantly reduce the number of test cases and thus the cost and resources for performing regression testing on modified software','10.3745/JIPS.2010.6.2.235',706,3572,0,0,NULL,NULL),(127,2010,6,2,253,0,'A License Audit Model for Secure DRM Systems in IP-based Environments','Digital Forensic, DRM, IP-Based Network','Ui Jin Jang, Hyung-Min Lim and Yong-Tae Shin','dlibrary/JIPS_v06_no2_paper10.pdf','Communication devices aim to provide a multimedia service without spatial or temporal limitations in an IP-based environment. However, it is incapable of allowing for fair use by consumers who legally buy content, and damages provider contents through the indiscriminate distribution and use of illegal contents.\r\nThe DRM system that emerged to solve this problem cannot protect licenses stored on communication devices, and manage licenses by redistribution. This paper proposes a license audit model, which checks for illegal access, modification and redistribution, and reports alert logs to the server.','10.3745/JIPS.2010.6.2.253',488,449,0,0,NULL,NULL),(128,2010,6,2,261,0,'Recognition of Human Facial Expression in a Video Image using the Active Appearance Model','Active Appearance Model, Facial Expression Recognition, Image Alignment Method','Gyeong-Sic Jo and Yong-Guk Kim','dlibrary/JIPS_v06_no2_paper11.pdf','Tracking human facial expression within a video image has many useful applications, such as surveillance and teleconferencing, etc. Initially, the Active Appearance Model (AAM) was proposed for facial recognition; however, it turns out that the AAM has many advantages as regards continuous facial expression recognition. We have implemented a continuous facial expression recognition system using the AAM. In this study, we adopt an independent AAM using the Inverse Compositional Image Alignment method. The system was evaluated using the standard Cohn-Kanade facial expression database, the results of which show that it could have numerous potential applications.','10.3745/JIPS.2010.6.2.261',517,417,0,0,NULL,NULL),(129,2010,6,3,269,0,'DEESR: Dynamic Energy Efficient and Secure Routing Protocol for Wireless Sensor Networks in Urban Environments','Sensor Network, Security, Energy Efficiency, Routing, Dynamic Trust Factor','Mohammad S. Obaidat, Sanjay K. Dhurandher, Deepank Gupta, Nidhi Gupta and Anupriya Asthana','dlibrary/JIPS_v06_no3_paper01.pdf','The interconnection of mobile devices in urban environments can open up a lot of vistas for collaboration and content-based services. This will require setting up of a network in an urban environment which not only provides the necessary services to the user but also ensures that the network is secure and energy efficient. In this paper, we propose a secure, energy efficient dynamic routing protocol for heterogeneous wireless sensor networks in urban environments. A decision is made by every node based on various parameters like longevity, distance, battery power which measure the node and link quality to decide the next hop in the route. This ensures that the total load is distributed evenly while conserving the energy of battery-constrained nodes. The protocol also maintains a trusted population for each node through Dynamic Trust Factor (DTF) which ensures secure communication in the environment by gradually isolating the malicious nodes. The results obtained show that the proposed protocol when compared with another energy efficient protocol (MMBCR) and a widely accepted protocol (DSR) gives far better results in terms of energy efficiency. Similarly, it also outdoes a secure protocol (QDV) when it comes to detecting malicious nodes in the network.','10.3745/JIPS.2010.6.3.269 ',2888,2011,5,0,NULL,NULL),(130,2010,6,3,295,0,'MAP : A Balanced Energy Consumption Routing Protocol for Wireless Sensor Networks','Wireless Sensor Network(WSN), Energy Efficient Routing','Mohamed Mostafa A. Azim ','dlibrary/JIPS_v06_no3_paper02.pdf','Network lifetime is a critical issue in Wireless Sensor Networks (WSNs). In which, a large number of sensor nodes communicate together to perform a predetermined sensing task. In such networks, the network life time depends mainly on the lifetime of the sensor nodes constituting the network. Therefore, it is essential to balance the energy consumption among all sensor nodes to ensure the network connectivity. In this paper, we propose an energy-efficient data routing protocol for wireless sensor networks. Contrary to the protocol proposed in [6], that always selects the path with minimum hop count to the base station, our proposed routing protocol may choose a longer path that will provide better distribution of the energy consumption among the sensor nodes. Simulation results indicate clearly that compared to the routing protocol proposed in [6], our proposed protocol evenly distributes the energy consumption among the network nodes thus maximizing the network life time.','10.3745/JIPS.2010.6.3.295 ',689,369,0,0,NULL,NULL),(131,2010,6,3,307,0,'A Classifiable Sub-Flow Selection Method for Traffic Classification in Mobile IP Networks','Mobile IP Network, Traffic Classification, Network Management, Traffic Engineering, Machine Learning','Akihiro Satoh, Toshiaki Osada, Toru Abe, Gen Kitagata, Norio Shiratori and Tetsuo Kinoshita','dlibrary/JIPS_v06_no3_paper03.pdf','Traffic classification is an essential task for network management. Many researchers have paid attention to initial sub-flow features based classifiers for traffic classification. However, the existing classifiers cannot classify traffic effectively in mobile IP networks. The classifiers depend on initial sub-flows, but they cannot always capture the sub-flows at a point of attachment for a variety of elements because of seamless mobility. Thus the ideal classifier should be capable of traffic classification based on not only initial sub-flows but also various types of sub-flows. In this paper, we propose a classifiable sub-flow selection method to realize the ideal classifier. The experimental results are so far promising for this research direction, even though they are derived from a reduced set of general applications and under relatively simplifying assumptions. Altogether, the significant contribution is indicating the feasibility of the ideal classifier by selecting not only initial sub-flows but also transition sub-flows.','10.3745/JIPS.2010.6.3.307 ',612,468,0,0,NULL,NULL),(132,2010,6,3,323,0,'Plans and Strategies for UBcN Networks and Services','UBcN, Broadband, NGN, Converged Services, Policies','Eunyoung Lee','dlibrary/JIPS_v06_no3_paper04.pdf','The broadcasting & telecommunication services in the future will be converged and be serviced on mobile devices. However, the current ICT infrastructure does not fully meet the future demand for those converged, realistic, intelligent, and personalized services. The Korean government is going to establish a high speed next generation network called UBcN (Ultra-Broadband Convergence Network) by 2013. The Korean government has announced a multi-year plan to establish an UBcN network and to discover and stimulate new converged services for an UBcN in January, 2009. The author of this paper has taken part in formulating development plans since the early stages of planning. In this paper, Korea\'s development plans for the next generation network and their development strategies are analyzed and discussed based on the author\'s experience. The paper also discusses the expected impacts of the plan for the future ICT industry, and the implications of government-driven development plans.','10.3745/JIPS.2010.6.3.323 ',504,371,0,0,NULL,NULL),(133,2010,6,3,335,0,'Solving the Discrete Logarithm Problem for Ephemeral Keys in Chang and Chang Password Key Exchange Protocol','Ephemeral Key, Pohlig-Hellman Method, Van-Oorschot Method, Index Calculus Method, Chang-Chang Password Key Exchange Protocol','R. Padmavathy and Chakravarthy Bhagvati','dlibrary/JIPS_v06_no3_paper05.pdf','The present study investigates the difficulty of solving the mathematical problem, namely the DLP (Discrete Logarithm Problem) for ephemeral keys. The DLP is the basis for many public key cryptosystems. The ephemeral keys are used in such systems to ensure security. The DLP defined on a prime field Z * p of random prime is considered in the present study. The most effective method to solve the DLP is the ICM (Index Calculus Method). In the present study, an efficient way of computing the DLP for ephemeral keys by using a new variant of the ICM when the factors of p ?1 are known and small is proposed. The ICM has two steps, a pre-computation and an individual logarithm computation. The pre-computation step is to compute the logarithms of a subset of a group and the individual logarithm step is to find the DLP using the precomputed logarithms. Since the ephemeral keys are dynamic and change for every session, once the logarithms of a subset of a group are known, the DLP for the ephemeral key can be obtained using the individual logarithm step. Therefore, an efficient way of solving the individual logarithm step based on the newly proposed precomputation method is presented and the performance is analyzed using a comprehensive set of experiments. The ephemeral keys are also solved by using other methods, which are efficient on random primes, such as the Pohlig-Hellman method, the Van Oorschot method and the traditional individual logarithm step. The results are compared with the newly proposed individual logarithm step of the ICM. Also, the DLP of ephemeral keys used in a popular password key exchange protocol known as Chang and Chang are computed and reported to launch key recovery attack.','10.3745/JIPS.2010.6.3.335 ',544,572,0,0,NULL,NULL),(134,2010,6,3,347,0,'A Measurement System for 3D Hand-Drawn Gesture with a PHANToM™ Device','Hand-Drawn Gesture, Hand-Held Device, Inertial Measurement Unit, PHANToMTM , Calibration','Seong Young Ko, Won-Chul Bang and Sang-Youn Kim','dlibrary/JIPS_v06_no3_paper06.pdf','This paper presents a measurement system for 3D hand-drawn gesture motion. Many pen-type input devices with Inertial Measurement Units (IMU) have been developed to estimate 3D hand-drawn gesture using the measured acceleration and/or the angular velocity of the device. The crucial procedure in developing these devices is to measure and to analyze their motion or trajectory. In order to verify the trajectory estimated by an IMU-based input device, it is necessary to compare the estimated trajectory to the real trajectory. For measuring the real trajectory of the pen-type device, a PHANToMTM haptic device is utilized because it allows us to measure the 3D motion of the object in real-time. Even though the PHANToMTM measures the position of the hand gesture well, poor initialization may produce a large amount of error. Therefore, this paper proposes a calibration method which can minimize measurement errors.','10.3745/JIPS.2010.6.3.347 ',590,861,0,0,NULL,NULL),(135,2010,6,3,359,0,'Access Control to Objects and their Description in the Future Network of Information','Future Internet, Network of Information, Security, Storage Space, Access Rights','Eric Renault, Ahmad Ahmad and Mohamed Abid','dlibrary/JIPS_v06_no3_paper07.pdf','The Future Internet that includes Real World Objects and the Internet of Things together with the more classic web pages will move communications from a nodecentric organization to an information-centric network allowing new a paradigm to take place. The 4WARD project initiated some works on the Future Internet. One of them is the creation of a Network of Information designed to enable more powerful semantic searches. In this paper, we propose a security solution for a model of information based on a semantic description and search of objects. The proposed solution takes into account both the access and the management of both objects and their descriptions.','10.3745/JIPS.2010.6.3.359 ',590,317,0,0,NULL,NULL),(136,2010,6,3,375,0,'En-Route Trajectory calculation using Flight Plan Information for Effective Air Traffic Management','ATC, ATM, Trajectory Prediction, ATFM','Yong-Kyun Kim, Yun-Hyun Jo, Jin-Won Yun, Taeck-Keun Oh, Hee-Chang Roh, Sang-Bang Choi and Hyo-Dal Park','dlibrary/JIPS_v06_no3_paper08.pdf','Trajectory modeling is foundational for 4D-Route modeling, conflict detection and air traffic flow management. This paper proposes a novel algorithm based Vincenty’s fomulas for trajectory calculation, combined with the Dijkstra algorithm and Vincenty’s formulas. Using flight plan simulations our experimental results show that our method of En-route trajectory calculation exhibits much improved performance in accuracy.','10.3745/JIPS.2010.6.3.375 ',631,952,0,0,NULL,NULL),(137,2010,6,3,385,0,'Stakeholders Driven Requirements Engineering Approach for Data Warehouse Development','Agent, Dependencies Among Agents, Stakeholders of the Organization, Data Warehouse Requirements Engineering, Early Requirements Engineering, Late Requirements Engineering','Manoj Kumar, Anjana Gosain and Yogesh Singh','dlibrary/JIPS_v06_no3_paper09.pdf','Most of the data warehouse (DW) requirements engineering approaches have not distinguished the early requirements engineering phase from the late requirements engineering phase. There are very few approaches seen in the literature that explicitly model the early & late requirements for a DW. In this paper, we propose an AGDI (Agent-Goal-Decision-Information) model to support the early and late requirements for the development of DWs. Here, the notion of agent refers to the stakeholders of the organization and the dependency among agents refers to the dependencies among stakeholders for fulfilling their organizational goals. The proposed AGDI model also supports three interrelated modeling activities namely, organization modeling, decision modeling and information modeling. Here, early requirements are modeled by performing organization modeling and decision modeling activities, whereas late requirements are modeled by performing information modeling activities. The proposed approach has been illustrated to capture the early and late requirements for the development of a university data warehouse exemplifying our model’s ability of supporting its decisional goals by providing decisional information.','10.3745/JIPS.2010.6.3.385 ',611,317,0,0,NULL,NULL),(138,2010,6,3,403,0,'Speed-Sensitive Handover Scheme over IEEE 802.16 Multi-Relay Networks','Multi-Relay Networks, Handover','DongHo Kim, SoonSeok Kim and YongHee Lee','dlibrary/JIPS_v06_no3_paper10.pdf','Multi-Relay Networks should accommodate mobile users of various speeds. The cellular system should meet the minimum residency time requirements for handover calls while considering an efficient use of available channels. In this paper, we design speed-sensitive handover under dynamic hierarchical cellular systems, in which mobile users are classified according to the mean speed of mobile users and each class has its cellular layer. In order to meet the minimum residency time, the cell size of each cellular layer is dynamically determined depending on the distributions of mean speeds of mobile users. Since the speed-dependent non-preferred cell can provide a secondary resource, overflow and take-back schemes are adopted in the system. We develop analytical models to study the performance of the proposed system, and show that the optimal cell size improves the blocking probability.','10.3745/JIPS.2010.6.3.403 ',552,356,0,0,NULL,NULL),(139,2010,6,3,413,0,'On the Handling of Node Failures: Energy-Efficient Job Allocation Algorithm for Real-time Sensor Networks','Failure Recovery, Job Allocation, Quality of Service, Real-Time Scheduling, Wireless Sensor Network','Hamid Karimi, Mehdi Kargahi, and Nasser Yazdani','dlibrary/JIPS_v06_no3_paper11.pdf','Wireless sensor networks are usually characterized by dense deployment of energy constrained nodes. Due to the usage of a large number of sensor nodes in uncontrolled hostile or harsh environments, node failure is a common event in these systems. Another common reason for node failure is the exhaustion of their energy resources and node inactivation. Such failures can have adverse effects on the quality of the real-time services in Wireless Sensor Networks (WSNs). To avoid such degradations, it is necessary that the failures be recovered in a proper manner to sustain network operation. In this paper we present a dynamic Energy efficient Real-Time Job Allocation (ERTJA) algorithm for handling node failures in a cluster of sensor nodes with the consideration of communication energy and time overheads besides the nodes’ characteristics. ERTJA relies on the computation power of cluster members for handling a node failure. It also tries to minimize the energy consumption of the cluster by minimum activation of the sleeping nodes. The resulting system can then guarantee the Quality of Service (QoS) of the cluster application. Further, when the number of sleeping nodes is limited, the proposed algorithm uses the idle times of the active nodes to engage a graceful QoS degradation in the cluster. Simulation results show significant performance improvements of ERTJA in terms of the energy conservation and the probability of meeting deadlines compared with the other studied algorithms.','10.3745/JIPS.2010.6.3.413 ',631,429,0,0,NULL,NULL),(140,2010,6,4,435,0,'Hiding Secret Data in an Image Using Codeword Imitation','Data Hiding, Steganography, Vector Quantization','Zhi-Hui Wang, Chin-Chen Chang and Pei-Yu Tsai','dlibrary/JIPS_v06_no4_paper01.pdf','This paper proposes a novel reversible data hiding scheme based on a Vector Quantization (VQ) codebook. The proposed scheme uses the principle component analysis (PCA) algorithm to sort the codebook and to find two similar codewords of an image block. According to the secret to be embedded and the difference between those two similar codewords, the original image block is transformed into a difference number table. Finally, this table is compressed by entropy coding and sent to the receiver. The experimental results demonstrate that the proposed scheme can achieve greater hiding capacity, about five bits per index, with an acceptable bit rate. At the receiver end, after the compressed code has been decoded, the image can be recovered to a VQ compressed image.','10.3745/JIPS.2010.6.4.435 ',2952,1476,6,0,NULL,NULL),(141,2010,6,4,453,0,'Security Properties of Domain Extenders for Cryptographic Hash Functions','Hash Functions, Domain Extenders, Security Properties','Elena Andreeva, Bart Mennink and Bart Preneel ','dlibrary/JIPS_v06_no4_paper02.pdf','Cryptographic hash functions reduce inputs of arbitrary or very large length to a short string of fixed length. All hash function designs start from a compression function with fixed length inputs. The compression function itself is designed from scratch, or derived from a block cipher or a permutation. The most common procedure to extend the domain of a compression function in order to obtain a hash function is a simple linear iteration; however, some variants use multiple iterations or a tree structure that allows for parallelism. This paper presents a survey of 17 extenders in the literature. It considers the natural question whether these preserve the security properties of the compression function, and more in particular collision resistance, second preimage resistance, preimage resistance and the pseudo-random oracle property.','10.3745/JIPS.2010.6.4.453 ',3133,737,7,0,NULL,NULL),(142,2010,6,4,481,0,'Distributed and Scalable Intrusion Detection System Based on Agents and Intelligent Techniques','Data-Mining, Fuzzy Logic, IDS, Intelligent Techniques, Network Security, Software Agents','Aly M. El-Semary and Mostafa Gadal-Haqq M. Mostafa ','dlibrary/JIPS_v06_no4_paper03.pdf','The Internet explosion and the increase in crucial web applications such as ebanking and e-commerce, make essential the need for network security tools. One of such tools is an Intrusion detection system which can be classified based on detection approachs as being signature-based or anomaly-based. Even though intrusion detection systems are well defined, their cooperation with each other to detect attacks needs to be addressed. Consequently, a new architecture that allows them to cooperate in detecting attacks is proposed. The architecture uses Software Agents to provide scalability and distributability. It works in two modes: learning and detection. During learning mode, it generates a profile for each individual system using a fuzzy data mining algorithm. During detection mode, each system uses the FuzzyJess to match network traffic against its profile. The architecture was tested against a standard data set produced by MIT Lincoln Laboratory and the primary results show its efficiency and capability to detect attacks. Finally, two new methods, the memory-window and memoryless-window, were developed for extracting useful parameters from raw packets. The parameters are used as detection metrics','10.3745/JIPS.2010.6.4.481 ',886,381,0,0,NULL,NULL),(143,2010,6,4,501,0,'Medium Access Control with Dynamic Frame Length in Wireless Sensor Networks','Sensor Networks, Energy-Efficient MAC, S-MAC','Dae-Suk Yoo and Seung Sik Choi','dlibrary/JIPS_v06_no4_paper04.pdf','Wireless sensor networks consist of sensor nodes which are expected to be battery-powered and are hard to replace or recharge. Thus, reducing the energy consumption of sensor nodes is an important design consideration in wireless sensor networks. For the implementation of an energy-efficient MAC protocol, a Sensor-MAC based on the IEEE 802.11 protocol, which has energy efficient scheduling, has been proposed. In this paper, we propose a Dynamic S-MAC that adapts dynamically to the network-traffic state. The dynamic S-MAC protocol improves the energy consumption of the S-MAC by changing the frame length according to the network-traffic state. Using an NS-2 Simulator, we compare the performance of the Dynamic S-MAC with that of the SMAC protocol.','10.3745/JIPS.2010.6.4.501 ',778,551,0,0,NULL,NULL),(144,2010,6,4,511,0,'Fingerprint Detection Using Canny Filter and DWT, a New Approach ','Canny Filter, Color Inversion, Skewness, Kurtosis and Convolution','Md. Imdadul Islam, Nasima Begum, Mahbubul Alam and M. R. Amin ','dlibrary/JIPS_v06_no4_paper05.pdf','This paper proposes two new methods to detect the fingerprints of different persons based on one-dimensional and two-dimensional discrete wavelet transformations (DWTs). Recent literature shows that fingerprint detection based on DWT requires less memory space compared to pattern recognition and moment-based image recognition techniques. In this study four statistical parameters - cross correlation co-efficient, skewness, kurtosis and convolution of the approximate coefficient of one-dimensional DWTs are used to evaluate the two methods involving fingerprints of the same person and those of different persons. Within the contexts of all statistical parameters in detection of fingerprints, our second method shows better results than that of the first method.','10.3745/JIPS.2010.6.4.511 ',832,514,0,0,NULL,NULL),(145,2010,6,4,521,0,'Mining Spatio-Temporal Patterns in Trajectory Data ','Data Mining, Spatio-Temporal Data Mining, Trajectory Data, Frequent Spatio-Temporal Patterns','Juyoung Kang and Hwan-Seung Yong ','dlibrary/JIPS_v06_no4_paper06.pdf','Spatio-temporal patterns extracted from historical trajectories of moving objects reveal important knowledge about movement behavior for high quality LBS services. Existing approaches transform trajectories into sequences of location symbols and derive frequent subsequences by applying conventional sequential pattern mining algorithms. However, spatio-temporal correlations may be lost due to the inappropriate approximations of spatial and temporal properties. In this paper, we address the problem of mining spatio-temporal patterns from trajectory data. The inefficient description of temporal information decreases the mining efficiency and the interpretability of the patterns. We provide a formal statement of efficient representation of spatio-temporal movements and propose a new approach to discover spatio-temporal patterns in trajectory data. The proposed method first finds meaningful spatio-temporal regions and extracts frequent spatio-temporal patterns based on a prefix-projection approach from the sequences of these regions. We experimentally analyze that the proposed method improves mining performance and derives more intuitive patterns.','10.3745/JIPS.2010.6.4.521 ',783,546,0,0,NULL,NULL),(146,2010,6,4,537,0,'An Optimized Approach of Fault Distribution for Debugging in Parallel ','Clustering, Debugging, Fault Localization, Optimization, Software Testing','Maneesha Srivasatav, Yogesh Singh and Durg Singh Chauhan ','dlibrary/JIPS_v06_no4_paper07.pdf','Software Debugging is the most time consuming and costly process in the software development process. Many techniques have been proposed to isolate different faults in a program thereby creating separate sets of failing program statements. Debugging in parallel is a technique which proposes distribution of a single faulty program segment into many fault focused program slices to be debugged simultaneously by multiple debuggers. In this paper we propose a new technique called Faulty Slice Distribution (FSD) to make parallel debugging more efficient by measuring the time and labor associated with a slice. Using this measure we then distribute these faulty slices evenly among debuggers. For this we propose an algorithm that estimates an optimized group of faulty slices using as a parameter the priority assigned to each slice as computed by value of their complexity. This helps in the efficient merging of two or more slices for distribution among debuggers so that debugging can be performed in parallel. To validate the effectiveness of this proposed technique we explain the process using example.','10.3745/JIPS.2010.6.4.537 ',774,502,0,0,NULL,NULL),(147,2010,6,4,553,0,'Efficient Server Virtualization using Grid Service Infrastructure ','Server Virtualization, Grid Service, Grid Infrastructure, Power Efficiency, Cloud Computing','Sung-Jin Baek, Sun-Mi Park, Su-Hyun Yang, Eun-Ha Song and Young-Sik Jeong ','dlibrary/JIPS_v06_no4_paper08.pdf','The core services in cloud computing environment are SaaS (Software as a Service), Paas (Platform as a Service) and IaaS (Infrastructure as a Service). Among these three core services server virtualization belongs to IaaS and is a service technology to reduce the server maintenance expenses. Normally, the primary purpose of sever virtualization is building and maintaining a new well functioning server rather than using several existing servers, and in improving the various system performances. Often times this presents an issue in that there might be a need to increase expenses in order to build a new server. This study intends to use grid service architecture for a form of server virtualization which utilizes the existing servers rather than introducing a new server. More specifically, the proposed system is to enhance system performance and to reduce the corresponding expenses, by adopting a scheduling algorithm among the distributed servers and the constituents for grid computing thereby supporting the server virtualization service. Furthermore, the proposed server virtualization system will minimize power management by adopting the sleep severs, the subsidized servers and the grid infrastructure. The power maintenance expenses for the sleep servers will be lowered by utilizing the ACPI (Advanced Configuration & Power Interface) standards with the purpose of overcoming the limits of server performance.','10.3745/JIPS.2010.6.4.553 ',901,422,0,0,NULL,NULL),(148,2010,6,4,563,0,'Intercepting Filter Approach to Injection Flaws ','Injection Flaws, SQL Injection, Intercepting Filter, Cross-site Scripting Vulnerability','Ahmed Salem ','dlibrary/JIPS_v06_no4_paper09.pdf','The growing number of web applications in the global economy has made it critically important to develop secure and reliable software to support the economy\'s increasing dependence on web-based systems. We propose an intercepting filter approach to mitigate the risk of injection flaw exploitation- one of the most dangerous methods of attacking web applications. The proposed approach can be implemented in Java or .NET environments following the intercepting filter design pattern. This paper provides examples to illustrate the proposed approach.',' 10.3745/JIPS.2010.6.4.563 ',696,1374,0,0,NULL,NULL),(149,2010,6,4,575,0,'Generalized Proxy-Assisted Periodic Broadcasting (G-ProB) for Heterogeneous Clients in Video-on- Demand Service ','Proxy-Assisted, Periodic Broadcasting, Video-on-Demand','Hidayat Febiansyah and Jin Baek Kwon ','dlibrary/JIPS_v06_no4_paper10.pdf','Video-on-Demand services are increasing rapidly nowadays. The load on servers can be very high, even exceeding their capacity. For popular contents, we can use a Periodic Broadcast (PB) strategy using multicast to serve all clients. Recent development of PB uses multiple channels broadcasting for segments of movies in certain patterns, so that users only need to wait for a small segment to start the service. However, users need higher download capacity to download multiple segments at a time. In order to compensate for this, a proxy server can help to reduce download bandwidth requirements by holding some segments for a certain time. This research will focus on more recent PB schemes that couldn\'t be covered by previous Proxy-Assisted Periodic Broadcast strategies.','10.3745/JIPS.2010.6.4.575 ',762,446,0,0,NULL,NULL),(150,2010,6,4,597,0,'A Dynamic Approach to Estimate Change Impact using Type of Change Propagation ','Change Impact Analysis, Regression Testing, Software Maintenance, Software Testing','Chetna Gupta, Yogesh Singh and Durg Singh Chauhan ','dlibrary/JIPS_v06_no4_paper11.pdf','Software evolution is an ongoing process carried out with the aim of extending base applications either for adding new functionalities or for adapting software to changing environments. This brings about the need for estimating and determining the overall impact of changes to a software system. In the last few decades many such change/impact analysis techniques have been developed to identify consequences of making changes to software systems. In this paper we propose a new approach of estimating change/impact analysis by classifying change based on type of change classification e.g. (a) nature and (b) extent of change propagation. The impact set produced consists of two dimensions of information: (a) statements affected by change propagation and (b) percentage i.e. statements affected in each category and involving the overall system. We also propose an algorithm for classifying the type of change. To establish confidence in effectiveness and efficiency we illustrate this technique with the help of an example. Results of our analysis are promising towards achieving the aim of the proposed endeavor to enhance change classification. The proposed dynamic technique for estimating impact sets and their percentage of impact will help software maintainers in performing selective regression testing by analyzing impact sets regarding the nature of change and change dependency.','10.3745/JIPS.2010.6.4.597 ',791,351,0,0,NULL,NULL),(151,2010,6,4,609,0,'A Study on Design and Implementation of the Ubiquitous Computing Environment-based Dynamic Smart On/Off-line Learner Tracking System ','u-Learning, e-Learning, Event Hooking, Content packing','Hyung-Min Lim, Kun-Won Jang and Byung-Gi Kim ','dlibrary/JIPS_v06_no4_paper12.pdf','In order to provide a tailored education for learners within the ubiquitous environment, it is critical to undertake an analysis of the learning activities of learners. For this purpose, SCORM (Sharable Contents Object Reference Model), IMS LD (Instructional Management System Learning Design) and other standards provide learning design support functions, such as, progress checks. However, in order to apply these types of standards, contents packaging is required, and due to the complicated standard dimensions, the facilitation level is lower than the work volume when developing the contents and this requires additional work when revision becomes necessary. In addition, since the learning results are managed by the server there is the problem of the OS being unable to save data when the network is cut off. In this study, a system is realized to manage the actions of learners through the event interception of a web-browser by using event hooking. Through this technique, all HTMLbased contents can be facilitated again without additional work and saving and analysis of learning results are available to improve the problems following the application of standards. Furthermore, the ubiquitous learning environment can be supported by tracking down learning results when the network is cut off.','10.3745/JIPS.2010.6.4.609 ',836,334,0,0,NULL,NULL),(152,2011,7,1,1,0,'Computer Simulation: A Hybrid Model for Traffic Signal Optimisation','Traffic Congestion, Hybrid Model, Optimisation Method','Mohamed Kamal JBIRA and Munir AHMED','dlibrary/JIPS_v07_no1_paper01.pdf','With the increasing number of vehicles in use in our daily life and the rise of traffic congestion problems, many methods and models have been developed for real time optimisation of traffic lights. Nevertheless, most methods which consider real time physical queue sizes of vehicles waiting for green lights overestimate the optimal cycle length for such real traffic control. This paper deals with the development of a generic hybrid model describing both physical traffic flows and control of signalised intersections. The firing times assigned to the transitions of the control part are considered dynamic and are calculated by a simplified optimisation method. This method is based on splitting green times proportionally to the predicted queue sizes through input links for each new cycle time. The proposed model can be easily translated into a control code for implementation in a real time control system.',' 10.3745/JIPS.2011.7.1.001  ',593,281,0,0,NULL,NULL),(153,2011,7,1,17,0,'A Single Mobile Target Tracking in Voronoi-based Clustered Wireless Sensor Network','Mobile Target Tracking, Sensor Network, Clustering, Voronoi Diagram','Jiehui Chen, Mariam B.Salim and Mitsuji Matsumoto','dlibrary/JIPS_v07_no1_paper02.pdf','Despite the fact that the deployment of sensor networks and target tracking could both be managed by taking full advantage of Voronoi diagrams, very little few have been made in this regard. In this paper, we designed an optimized barrier coverage and an energy-efficient clustering algorithm for forming Vonoroi-based Wireless Sensor Networks(WSN) in which we proposed a mobile target tracking scheme (CTT&MAV) that takes full advantage of Voronoi-diagram boundary to improve detectability. Simulations verified that CTT&MAV outperforms random walk, random waypoint, random direction and Gauss-Markov in terms of both the average hop distance that the mobile target moved before being detected and lower sensor death rate. Moreover, we demonstrate that our results are robust as realistic sensing models and also validate our observations through extensive simulations.','10.3745/JIPS.2011.7.1.017  ',656,286,0,0,NULL,NULL),(154,2011,7,1,29,0,'A Clustering Protocol with Mode Selection for Wireless Sensor Network','Ad Hoc Network, Wireless Sensor Networks, Clustering, Routing Protocol','Aries Kusdaryono and Kyung Oh Lee','dlibrary/JIPS_v07_no1_paper03.pdf','Wireless sensor networks are composed of a large number of sensor nodes with limited energy resources. One critical issue in wireless sensor networks is how to gather sensed information in an energy efficient way, since their energy is limited. The clustering algorithm is a technique used to reduce energy consumption. It can improve the scalability and lifetime of wireless sensor networks. In this paper, we introduce a clustering protocol with mode selection (CPMS) for wireless sensor networks. Our scheme improves the performance of BCDCP (Base Station Controlled Dynamic Clustering Protocol) and BIDRP (Base Station Initiated Dynamic Routing Protocol) routing protocol. In CPMS, the base station constructs clusters and makes the head node with the highest residual energy send data to the base station. Furthermore, we can save the energy of head nodes by using the modes selection method. The simulation results show that CPMS achieves longer lifetime and more data message transmissions than current important clustering protocols in wireless sensor networks.','10.3745/JIPS.2011.7.1.029  ',697,356,0,0,NULL,NULL),(155,2011,7,1,43,0,'Analytical Coexistence Benchmark for Assessing the Utmost Interference Tolerated by IEEE 802.20','MBWA, IEEE 802.20, Interference, Mobility, Degradation','Mouhamed Abdulla and Yousef R. Shayan','dlibrary/JIPS_v07_no1_paper04.pdf','Whether it is crosstalk, harmonics, or in-band operation of wireless technologies, interference between a reference system and a host of offenders is virtually unavoidable. In past contributions, a benchmark has been established and considered for coexistence analysis with a number of technologies including FWA, UMTS, and WiMAX. However, the previously presented model does not take into account the mobility factor of the reference node in addition to a number of interdependent requirements regarding the link direction, channel state, data rate and system factors; hence limiting its applicability for the MBWA (IEEE 802.20) standard. Thus, over diverse modes, in this correspondence we analytically derived the greatest aggregate interference level tolerated for high-fidelity transmission tailored specifically for the MBWA standard. Our results, in the form of benchmark indicators, should be of particular interest to peers analyzing and researching RF coexistence scenarios with this new protocol.','10.3745/JIPS.2011.7.1.043  ',525,305,0,0,NULL,NULL),(156,2011,7,1,53,0,'Dynamic Load Balancing and Network Adaptive Virtual Storage Service for Mobile Appliances','iATA Protocol, Load Balancing, Network Monitoring, Storage Network Solution, Write Replication','Ivy Ong and Hyotaek Lim','dlibrary/JIPS_v07_no1_paper05.pdf','With the steady growth of mobile technology and applications, demand for more storage in mobile devices has also increased. A lightweight block-level protocol, Internet Advanced Technology Attachment (iATA), has been developed to deliver a costeffective storage network solution for mobile devices to obtain more storage. This paper seeks to contribute to designing and implementing Load Balancing (LB), Network Monitoring (NM) and Write Replication (WR) modules to improve the protocol¡¯s scalability and data availability. LB and NM modules are invoked to collect system resources states and current network status at each associate node (server machine). A dynamic weight factor is calculated based on the collected information and sent to a referral server. The referral server is responsible to analyze and allocate the most ideal node with the least weight to serve the client. With this approach, the client can avoid connecting to a heavily loaded node that may cause delays in subsequent in-band I/O operations. Write replication is applied to the remaining nodes through a WR module by utilizing the Unison file synchronization program. A client initially connected to node IP A for write operations will have no hindrances in executing the relevant read operations at node IP B in new connections. In the worst case scenario of a node crashing, data remain recoverable from other functioning nodes. We have conducted several benchmark tests and our results are evaluated and verified in a later section.','10.3745/JIPS.2011.7.1.053  ',490,286,0,0,NULL,NULL),(157,2011,7,1,63,0,'Accelerating the Sweep3D for a Graphic Processor Unit','Sweep3D, Neutron Transport, GPU, CUDA','Chunye Gong, Jie Liu, Haitao Chen, Jing Xie and Zhenghu Gong','dlibrary/JIPS_v07_no1_paper06.pdf','As a powerful and flexible processor, the Graphic Processing Unit (GPU) can offer a great faculty in solving many high-performance computing applications. Sweep3D, which simulates a single group time-independent discrete ordinates (Sn) neutron transport deterministically on 3D Cartesian geometry space, represents the key part of a real ASCI application. The wavefront process for parallel computation in Sweep3D limits the concurrent threads on the GPU. In this paper, we present multi-dimensional optimization methods for Sweep3D, which can be efficiently implemented on the finegrained parallel architecture of the GPU. Our results show that the overall performance of Sweep3D on the CPU-GPU hybrid platform can be improved up to 4.38 times as compared to the CPU-based implementation.','10.3745/JIPS.2011.7.1.063  ',598,405,0,0,NULL,NULL),(158,2011,7,1,75,0,'An Embedding of Multiple Edge-Disjoint Hamiltonian Cycles on Enhanced Pyramid Graphs','Enhanced Pyramid Model, Hamiltonian Cycle, Edge-Disjoint Cycle','Jung-Hwan Chang','dlibrary/JIPS_v07_no1_paper07.pdf','The enhanced pyramid graph was recently proposed as an interconnection network model in parallel processing for maximizing regularity in pyramid networks. We prove that there are two edge-disjoint Hamiltonian cycles in the enhanced pyramid networks. This investigation demonstrates its superior property in edge fault tolerance. This result is optimal in the sense that the minimum degree of the graph is only four.',' 10.3745/JIPS.2011.7.1.075  ',529,579,0,0,NULL,NULL),(159,2011,7,1,85,0,'Effective Partitioning of Static Global Buses for Small Processor Arrays','Processor Array, Dynamically Reconfigurable Bus, Statically Partitioned Bus, Scaling-Simulation, Polylogarithmic Time Simulation','Susumu Matsumae','dlibrary/JIPS_v07_no1_paper08.pdf','This paper shows an effective partitioning of static global row/column buses for tightly coupled 2D mesh-connected small processor arrays (¡°mesh¡±, for short). With additional O(n/m (n/m + log m)) time slowdown, it enables the mesh of size m¡¿m with static row/column buses to simulate the mesh of the larger size n¡¿n with reconfigurable row/column buses (m ¡Â n). This means that if a problem can be solved in O(T) time by the mesh of size n¡¿n with reconfigurable buses, then the same problem can be solved in O(T n/m (n/m + log m)) time on the mesh of a smaller size m¡¿m without a reconfigurable function. This time-cost is optimal when the relation n ¡Ã m log m holds (e.g., m = n1-¥å for ¥å> 0).','10.3745/JIPS.2011.7.1.085  ',516,302,0,0,NULL,NULL),(160,2011,7,1,93,0,'Dynamic Voltage and Frequency Scaling for Power-Constrained Design using Process Voltage and Temperature Sensor Circuits','PVT Variation sensors, Yield, Voltage Scaling, Frequency Scaling','Haiqing Nan, Kyung Ki Kim, Wei Wang and Ken Choi','dlibrary/JIPS_v07_no1_paper09.pdf','In deeply scaled CMOS technologies, two major non-ideal factors are threatening the survival of the CMOS; i) PVT (process, voltage, and temperature) variations and ii) leakage power consumption. In this paper, we propose a novel postsilicon tuning methodology to scale optimum voltage and frequency ¡°dynamically¡±. The proposed design technique will use our PVT sensor circuits to monitor the variations and based on the monitored variation data, voltage and frequency will be compensated ¡°automatically¡±. During the compensation process, supply voltage is dynamically adjusted to guarantee the minimum total power consumption without violating the frequency requirement. The simulation results show that the proposed technique can reduce the total power by 85% and the static power by 53% on average for the selected ISCAS¡¯85 benchmark circuits with 45 nm CMOS technology compared to the results of the traditional PVT compensation method.','10.3745/JIPS.2011.7.1.093  ',548,423,0,0,NULL,NULL),(161,2011,7,1,103,0,'Adaptive Motion Vector Smoothing for Improving Side Information in Distributed Video Coding','Distributed Video Coding, Wyner-Ziv Coding, Spatial Motion Vector Smoothing, Weighted Vector Median Filter, Side Information','Jun Guo and Joohee Kim','dlibrary/JIPS_v07_no1_paper10.pdf','In this paper, an adaptive motion vector smoothing scheme based on weighted vector median filtering is proposed in order to eliminate the motion outliers more effectively for improving the quality of side information in frame-based distributed video coding. We use a simple motion vector outlier reliability measure for each block in a motion compensated interpolated frame and apply weighted vector median filtering only to the blocks with unreliable motion vectors. Simulation results show that the proposed adaptive motion vector smoothing algorithm improves the quality of the side information significantly while maintaining low complexity at the encoder in frame-based distributed video coding.',' 10.3745/JIPS.2011.7.1.103  ',479,358,0,0,NULL,NULL),(162,2011,7,1,111,0,'Security Framework for RFID-based Applications in Smart Home Environment','RFID, Smart Home, Home Network System, Home Server, Secure RFIDBased Applications, RFID Reader-Enabled Devices, RFID Tagged Consumer Items, EPCglobal Architecture Framework','Divyan M. Konidala, Daeyoung Kim, Chan Yeob Yeun and Byoungcheon Lee','dlibrary/JIPS_v07_no1_paper11.pdf','The concept of Smart-Homes is becoming more and more popular. It is anticipated that Radio Frequency IDentification (RFID) technology will play a major role in such environments. We can find many previously proposed schemes that focus solely on: authentication between the RFID tags and readers, and user privacy protection from malicious readers. There has also been much talk of a very popular RFID application: a refrigerator/bookshelf that can scan and list out the details of its items on its display screen. Realizing such an application is not as straight forward as it seems to be, especially in securely deploying such RFID-based applications in a smart home environment. Therefore this paper describes some of the RFID-based applications that are applicable to smart home environments. We then identify their related privacy and security threats and security requirements and also propose a secure approach, where RFID-tagged consumer items, RFID-reader enabled appliances (e.g., refrigerators), and RFID-based applications would securely interact among one another. At the moment our approach is just a conceptual idea, but it sheds light on very important security issues related to RFID-based applications that are beneficial for consumers.','10.3745/JIPS.2011.7.1.111  ',828,586,0,0,NULL,NULL),(163,2011,7,1,121,0,'Ensuring Anonymity for LBSs in Smartphone Environment','Location Based Services, Anonymity, Location Information','Mohammed Alzaabi, Chan Yeob Yeun and Thomas Anthony Martin','dlibrary/JIPS_v07_no1_paper12.pdf','With the rapid growth of GPS-enable Smartphones, the interest on using Location Based Services (LBSs) has increased significantly. The evolution in the functionalities provided by those smartphones has enabled them to accurately pinpoint the location of a user. Because location information is what all LBSs depend on to process user¡¯s request, it should be properly protected from attackers or malicious service providers (SP). Additionally, maintaining user¡¯s privacy and confidentiality are imperative challenges to be overcome. A possible solution for these challenges is to provide user anonymity, which means to ensure that a user initiating a request to the SP should be indistinguishable from a group of people by any adversary who had access to the request. Most of the proposals that maintain user¡¯s anonymity are based on location obfuscation. It mainly focuses on adjusting the resolution of the user¡¯s location information. In this paper, we present a new protocol that is focused on using cryptographic techniques to provide anonymity for LBSs users in the smartphone environment. This protocol makes use of a trusted third party called the Anonymity Server (AS) that ensures anonymous communication between the user and the service provider.','10.3745/JIPS.2011.7.1.121  ',467,277,0,0,NULL,NULL),(164,2011,7,1,137,0,'Handling Malicious Flooding Attacks through Enhancement of Packet Processing Technique in Mobile Ad Hoc Networks','Collaborative Attack, Malicious Flooding Attack, Wireless Ad Hoc Network','HyoJin Kim, Ramachandra Bhargav Chitti and JooSeok Song','dlibrary/JIPS_v07_no1_paper13.pdf','Mobile ad hoc networks are expected to be widely used in the near future. However, they are susceptible to various security threats because of their inherent characteristics. Malicious flooding attacks are one of the fatal attacks on mobile ad hoc networks. These attacks can severely clog an entire network, as a result of clogging the victim node. If collaborative multiple attacks are conducted, it becomes more difficult to prevent. To defend against these attacks, we propose a novel defense mechanism in mobile ad hoc networks. The proposed scheme enhances the amount of legitimate packet processing at each node. The simulation results show that the proposed scheme also improves the end-to-end packet delivery ratio.','10.3745/JIPS.2011.7.1.137  ',595,295,0,0,NULL,NULL),(165,2011,7,1,151,0,'Guess and Determine Attack on Bivium','Bivium, Guess and Determine Attack, Stream Ciphers, Linear Approximations, Entropy','Neda Rohani, Zainab Noferesti, Javad Mohajeri and Mohammad Reza Aref','dlibrary/JIPS_v07_no1_paper14.pdf','Bivium is a simplified version of Trivium, a hardware profile finalist of the eSTREAM project. Bivium has an internal state size of 177 bits and a key length of 80 bits. In this paper, a guess and determine attack on this cipher is introduced. In the proposed method, the best linear approximations for the updating functions are first defined. Then by using these calculated approximations, a system of linear equations is built. By guessing 30 bits of internal state, the system is solved and all the other 147 remaining bits are determined. The complexity of the attack is O (230), which is an improvement to the previous guess and determine attack with a complexity of order O(252.3).','10.3745/JIPS.2011.7.1.151 ',580,615,0,0,NULL,NULL),(166,2011,7,1,159,0,'Generic Constructions for Strong Designated Verifier Signature','Strong Designated Verifier Signature, Ring Signature, Deniable Authenticated Key Exchange, Provable security','Deng-Guo Feng, Jing Xu and Wei-Dong Chen','dlibrary/JIPS_v07_no1_paper15.pdf','A designated verifier signature is a special type of digital signature, which convinces a designated verifier that she has signed a message in such a way that the designated verifier cannot transfer the signature to a third party. A strong designated verifier signature scheme enhances the privacy of the signer such that no one but the designated verifier can verify the signer¡¯s signatures. In this paper we present two generic frame works for constructing strong designated verifier signature schemes from any secure ring signature scheme and any deniable one-pass authenticated key exchange protocol, respectively. Compared with similar protocols, the instantiations of our construction achieve improved efficiency.','10.3745/JIPS.2011.7.1.159',620,327,0,0,NULL,NULL),(167,2011,7,1,173,0,'Virus Detection Method based on Behavior Resource Tree','Computer Virus, Behavior-Based Detection, Dynamic Link Library, Behavior Resource Tree','Mengsong Zou, Lansheng Han, Ming Liu and Qiwen Liu','dlibrary/JIPS_v07_no1_paper16.pdf','Due to the disadvantages of signature-based computer virus detection techniques, behavior-based detection methods have developed rapidly in recent years. However, current popular behavior-based detection methods only take API call sequences as program behavior features and the difference between API calls in the detection is not taken into consideration. This paper divides virus behaviors into separate function modules by introducing DLLs into detection. APIs in different modules have different importance. DLLs and APIs are both considered program calling resources. Based on the calling relationships between DLLs and APIs, program calling resources can be pictured as a tree named program behavior resource tree. Important block structures are selected from the tree as program behavior features. Finally, a virus detection model based on behavior the resource tree is proposed and verified by experiment which provides a helpful reference to virus detection.','10.3745/JIPS.2011.7.1.173',564,438,0,0,NULL,NULL),(168,2011,7,1,187,0,'A Method of Risk Assessment for Multi-Factor Authentication','Multi-factor Authentication, PKI, User Authentication, Biometric Authentication','Jae-Jung Kim and Seng-Phil Hong','dlibrary/JIPS_v07_no1_paper17.pdf','User authentication refers to user identification based on something a user knows, something a user has, something a user is or something the user does; it can also take place based on a combination of two or more of such factors. With the increasingly diverse risks in online environments, user authentication methods are also becoming more diversified. This research analyzes user authentication methods being used in various online environments, such as web portals, electronic transactions, financial services and e-government, to identify the characteristics and issues of such authentication methods in order to present a user authentication level system model suitable for different online services. The results of our method are confirmed through a risk assessment and we verify its safety using the testing method presented in OWASP and NIST SP800-63.','10.3745/JIPS.2011.7.1.187',585,480,0,0,NULL,NULL),(169,2011,7,1,199,0,'Lifting a Metadata Model to the Semantic Multimedia World','Multimedia, Metadata Annotation, Semantic Web Technologies','Gaetan Martens, Ruben Verborgh, Chris Poppe and Rik Van de Walle','dlibrary/JIPS_v07_no1_paper18.pdf','This paper describes best-practices in lifting an image metadata standard to the Semantic Web. We provide guidelines on how an XML-based metadata format can be converted into an OWL ontology. Additionally, we discuss how this ontology can be mapped to the W3C¡¯s Media Ontology. This ontology is a standardization effort of the W3C to provide a core vocabulary for multimedia annotations. The approach presented here can be applied to other XML-based metadata standards.','10.3745/JIPS.2011.7.1.199',529,1220,0,0,NULL,NULL),(170,2011,7,1,209,0,'A Cultural Dimensions Model based on Smart Phone Applications','Smart Phone, Culture, Cultural Dimensions Model, MDS, Mobile Application Analysis','Jung-Min Oh and Nammee Moon','dlibrary/JIPS_v07_no1_paper19.pdf','One of the major factors influencing the phenomenal growth of the smart phone market is the active development applications based on open environments. Despite difficulties in finding and downloading applications due to the small screens and inconvenient interfaces of smart phones, users download applications nearly every day. Such user behavior patterns indicate the significance of smart phone applications. So far, studies on applications have focused mainly on technical approaches, including recommendation systems. Meanwhile, the issue of culture, as an aspect of user characteristics regarding smart phone use, remains largely unexamined throughout the world. Hence, the present study attempts to analyze the highest ranked smart phone applications downloaded and paid for that are ranked the highest in 10 countries (Korea, Japan, China, India, the UK, USA, Indonesia, Canada, France, and Mexico) and we then derive the CDSC (Cultural Dimensions Score of Content) for these applications. The results derived are, then, mapped to the cultural dimensions model to determine the CISC (Cultural Index Score for Country). Further, culturally significant differences in smart phone environments are identified using MDS analysis.','10.3745/JIPS.2011.7.1.209',518,285,0,0,NULL,NULL),(171,2010,7,2,221,0,'An Efficient Broadcast Technique for Vehicular Networks','V2V Communication Protocols, Vehicular Network, Ad Hoc Network, Broadcast, Broadcasting Storm, Routing','Ai Hua Ho, Yao H. Ho, Kien A. Hua, Roy Villafane, and Han-Chieh Chao','dlibrary/JIPS_v07_no2_paper01.pdf','Vehicular networks are a promising application of mobile ad hoc networks. In this paper, we introduce an efficient broadcast technique, called CB-S (Cell Broadcast for Streets), for vehicular networks with occlusions such as skyscrapers. In this environment, the road network is fragmented into cells such that nodes in a cell can communicate with any node within a two cell distance. Each mobile node is equipped with a GPS (Global Positioning System) unit and a map of the cells. The cell map has information about the cells including their identifier and the coordinates of the upper-right and lower-left corner of each cell. CB-S has the following desirable property. Broadcast of a message is performed by rebroadcasting the message from every other cell in the terrain. This characteristic allows CB-S to achieve an efficient performance. Our simulation results indicate that messages always reach all nodes in the wireless network. This perfect coverage is achieved with minimal overhead. That is, CB-S uses a low number of nodes to disseminate the data packets as quickly as probabilistically possible. This efficiency gives it the advantage of low delay. To show these benefits, we give simulations results to compare CB-S with four other broadcast techniques. In practice, CB-S can be used for information dissemination, or to reduce the high cost of destination discovery in routing protocols. By also specify the radius of affected zone, CB-S is also more efficient when broadcast to a subset of the nodes is desirable.','10.3745/JIPS.2011.7.2.221',2985,520,8,0,NULL,NULL),(172,2011,7,2,241,0,'CASPER: Congestion Aware Selection of Path with Efficient Routing in Multimedia Networks','Routing, Multimedia Networks, Congestion-aware Selection, MANET, CASPER, Performance Evaluation','Mohammad S. Obaidat, Sanjay K. Dhurandher and Khushboo Diwakar','dlibrary/JIPS_v07_no2_paper02.pdf','In earlier days, most of the data carried on communication networks was textual data requiring limited bandwidth. With the rise of multimedia and network technologies, the bandwidth requirements of data have increased considerably. If a network link at any time is not able to meet the minimum bandwidth requirement of data, data transmission at that path becomes difficult, which leads to network congestion. This causes delay in data transmission and might also lead to packet drops in the network. The retransmission of these lost packets would aggravate the situation and jam the network. In this paper, we aim at providing a solution to the problem of network congestion in mobile ad hoc networks [1, 2] by designing a protocol that performs routing intelligently and minimizes the delay in data transmission. Our Objective is to move the traffic away from the shortest path obtained by a suitable shortest path calculation algorithm to a less congested path so as to minimize the number of packet drops during data transmission and to avoid unnecessary delay. For this we have proposed a protocol named as Congestion Aware Selection Of Path With Efficient Routing (CASPER). Here, a router runs the shortest path algorithm after pruning those links that violate a given set of constraints. The proposed protocol has been compared with two link state protocols namely, OSPF [3, 4] and OLSR [5, 6, 7, 8].The results achieved show that our protocol performs better in terms of network throughput and transmission delay in case of bulky data transmission.','10.3745/JIPS.2011.7.2.241',2950,850,9,0,NULL,NULL),(173,2011,7,2,261,0,'Packet Scheduling with QoS and Fairness for Downlink Traffic in WiMAX Networks','IEEE.802.16, Scheduling, Round Robin, Weighted Proportional, Fairness','Wei Nie, Houjun Wang and Jong Hyuk Park','dlibrary/JIPS_v07_no2_paper03.pdf','The IEEE 802.16 standard is supposed to provide a wide-range broadband wireless service, but it leaves the implementation of the wireless resource scheduler as an open issue. We have studied the scheduling problem and propose a two level scheduling (TLS) scheme with support for quality of service and fairness guarantees for downlink traffic in a WiMAX network. A central controller Base Station has a number of users, and each mobile subscriber station has different channel conditions. The same mobile subscriber station may have different service requirements at different times in the WiMAX network. Based on OPNET simulation, the results show our scheduling algorithm can increase the network throughput, maintain relative fairness, and lower delay over the round robin and weighted round robin algorithms.','10.3745/JIPS.2011.7.2.261',602,709,0,0,NULL,NULL),(174,2011,7,2,271,0,'Parallel Prefix Computation and Sorting on a Recursive Dual-Net','Interconnection Networks, Algorithm, Parallel Prefix Computation, Sorting','Yamin Li, Shietung Peng and Wanming Chu','dlibrary/JIPS_v07_no2_paper04.pdf','In this paper, we propose efficient algorithms for parallel prefix computation and sorting on a recursive dual-net. The recursive dual-net RDNk(B) for k > 0 has (2no)2K/2 nodes and d0 + k links per node, where n0 and d0 are the number of nod es and the node-degree of the base-network B, respectively. Assume that each node holds one data item, the communication and computation time complexities of the algorithm for parallel prefix computation on RDNk(B), k > 0, are 2k+1-2+2kTcomm(0) and 2 k+1-2+2kTcomp(0), respectively, where Tcomm(0) and Tcomp(0) are the communication and computation time complexities of the algorithm for parallel prefix computation on the base-network B, respectively. The algorithm for parallel sorting on RDNk(B) is restricted on B = Qm where Qm is an m-cube. Assume that each node holds a single data item, the sorting algorithm runs in O((m2k)2) computation steps and O((km2k)2) communication steps, respectively.','10.3745/JIPS.2011.7.2.271',507,534,0,0,NULL,NULL),(175,2011,7,2,287,0,'Evaluating Service Description to Guarantee Quality of U-service Ontology','Quality Model, Quality Metric, Dynamic Service Composition, U-service (Ubiquitous-Service) Ontology, U-service Description Specification','Meeyeon Lee, Jung-Won Lee, Kyung-Ah Kim and Seung Soo Park','dlibrary/JIPS_v07_no2_paper05.pdf','Efficient service description and modeling methodologies are essential for dynamic service composition to provide autonomous services for users in ubiquitous computing environments. In our previous research, we proposed a ¡®u-service¡¯ ontology which is an abstract and structured concept for device operations in ubiquitous environments. One of the problems that we faced during the design process was that there are not enough standards to analyze the effectiveness of a u-service ontology. In this paper, we propose a quality evaluation model to facilitate the design process of a uservice ontology. We extract modeling goals and evaluation indicators based on the uservice description specification. We also present quality metrics to quantify each of the design properties. The experiment result of the proposed quality model shows that we can use it to analyze the design of u-service ontology from various angles. Also, it shows that the model can provide a guideline, and offer appropriate recommendations for improvements.','10.3745/JIPS.2011.7.2.287',664,335,0,0,NULL,NULL),(176,2011,7,2,299,0,'Batch Resizing Policies and Techniques for Fine-Grain Grid Tasks: The Nuts and Bolts','Batch Resizing, Task Granularity, Global Grid, Application Turnaround Time','Nithiapidary Muthuvelu, Ian Chai, Eswaran Chikkannan and Rajkumar Buyya','dlibrary/JIPS_v07_no2_paper06.pdf','The overhead of processing fine-grain tasks on a grid induces the need for batch processing or task group deployment in order to minimise overall application turnaround time. When deciding the granularity of a batch, the processing requirements of each task should be considered as well as the utilisation constraints of the interconnecting network and the designated resources. However, the dynamic nature of a grid requires the batch size to be adaptable to the latest grid status. In this paper, we describe the policies and the specific techniques involved in the batch resizing process. We explain the nuts and bolts of these techniques in order to maximise the resulting benefits of batch processing. We conduct experiments to determine the nature of the policies and techniques in response to a real grid environment. The techniques are further investigated to highlight the important parameters for obtaining the appropriate task granularity for a grid resource.','10.3745/JIPS.2011.7.2.299',534,291,0,0,NULL,NULL),(177,2011,7,2,321,0,'Development of an OPC Client-Server Framework for Monitoring and Control Systems','OPC, OPC UA SDK, Monitoring and Control, Redundancy, Unified Architecture','Vu Van Tan and Myeong-Jae Yi','dlibrary/JIPS_v07_no2_paper07.pdf','In this article, the current technological state of OPC (Openness, Productivity, and Collaboration; formerly ¡°OLE for Process Control¡±) standards and the problem statement of these OPC standards are discussed. The development of an OPC clientserver framework for monitoring and control systems is introduced by using the new OPC Unified Architecture (UA) specifications, Service Oriented Architecture (SOA), web services, XML, etc. The developed framework in turn minimizes the efforts of developers in learning new techniques and allows system architects and designers to perform dependency analysis on the development of monitoring and control applications. The potential areas of the proposed framework and the redundancy strategies to increase the efficiency and reliability of the system are also represented according to the initial results from the system that was developed by the Visual Studio 2008 and OPC UA SDK.','10.3745/JIPS.2011.7.2.321',557,2417,0,0,NULL,NULL),(178,2011,7,2,341,0,'Analysis of Generalized Impact Factors and the Indices of Journals','Information Systems, Quality of Research, Impact factor, h-index, g-index','Ash Mohammad Abbas','dlibrary/JIPS_v07_no2_paper08.pdf','Analyzing the relationships among the parameters for quantifying the quality of research published in journals is a challenging task. In this paper, we analyze the relationships between the impact factor, h-index, and g-index of a journal. To keep our analysis simple and easy to understand, we consider a generalized version of the impact factor where there is no time window. In the absence of the time window, the impact factor converges to the number of citations received per paper. This is not only justified for the impact factor, it also simplifies the analysis of the h-index and g-index as well because addition of a time window in the form of years complicates the computation of indices too. We derive the expressions for the relationships among impact factor, h index, and g-index and validate them using a given set of publication-citation data.','10.3745/JIPS.2011.7.2.341',971,319,0,0,NULL,NULL),(179,2011,7,2,355,0,'Design of Multi-dimensional Contents Retrieval UI for Mobile IPTV','Mobile IPTV, UI(User Interface), Contents Browser, EPG, Personalized Content, Interactive Service','Jaehee Byeon, Ju-Hong Song and Nammee Moon','dlibrary/JIPS_v07_no2_paper09.pdf','Since two-way interactive broadcasting service began, remote controls have been fitted with 4 color buttons, which enables interaction and convenience to increase between users and content. Currently, diverse studies on IPTV are in progress. Particularly, as the mobile market rapidly grows, studies on mobile IPTV and on linkage with other media are constantly increasing. However, mobile IPTV has never been studied until now. In that sense, this present study attempted to design a mobile-based IPTV UI that could use a multi-dimensional search method based on consistent criteria for content search. As a result, the proposed IPTV UI is fitted with more usability and functionality for 4 color buttons. The UI designed in this study was compared to the IMDb Android Application, which uses GOMS-KLM. The results showed that the performance process was reduced by three stages, and that the performance time was reduced by more than 17.9%. Therefore, the conclusion can be reached that the proposed UI is effective for a fast search of contents.','10.3745/JIPS.2011.7.2.355',636,450,0,0,NULL,NULL),(180,2011,7,2,363,0,'An Adequacy Based Test Data Generation Technique Using Genetic Algorithms','Software Testing, Adequacy Based Testing Criteria, Reliability Based Testing Criteria, Genetic Algorithms, Mutation Analysis','Ruchika Malhotra and Mohit Garg','dlibrary/JIPS_v07_no2_paper10.pdf','As the complexity of software is increasing, generating an effective test data has become a necessity. This necessity has increased the demand for techniques that can generate test data effectively. This paper proposes a test data generation technique based on adequacy based testing criteria. Adequacy based testing criteria uses the concept of mutation analysis to check the adequacy of test data. In general, mutation analysis is applied after the test data is generated. But, in this work, we propose a technique that applies mutation analysis at the time of test data generation only, rather than applying it after the test data has been generated. This saves significant amount of time (required to generate adequate test cases) as compared to the latter case as the total time in the latter case is the sum of the time to generate test data and the time to apply mutation analysis to the generated test data. We also use genetic algorithms that explore the complete domain of the program to provide near-global optimum solution. In this paper, we first define and explain the proposed technique. Then we validate the proposed technique using ten real time programs. The proposed technique is compared with path testing technique (that use reliability based testing criteria) for these ten programs. The results show that the adequacy based proposed technique is better than the reliability based path testing technique and there is a significant reduce in number of generated test cases and time taken to generate test cases.','10.3745/JIPS.2011.7.2.363',677,350,0,0,NULL,NULL),(181,2011,7,2,385,0,'Analysis of Business Attributes in Information Technology Environments','Business Attributes, Information Technology, Value Chain, Business System','Hong Joo Lee','dlibrary/JIPS_v07_no2_paper11.pdf','Information technology is changing the business value chain and business systems. This situation is due to the business value chain and the value creation factors in business. Technology companies and researchers are developing new businesses, but many companies and researchers cannot find successful ways to analyze and develop a business in a specific way. In this paper, the following will be explored. First, the value creation motive in business is analyzed through a literary review. Second, business attributes are analyzed while considering the value creation motive and business factors in management. Finally, the business attributes of information technology are studied through a review of previous research that has been conducted on this topic.','10.3745/JIPS.2011.7.2.385',520,379,0,0,NULL,NULL),(182,2011,7,3,397,0,'The Principle of Justifiable Granularity and an Optimization of Information Granularity Allocation as Fundamentals of Granular Computing','Information Granularity, Principle of Justifiable Granularity, Knowledge Management, Optimal Granularity Allocation','Witold Pedrycz','dlibrary/JIPS_v07_no3_paper01.pdf','Granular Computing has emerged as a unified and coherent framework of designing, processing, and interpretation of information granules. Information granules are formalized within various frameworks such as sets (interval mathematics), fuzzy sets, rough sets, shadowed sets, probabilities (probability density functions), to name several the most visible approaches. In spite of the apparent diversity of the existing formalisms, there are some underlying commonalities articulated in terms of the fundamentals, algorithmic developments and ensuing application domains. In this study, we introduce two pivotal concepts: a principle of justifiable granularity and a method of an optimal information allocation where information granularity is regarded as an important design asset. We show that these two concepts are relevant to various formal setups of information granularity and offer constructs supporting the design of information granules and their processing. A suite of applied studies is focused on knowledge management in which case we identify several key categories of schemes present there.','10.3745/JIPS.2011.7.3.397',3311,1037,10,0,NULL,NULL),(183,2011,7,3,413,0,'A Novel Similarity Measure for Sequence Data','Sequence Data, Similarity Measure, Sequence Mining','Mohammad. H. Pandi, Omid Kashefi and Behrouz Minaei','dlibrary/JIPS_v07_no3_paper02.pdf','A variety of different metrics has been introduced to measure the similarity of two given sequences. These widely used metrics are ranging from spell correctors and categorizers to new sequence mining applications. Different metrics consider different aspects of sequences, but the essence of any sequence is extracted from the ordering of its elements. In this paper, we propose a novel sequence similarity measure that is based on all ordered pairs of one sequence and where a Hasse diagram is built in the other sequence. In contrast with existing approaches, the idea behind the proposed sequence similarity metric is to extract all ordering features to capture sequence properties. We designed a clustering problem to evaluate our sequence similarity metric. Experimental results showed the superiority of our proposed sequence similarity metric in maximizing the purity of clustering compared to metrics such as d2, Smith-Waterman, Levenshtein, and Needleman-Wunsch. The limitation of those methods originates from some neglected sequence features, which are considered in our proposed sequence similarity metric.','10.3745/JIPS.2011.7.3.413',721,593,0,0,NULL,NULL),(184,2011,7,3,425,0,'Wavelet-based Feature Extraction Algorithm for an Iris Recognition System','Biometrics, Degrees of Freedom, Iris Recognition, Wavelet','Ayra Panganiban, Noel Linsangan and Felicito Caluyo','dlibrary/JIPS_v07_no3_paper03.pdf','The success of iris recognition depends mainly on two factors: image acquisition and an iris recognition algorithm. In this study, we present a system that considers both factors and focuses on the latter. The proposed algorithm aims to find out the most efficient wavelet family and its coefficients for encoding the iris template of the experiment samples. The algorithm implemented in software performs segmentation, normalization, feature encoding, data storage, and matching. By using the Haar and Biorthogonal wavelet families at various levels feature encoding is performed by decomposing the normalized iris image. The vertical coefficient is encoded into the iris template and is stored in the database. The performance of the system is evaluated by using the number of degrees of freedom, False Reject Rate (FRR), False Accept Rate (FAR), and Equal Error Rate (EER) and the metrics show that the proposed algorithm can be employed for an iris recognition system.','10.3745/JIPS.2011.7.3.425',761,507,0,0,NULL,NULL),(185,2011,7,3,435,0,'Probabilistic Soft Error Detection Based on Anomaly Speculation','Probabilistic Soft Error Detection, Reliability, Anomaly Speculation','Joonhyuk Yoo','dlibrary/JIPS_v07_no3_paper04.pdf','Microprocessors are becoming increasingly vulnerable to soft errors due to the current trends of semiconductor technology scaling. Traditional redundant multithreading architectures provide perfect fault tolerance by re-executing all the computations. However, such a full re-execution technique significantly increases the verification workload on the processor resources, resulting in severe performance degradation. This paper presents a pro-active verification management approach to mitigate the verification workload to increase its performance with a minimal effect on overall reliability. An anomaly-speculation-based filter checker is proposed to guide a verification priority before the re-execution process starts. This technique is accomplished by exploiting a value similarity property, which is defined by a frequent occurrence of partially identical values. Based on the biased distribution of similarity distance measure, this paper investigates further application to exploit similar values for soft error tolerance with anomaly speculation. Extensive measurements prove that the majority of instructions produce values, which are different from the previous result value, only in a few bits. Experimental results show that the proposed scheme accelerates the processor to be 180% faster than traditional fully-fault-tolerant processor with a minimal impact on overall soft error rate.','10.3745/JIPS.2011.7.3.435',503,371,0,0,NULL,NULL),(186,2011,7,3,447,0,'An Approach to Art Collections Management and Content-based Recovery','Search by Content, Faceted Classification, IT, Collections Management, Metadata, Information Retrieval','Concepcion Perez de Celis Herrero, Jaime Lara Alvarez, Gustavo Cossio Aguilar and Maria J. Somodevilla Garcia','dlibrary/JIPS_v07_no3_paper05.pdf','This study presents a comprehensive solution to the collection management, which is based on the model for Cultural Objects (CCO). The developed system manages and spreads the collections that are safeguarded in museums and galleries more easily by using IT. In particular, we present our approach for a non-structured search and recovery of the objects based on the annotation of artwork images. In this methodology, we have introduced a faceted search used as a framework for multi-classification and for exploring/browsing complex information bases in a guided, yet unconstrained way, through a visual interface.','10.3745/JIPS.2011.7.3.447',641,466,0,0,NULL,NULL),(187,2011,7,3,459,0,'Utilizing Various Natural Language Processing Techniques for Biomedical Interaction Extraction','Biomedical Interaction Extraction, Natural Language Processing, Interaction Verb Extraction, Argument Relation Identification','Kyung-Mi Park, Han-Cheol Cho and Hae-Chang Rim','dlibrary/JIPS_v07_no3_paper06.pdf','The vast number of biomedical literature is an important source of biomedical interaction information discovery. However, it is complicated to obtain interaction information from them because most of them are not easily readable by machine. In this paper, we present a method for extracting biomedical interaction information assuming that the biomedical Named Entities (NEs) are already identified. The proposed method labels all possible pairs of given biomedical NEs as INTERACTION or NOINTERACTION by using a Maximum Entropy (ME) classifier. The features used for the classifier are obtained by applying various NLP techniques such as POS tagging, base phrase recognition, parsing and predicate-argument recognition. Especially, specific verb predicates (activate, inhibit, diminish and etc.) and their biomedical NE arguments are very useful features for identifying interactive NE pairs. Based on this, we devised a twostep method: 1) an interaction verb extraction step to find biomedically salient verbs, and 2) an argument relation identification step to generate partial predicate-argument structures between extracted interaction verbs and their NE arguments. In the experiments, we analyzed how much each applied NLP technique improves the performance. The proposed method can be completely improved by more than 2% compared to the baseline method. The use of external contextual features, which are obtained from outside of NEs, is crucial for the performance improvement. We also compare the performance of the proposed method against the co-occurrence-based and the rule-based methods. The result demonstrates that the proposed method considerably improves the performance.','10.3745/JIPS.2011.7.3.459',560,417,0,0,NULL,NULL),(188,2011,7,3,473,0,'Integrated Software Quality Evaluation: A Fuzzy Multi-Criteria Approach','Software Quality Parameters, ISO/IEC 9126, Fuzzy Software Quality Quantification Tool (FSQQT), Fuzzy Membership Function, Triangular Fuzzy Sets, KLOC, GUI, CUI','Jagat Sesh Challa, Arindam Paul, Yogesh Dada, Venkatesh Nerella, Praveen Ranjan Srivastava and Ajit Pratap Singh','dlibrary/JIPS_v07_no3_paper07.pdf','Software measurement is a key factor in managing, controlling, and improving the software development processes. Software quality is one of the most important factors for assessing the global competitive position of any software company. Thus the quantification of quality parameters and integrating them into quality models is very essential. Software quality criteria are not very easily measured and quantified. Many attempts have been made to exactly quantify the software quality parameters using various models such as ISO/IEC 9126 Quality Model, Boehm’s Model, McCall’s model, etc. In this paper an attempt has been made to provide a tool for precisely quantifying software quality factors with the help of quality factors stated in ISO/IEC 9126 model. Due to the unpredictable nature of the software quality attributes, the fuzzy multi criteria approach has been used to evolve the quality of the software.','10.3745/JIPS.2011.7.3.473',1059,652,0,0,NULL,NULL),(189,2011,7,3,519,0,'A Fast Snake Algorithm for Tracking Multiple Objects','Snake, Detec tion, Tracking, Multiple Objects, Topology Changes','Hua Fang, JeongWoo Kim and JongWhan Jang','dlibrary/JIPS_v07_no3_paper08.pdf','A Snake is an active contour for representing object contours. Traditional snake algorithms are often used to represent the contour of a single object. However, if there is more than one object in the image, the snake model must be adaptive to determine the corresponding contour of each object. Also, the previous initialized snake contours risk getting the wrong results when tracking multiple objects in successive frames due to the weak topology changes. To overcome this problem, in this paper, we present a new snake method for efficiently tracking contours of multiple objects. Our proposed algorithm can provide a straightforward approach for snake contour rapid splitting and connection, which usually cannot be gracefully handled by traditional snakes. Experimental results of various test sequence images with multiple objects have shown good performance, which proves that the proposed method is both effective and accurate.','10.3745/JIPS.2011.7.3.519',607,1401,0,0,NULL,NULL),(190,2011,7,3,531,0,'A Fair and Efficient Congestion Avoidance Scheme Based on the Minority Game','Congestion Control, AIMD, Minority Game','Hiroshi Kutsuna and Satoshi Fujita','dlibrary/JIPS_v07_no3_paper09.pdf','In this paper, we propose a new congestion control scheme for high-speed networks. The basic idea of our proposed scheme is to adopt a game theory called, “Minority Game” (MG), to realize a selective reduction of the transmission speed of senders. More concretely, upon detecting any congestion, the scheme starts a game among all senders who are participating in the communication. The losers of the game reduce the transmission speed by a multiplicative factor. MG is a game that has recently attracted considerable attention, and it is known to have a remarkable property so that the number of winners converges to a half the number of players in spite of the selfish behavior of the players to increase its own profit. By using this property of MG, we can realize a fair reduction of the transmission speed, which is more efficient than the previous schemes in which all senders uniformly reduce their transmission speed. The effect of the proposed scheme is evaluated by simulation. The result of simulations indicates that the proposed scheme certainly realizes a selective reduction of the transmission speed. It is sufficiently fair compared to other simple randomized schemes and is sufficiently efficient compared to other conventional schemes.','10.3745/JIPS.2011.7.3.531',517,368,0,0,NULL,NULL),(191,2011,7,3,543,0,'A Study on the Business Strategy of Smart Devices for Multimedia Contents','Smart Device, Business Strategy, Business Value Chain','Hong Joo Lee','dlibrary/JIPS_v07_no3_paper10.pdf','Information technology is changing the business value chain and business systems. This situation is due to the business value chain and the value creation factors in business. Technology companies and researchers are developing new businesses, but many companies and researchers cannot find successful ways to analyze and develop a business in a specific way. In this paper, first, the value creation motive in business is analyzed through a literature review. Second, business attributes are analyzed, while considering the value creation motive and the business factors in management. Finally, the business attributes of information technology are studied through a review of previous research papers on this topic.','10.3745/JIPS.2011.7.3.543',557,617,0,0,NULL,NULL),(192,2011,7,3,549,0,'Efficient Proof of Vote Validity Without Honest-Verifier Assumption in Homomorphic E-Voting','Efficient Proof, E-Voting','Kun Peng','dlibrary/JIPS_v07_no3_paper11.pdf','Vote validity proof and verification is an efficiency bottleneck and privacy drawback in homomorphic e-voting. The existing vote validity proof technique is inefficient and only achieves honest-verifier zero knowledge. In this paper, an efficient proof and verification technique is proposed to guarantee vote validity in homomorphic e-voting. The new proof technique is mainly based on hash function operations that only need a very small number of costly public key cryptographic operations. It can handle untrusted verifiers and achieve stronger zero knowledge privacy. As a result, the efficiency and privacy of homomorphic e-voting applications will be significantly improved.','10.3745/JIPS.2011.7.3.549',605,535,0,0,NULL,NULL),(193,2011,7,4,561,0,'A Survey of RFID Deployment and Security Issues','RFID, RFID Standards, RFID Protocols, RFID Security, EPC structure, RFID Applications, RFID Classification','Amit Grover and Hal Berghel','dlibrary/JIPS_v07_no4_paper01.pdf','This paper describes different aspects of a typical RFID implementation. Section 1 provides a brief overview of the concept of Automatic Identification and compares the use of different technologies while Section 2 describes the basic components of a typical RFID system. Section 3 and Section 4 deal with the detailed specifications of RFID transponders and RFID interrogators respectively. Section 5 highlights different RFID standards and protocols and Section 6 enumerates the wide variety of applications where RFID systems are known to have made a positive improvement. Section 7 deals with privacy issues concerning the use of RFIDs and Section 8 describes common RFID system vulnerabilities. Section 9 covers a variety of RFID security issues, followed by a detailed listing of countermeasures and precautions in Section 10.','10.3745/JIPS.2011.7.4.561',3400,3351,11,0,NULL,NULL),(194,2011,7,4,581,0,'A Multi-Application Controller for SAGE-enabled Tiled Display Wall in Wide-area Distributed Computing Environments','T iled Display Wall, SAGE, Multiple Application Control','Yuki Fujiwara, Susumu Date, Kohei Ichikawa and Haruo Takemura','dlibrary/JIPS_v07_no4_paper02.pdf','Due to the recent advancement of networking and high-performance computing technologies, scientists can easily access large-scale data captured by scientific measurement devices through a network, and use huge computational power harnessed on the Internet for their analyses of scientific data. However, visualization technology, which plays a role of great importance for scientists to intuitively understand the analysis results of such scientific data, is not fully utilized so that it can seamlessly benefit from recent high-performance and networking technologies. One of such visualization technologies is SAGE (Scalable Adaptive Graphics Environment), which allows people to build an arbitrarily sized tiled display wall and is expected to be applied to scientific research. In this paper, we present a multi-application controller for SAGE, which we have developed, in the hope that it will help scientists efficiently perform scientific research requiring high-performance computing and visualization. The evaluation in this paper indicates that the efficiency of completing a comparison task among multiple data is increased by our system.','10.3745/JIPS.2011.7.4.581',927,718,0,0,NULL,NULL),(195,2011,7,4,595,0,'A Cascaded Fuzzy Inference System for University Non-Teaching Staff Performance Appraisal','Performance Appraisal, Cascaded Fuzzy Inference System, University Non-Teaching Staff, Sensitivity Analysis, Gaussian MF, Fuzzy Rules','Amartya Neogi, Abhoy Chand Mondal and Soumitra Kumar Mandal','dlibrary/JIPS_v07_no4_paper03.pdf','Most organizations use performance appraisal system to evaluate the effectiveness and efficiency of their employees. In evaluating staff performance, performance appraisal usually involves awarding numerical values or linguistic labels to employees performance. These values and labels are used to represent each staff achievement by reasoning incorporated in the arithmetical or statistical methods. However, the staff performance appraisal may involve judgments which are based on imprecise data especially when a person (the superior) tries to interpret another person’s (his/her subordinate) performance. Thus, the scores awarded by the appraiser are only approximations. From fuzzy logic perspective, the performance of the appraisee involves the measurement of his/her ability, competence and skills, which are actually fuzzy concepts that can be captured in fuzzy terms. Accordingly, fuzzy approach can be used to handle these imprecision and uncertainty information. Therefore, the performance appraisal system can be examined using Fuzzy Logic Approach, which is carried out in the study. The study utilized a Cascaded fuzzy inference system to generate the performance qualities of some University non-teaching staff that are based on specific performance appraisal criteria.','10.3745/JIPS.2011.7.4.595',902,812,0,0,NULL,NULL),(196,2011,7,4,613,0,'An Efficient DVS Algorithm for Pinwheel Task Schedules','Hard Real-time Systems, Power-aware Scheduling, Dynamic Voltage Scaling, Pinwheel Tasks','Da-Ren Chen and You-Shyang Chen','dlibrary/JIPS_v07_no4_paper04.pdf','In this paper, we focus on the pinwheel task model with a variable voltage processor with d discrete voltage/speed levels. We propose an intra-task DVS algorithm, which constructs a minimum energy schedule for k tasks in O(d+k log k) time. We also give an inter-task DVS algorithm with O(d+n log n) time, where n denotes th e number of jobs. Previous approaches solve this problem by generating a canonical schedule beforehand and adjusting the tasks’ speed in O(dn log n) or O(n3) time. However, the length of a canonical schedule depends on the hyper period of those task periods and is of exponential length in general. In our approach, the tasks with arbitrary periods are first transformed into harmonic periods and then profile their key features. Afterward, an optimal discrete voltage schedule can be computed directly from those features.','10.3745/JIPS.2011.7.4.613',871,484,0,0,NULL,NULL),(197,2011,7,4,627,0,'Partial Bicasting with Buffering for Proxy Mobile IPv6 Handover in Wireless Networks','Proxy Mobile IPv6, Handover, Partial Bicasting, Buffering, Simulation Analysis','Ji-In Kim and Seok-Joo Koh','dlibrary/JIPS_v07_no4_paper05.pdf','This paper addresses the Proxy Mobile IPv6 (PMIP) handover using bicasting in mobile/wireless networks. The bicasting scheme can be used to support the PMIP handover, which tends to waste the network resources of wireless links and incurs data losses during handover. We propose an enhanced scheme of PMIP handover, called the partial bicasting with buffering for PMIP (PBB-PMIP). In the PBB-PMIP handover, the bicasting is performed in the “partial” region between the Local Mobility Anchor (LMA) and the Mobile Access Gateway (MAG), when a mobile node is in the handover area. The data packets are buffered at the new MAG during handover to reduce data losses and are then forwarded to mobile nodes after handover. By ns-2 simulations, the proposed PBB-PMIP scheme is compared with the existing schemes of PMIP and PMIP with bicasting. The proposed scheme can benefit from the reduction of handover delay and packet loss, and the effective use of the network resources of wireless links, as compared to the existing handover schemes.','10.3745/JIPS.2011.7.4.627',894,617,0,0,NULL,NULL),(198,2011,7,4,635,0,'A Model Comparison for Spatiotemporal Data in Ubiquitous Environments: A Case Study','Parametric Data Model, Model Comparison, ParaSQL, Spatiotemporal Data','Seo-Young Noh and Shashi K. Gadia','dlibrary/JIPS_v07_no4_paper06.pdf','In ubiquitous environments, many applications need to process data with time and space dimensions. Because of this, there is growing attention not only on gathering spatiotemporal data in ubiquitous environments, but also on processing such data in databases. In order to obtain the full benefits from spatiotemporal data, we need a data model that naturally expresses the properties of spatiotemporal data. In this paper, we introduce three spatiotemporal data models extended from temporal data models. The main goal of this paper is to determine which data model is less complex in the spatiotemporal context. To this end, we compare their query languages in the complexity aspect because the complexity of a query language is tightly coupled with its underlying data model. Throughout our investigations, we show that it is important to intertwine space and time dimensions and keep one-to-one correspondence between an object in the real world and a tuple in a database in order to naturally express queries in ubiquitous applications.','10.3745/JIPS.2011.7.4.635',833,471,0,0,NULL,NULL),(199,2011,7,4,653,0,'Performance Evaluation of the WiMAX Network Based on Combining the 2D Markov Chain and MMPP Traffic Model','WiMAX, Markov Arrival Process, Markov Modulated Poisson Process, Two dimensional Markov Chain','Tonmoy Saha, Md. Abu Shufean, Mahbubul Alam and Md. Imdadul Islam','dlibrary/JIPS_v07_no4_paper07.pdf','WiMAX is intended for fourth generation wireless mobile communications where a group of users are provided with a connection and a fixed length queue. In present literature traffic of such network is analyzed based on the generator matrix of the Markov Arrival Process (MAP). In this paper a simple analytical technique of the two dimensional Markov chain is used to obtain the trajectory of the congestion of the network as a function of a traffic parameter. Finally, a two state phase dependent arrival process is considered to evaluate probability states. The entire analysis is kept independent of modulation and coding schemes.','10.3745/JIPS.2011.7.4.653',972,601,0,0,NULL,NULL),(200,2011,7,4,679,0,'Performance Evaluation of Finite Queue Switching Under Two-Dimensional M/G/1(m) Traffic','Carried Traffic, LST, Two-Dimensional Traffic, Cell Dropping Probability, M/G/1 Model','Md. Syeful Islam, Md. Rezaur Rahman, Anupam Roy, Md. Imdadul Islam and M. R. Amin','dlibrary/JIPS_v07_no4_paper08.pdf','In this paper we consider a local area network (LAN) of dual mode service where one is a token bus and the other is a carrier sense multiple access with a collision detection (CSMA/CD) bus. The objective of the paper is to find the overall cell/packet dropping probability of a dual mode LAN for finite length queue M/G/1(m) traffic. Here, the offered traffic of the LAN is taken to be the equivalent carried traffic of a one-millisecond delay. The concept of a tabular solution for two-dimensional Poisson’s traffic of circuit switching is adapted here to find the cell dropping probability of the dual mode packet service. Although the work is done for the traffic of similar bandwidth, it can be extended for the case of a dissimilar bandwidth of a circuit switched network.','10.3745/JIPS.2011.7.4.679',1102,404,0,0,NULL,NULL),(201,2011,7,4,691,0,'Grobner Basis Attacks on Lightweight RFID Authentication Protocols','RFID, Authentication Protocol, Algebraic Attack, Grobner Basis','Daewan Han','dlibrary/JIPS_v07_no4_paper09.pdf','Since security and privacy problems in RFID systems have attracted much attention, numerous RFID authentication protocols have been suggested. One of the various design approaches is to use light-weight logics such as bitwise Boolean operations and addition modulo 2m between m-bits words. Because these operations can be implemented in a small chip area, that is the major requirement in RFID protocols, a series of protocols have been suggested conforming to this approach. In this paper, we present new attacks on these lightweight RFID authentication protocols by using the Grobner basis. Our attacks are superior to previous ones for the following reasons: since we do not use the specific characteristics of target protocols, they are generally applicable to various ones. Furthermore, they are so powerful that we can recover almost all secret information of the protocols. For concrete examples, we show that almost all secret variables of six RFID protocols, LMAP, M2AP, EMAP, SASI, Lo et al.\"s protocol, and Lee et al.\"s protocol, can be recovered within a few seconds on a single PC.','10.3745/JIPS.2011.7.4.691',894,411,0,0,NULL,NULL),(202,2011,7,4,707,0,'A Log Analysis System with REST Web Services for Desktop Grids and its Application to Resource Group-based Task Scheduling','Desktop Grids, Execution Behavior, Log Analysis System, REST Web Services, Resource Group-based Task Scheduling','Joon-Min Gil and Mihye Kim','dlibrary/JIPS_v07_no4_paper10.pdf','It is important that desktop grids should be able to aggressively deal with the dynamic properties that arise from the volatility and heterogeneity of resources. Therefore, it is required that task scheduling be able to positively consider the execution behavior that is characterized by an individual resource. In this paper, we implement a log analysis system with REST web services, which can analyze the execution behavior by utilizing the actual log data of desktop grid systems. To verify the log analysis system, we conducted simulations and showed that the resource group-based task scheduling, based on the analysis of the execution behavior, offers a faster turnaround time than the existing one even if few resources are used.','10.3745/JIPS.2011.7.4.707',1113,569,0,0,NULL,NULL),(203,2011,7,4,717,0,'Stream-based Biomedical Classification Algorithms for Analyzing Biosignals','Data Stream Mining, VFDT, OVFDT, C4.5 and Biomedical Domain','Simon Fong, Yang Hang, Sabah Mohammed and Jinan Fiaidhi','dlibrary/JIPS_v07_no4_paper11.pdf','Classification in biomedical applications is an important task that predicts or classifies an outcome based on a given set of input variables such as diagnostic tests or the symptoms of a patient. Traditionally the classification algorithms would have to digest a stationary set of historical data in order to train up a decision-tree model and the learned model could then be used for testing new samples. However, a new breed of classification called stream-based classification can handle continuous data streams, which are ever evolving, unbound, and unstructured, for instance--biosignal live feeds. These emerging algorithms can potentially be used for real-time classification over biosignal data streams like EEG and ECG, etc. This paper presents a pioneer effort that studies the feasibility of classification algorithms for analyzing biosignals in the forms of infinite data streams. First, a performance comparison is made between traditional and stream-based classification. The results show that accuracy declines intermittently for traditional classification due to the requirement of model re-learning as new data arrives. Second, we show by a simulation that biosignal data streams can be processed with a satisfactory level of performance in terms of accuracy, memory requirement, and speed, by using a collection of stream-mining algorithms called Optimized Very Fast Decision Trees. The algorithms can effectively serve as a corner-stone technology for real-time classification in future biomedical applications.','10.3745/JIPS.2011.7.4.717',1435,827,0,0,NULL,NULL),(204,2012,8,1,1,0,'Indoor Link Quality Comparison of IEEE 802.11a Channels in a Multi-radio Mesh Network Testbed','IEEE 802.11a, Indoor Test Bed, Link Quality, Wireless Mesh Networks','Asitha U Bandaranayake, Vaibhav Pandit and Dharma P. Agrawal','dlibrary/JIPS_v08_no1_paper01.pdf','The most important criterion for achieving the maximum performance in a wireless mesh network (WMN) is to limit the interference within the network. For this purpose, especially in a multi-radio network, the best option is to use non-overlapping channels among different radios within the same interference range. Previous works that have considered non-overlapping channels in IEEE 802.11a as the basis for performance optimization, have considered the link quality across all channels to be uniform. In this paper, we present a measurement-based study of link quality across all channels in an IEEE 802.11a-based indoor WMN test bed. Our results show that the generalized assumption of uniform performance across all channels does not hold good in practice for an indoor environment and signal quality depends on the geometry around the me routers.','10.3745/JIPS.2012.8.1.001',3345,1246,12,0,NULL,NULL),(205,2012,8,1,21,0,'Optimal Software Release Using Time and Cost Benefits via Fuzzy Multi-Criteria and Fault Tolerance','Software Testing, Fuzzy Multi-Criteria Approach, Fuzzy Logic, Fuzzy Rules Based, Confidence, Centre of Gravity, Fault Tolerance, Kilo Line of Code (KLOC), Software Development Effort (SDE), Software Test Effort (STE), Decision Makers (DM)','Praveen Ranjan Srivastava','dlibrary/JIPS_v08_no1_paper02.pdf','As we know every software development process is pretty large and consists of different modules. This raises the idea of prioritizing different software modules so that important modules can be tested by preference. In the software testing process, it is not possible to test each and every module regressively, which is due to time and cost constraints. To deal with these constraints, this paper proposes an approach that is based on the fuzzy multi-criteria approach for prioritizing several software modules and calculates optimal time and cost for software testing by using fuzzy logic and the fault tolerance approach.','10.3745/JIPS.2012.8.1.021',1078,532,0,0,NULL,NULL),(206,2012,8,1,55,0,'A Dual Modeling Method for a Real-Time Palpation Simulator','Haptic Feedback, Dual Model, Palpation, Real-Time Simulation, S-chain Model','Sang-Youn Kim, Sekil Park and Jinah Park','dlibrary/JIPS_v08_no1_paper03.pdf','This paper presents a dual modeling method that simulates the graphic and haptic behavior of a volumetric deformable object and conveys the behavior to a human operator. Although conventional modeling methods (a mass-spring model and a finite element method) are suitable for the real-time computation of an object\"\'\"s deformation, it is not easy to compute the haptic behavior of a volumetric deformable object with the conventional modeling method in real-time (within a 1kHz) due to a computational burden. Previously, we proposed a fast volume haptic rendering method based on the S-chain model that can compute the deformation of a volumetric non-rigid object and its haptic feedback in real-time. When the S-chain model represents the object, the haptic feeling is realistic, whereas the graphical results of the deformed shape look linear. In order to improve the graphic and haptic behavior at the same time, we propose a dual modeling framework in which a volumetric haptic model and a surface graphical model coexist. In order to inspect the graphic and haptic behavior of objects represented by the proposed dual model, experiments are conducted with volumetric objects consisting of about 20,000 nodes at a haptic update rate of 1000Hz and a graphic update rate of 30Hz. We also conduct human factor studies to show that the haptic and graphic behavior from our model is realistic. Our experiments verify that our model provides a realistic haptic and graphic feeling to users in real-time.','10.3745/JIPS.2012.8.1.055',905,446,0,0,NULL,NULL),(207,2012,8,1,67,0,'Using a Cellular Automaton to Extract Medical Information from Clinical Reports','Clinical Reports, Information Extraction, Cellular Automaton, Boolean Inference Engine','Fatiha Barigou, Baghdad Atmani and Bouziane Beldjilali','dlibrary/JIPS_v08_no1_paper04.pdf','An important amount of clinical data concerning the medical history of a patient is in the form of clinical reports that are written by doctors. They describe patients, their pathologies, their personal and medical histories, findings made during interviews or during procedures, and so forth. They represent a source of precious information that can be used in several applications such as research information to diagnose new patients, epidemiological studies, decision support, statistical analysis, and data mining. But this information is difficult to access, as it is often in unstructured text form. To make access to patient data easy, our research aims to develop a system for extracting information from unstructured text. In a previous work, a rule-based approach is applied to a clinical reports corpus of infectious diseases to extract structured data in the form of named entities and properties. In this paper, we propose the use of a Boolean inference engine, which is based on a cellular automaton, to do extraction. Our motivation to adopt this Boolean modeling approach is twofold: first optimize storage, and second reduce the response time of the entities extraction.','10.3745/JIPS.2012.8.1.067',807,556,0,0,NULL,NULL),(208,2012,8,1,85,0,'Hartley Transform Based Fingerprint Matching','Biometrics, Feature Extraction, Hartley Transform, Discrete Wavelet Transform, Fingerprint Matching','Sangita Bharkad and Manesh Kokare','dlibrary/JIPS_v08_no1_paper05.pdf','The Hartley transform based feature extraction method is proposed for fingerprint matching. Hartley transform is applied on a smaller region that has been cropped around the core point. The performance of this proposed method is evaluated based on the standard database of Bologna University and the database of the FVC2002. We used the city block distance to compute the similarity between the test fingerprint and database fingerprint image. The results obtained are compared with the discrete wavelet transform (DWT) based method. The experimental results show that, the proposed method reduces the false acceptance rate (FAR) from 21.48% to 16.74 % based on the database of Bologna University and from 31.29% to 28.69% based on the FVC2002 database.','10.3745/JIPS.2012.8.1.085',936,1021,0,0,NULL,NULL),(209,2012,8,1,101,0,'Supporting Java Components in the SID Simulation System','Embedded System, Simulation System, SID Simulator','Hasrul Ma\'ruf, Hidayat Febiansyah and Jin Baek Kwon','dlibrary/JIPS_v08_no1_paper06.pdf','Embedded products are becoming richer in features. Simulation tools facilitate low-costs and the efficient development of embedded systems. SID is an open source simulation software that includes a library of components for modeling hardware and software components. SID components were originally written using C/C++ and Tcl/Tk. Tcl/Tk has mainly been used for GUI simulation in the SID system. However, Tcl/Tk components are hampered by low performance, and GUI development using Tcl/Tk also has poor flexibility. Therefore, it would be desirable to use a more advanced programming language, such as Java, to provide simulations of cutting-edge products with rich graphics. Here, we describe the development of the Java Bridge Module as a middleware that will enable the use of Java Components in SID. We also extended the low-level SID API to Java. In addition, we have added classes that contain default implementations of the API. These classes are intended to ensure the compatibility and simplicity of SID components in Java.','10.3745/JIPS.2011.8.1.101',689,769,0,0,NULL,NULL),(210,2012,8,1,119,0,'An Improved Fast and Secure Hash Algorithm','SHA-256, SFHA-256, Improved SFHA-256','Siddharth Agarwal, Abhinav Rungta, R.Padmavathy, Mayank Shankar and Nipun Rajan','dlibrary/JIPS_v08_no1_paper07.pdf','Recently, a fast and secure hash function SFHA . 256 has been proposed and claimed as more secure and as having a better performance than the SHA . 256. In this paper an improved version of SFHA . 256 is proposed and analyzed using two parameters, namely the avalanche effect and uniform deviation. The experimental results and further analysis ensures the performance of the newly proposed and improved SFHA-256. From the analysis it can be concluded that the newly proposed algorithm is more secure, efficient, and practical.','10.3745/JIPS.2012.8.1.119',829,578,0,0,NULL,NULL),(211,2012,8,1,133,0,'Energy Efficient Architecture Using Hardware Acceleration for Software Defined Radio Components','Software Communication Architecture, Software Defined Radio, Energy Efficiency, FPGA, Cognitive Radio','Chen Liu, Omar Granados, Rolando Duarte and Jean Andrian','dlibrary/JIPS_v08_no1_paper08.pdf','In order to make cognitive radio systems a practical technology to be deployed in real-world scenarios, the core Software Defined Radio (SDR) systems must meet the stringent requirements of the target application, especially in terms of performance and energy consumption for mobile platforms. In this paper we present a feasibility study of hardware acceleration as an energy-efficient implementation for SDR. We identified the amplifier function from the Software Communication Architecture (SCA) for hardware acceleration since it is one of the functions called for most frequently and it requires intensive floating-point computation. Then, we used the Virtex5 Field- Programmable Gate Array (FPGA) to perform a comparison between compiler floatingpoint support and the on-chip floating-point support. By enabling the on-chip floating-point unit (FPU), we obtained as high as a 2X speedup and 50% of the overall energy reduction. We achieved this with an increase of the power consumption by no more than 0.68%. This demonstrates the feasibility of the proposed approach.','10.3745/JIPS.2012.8.1.133',1028,638,0,0,NULL,NULL),(212,2012,8,1,145,0,'Performance Study of genus 3 Hyperelliptic Curve Cryptosystem','Hyperelliptic Curve Cryptosystem(HECC), Secure Hyperelliptic Curve, Hyperelliptic Curve Deffie-Hellman(HECDH), Hyperelliptic Curve Digital Signature Algorithm (HECDSA)','Daya Gupta, Asok De and Kakali Chatterjee','dlibrary/JIPS_v08_no1_paper09.pdf','Hyperelliptic Curve Cryptosystem (HECC) is well suited for all kinds of embedded processor architectures, where resources such as storage, time, or power are constrained due to short operand sizes. We can construct genus 3 HECC on 54-bit finite fields in order to achieve the same security level as 160-bit ECC or 1024-bit RSA due to the algebraic structure of Hyperelliptic Curve. This paper explores various possible attacks to the discrete logarithm in the Jacobian of a Hyperelliptic Curve (HEC) and addition and doubling of the divisor using explicit formula to speed up the scalar multiplication. Our aim is to develop a cryptosystem that can sign and authenticate documents and encrypt / decrypt messages efficiently for constrained devices in wireless networks. The performance of our proposed cryptosystem is comparable with that of ECC and the security analysis shows that it can resist the major attacks in wireless networks.','10.3745/JIPS.2012.8.1.145',825,633,0,0,NULL,NULL),(213,2012,8,1,159,0,'An Efficient Block Cipher Implementation on Many-Core Graphics Processing Units','General-Purpose Computation on a Graphics Processing Unit, SEED Block Cipher, Parallelism, Multi-Core Processors','Sangpil Lee, Deokho Kim, Jaeyoung Yi and Won Woo Ro','dlibrary/JIPS_v08_no1_paper10.pdf','This paper presents a study on a high-performance design for a block cipher algorithm implemented on modern many-core graphics processing units (GPUs). The recent emergence of VLSI technology makes it feasible to fabricate multiple processing cores on a single chip and enables general-purpose computation on a GPU (GPGPU). The GPU strategy offers significant performance improvements for all-purpose computation and can be used to support a broad variety of applications, including cryptography. We have proposed an efficient implementation of the encryption/decryption operations of a block cipher algorithm, SEED, on off-the-shelf NVIDIA many-core graphics processors. In a thorough experiment, we achieved high performance that is capable of supporting a high network speed of up to 9.5 Gbps on an NVIDIA GTX285 system (which has 240 processing cores). Our implementation provides up to 4.75 times higher performance in terms of encoding and decoding throughput as compared to the Intel 8-core system.','10.3745/JIPS.2012.8.1.159',848,752,0,0,NULL,NULL),(214,2012,8,1,175,0,'Attack and Correction: How to Design a Secure and Efficient Mix Network','Mix Network, Correction','Kun Peng','dlibrary/JIPS_v08_no1_paper11.pdf','Shuffling is an effective method to build a publicly verifiable mix network to implement verifiable anonymous channels that can be used for important cryptographic applications like electronic voting and electronic cash. One shuffling scheme by Groth is claimed to be secure and efficient. However, its soundness has not been formally proven. An attack against the soundness of this shuffling scheme is presented in this paper. Such an attack compromises the soundness of the mix network based on it. Two new shuffling protocols are designed on the basis of Groth\"\'\"s shuffling and batch verification techniques. The first new protocol is not completely sound, but is formally analyzed in regards to soundness, so it can be applied to build a mix network with formally proven soundness. The second new protocol is completely sound, so is more convenient to apply. Formal analysis in this paper guarantees that both new shuffling protocols can be employed to build mix networks with formally provable soundness. Both protocols prevent the attack against soundness in Groth\"\'\"s scheme. Both new shuffling protocols are very efficient as batch-verification-based efficiency-improving mechanisms have been adopted. The second protocol is even simpler and more elegant than the first one as it is based on a novel batch cryptographic technique.','10.3745/JIPS.2012.8.1.175',749,544,0,0,NULL,NULL),(215,2012,8,2,191,0,'An Adaptive Approach to Learning the Preferences of Users in a Social Network Using Weak Estimators','Weak es timators, User\'s Profiling, Time Varying Preferences','B. John Oommen, Anis Yazidi and Ole-Christoffer Granmo','dlibrary/JIPS_v08_no2_paper01.pdf','Since a social network by definition is so diverse, the problem of estimating the preferences of its users is becoming increasingly essential for personalized applications, which range from service recommender systems to the targeted advertising of services. However, unlike traditional estimation problems where the underlying target distribution is stationary; estimating a user\"\'\"s interests typically involves non-stationary distributions. The consequent time varying nature of the distribution to be tracked imposes stringent constraints on the \"unlearning” capabilities of the estimator used. Therefore, resorting to strong estimators that converge with a probability of 1 is inefficient since they rely on the assumption that the distribution of the user\"\'\"s preferences is stationary. In this vein, we propose to use a family of stochastic-learning based Weak estimators for learning and tracking a user\"\'\"s time varying interests. Experimental results demonstrate that our proposed paradigm outperforms some of the traditional legacy approaches that represent the state-of-the-art technology.','10.3745/JIPS.2012.8.2.191',3477,1373,13,0,NULL,NULL),(216,2012,8,2,213,0,'A Novel Approach for Deriving Test Scenarios and Test Cases from Events','Events, Event Meta Model, Testing, Test cases, Test scenarios, Event Based Systems, Software Engineering','Sandeep K. Singh, Sangeeta Sabharwal and J.P.Gupta','dlibrary/JIPS_v08_no2_paper02.pdf','Safety critical systems, real time systems, and event-based systems have a complex set of events and their own interdependency, which makes them difficult to test ma Safety critic Safety critical systems, real time systems, and event-based systems have a complex set of events and their own interdependency, which makes them difficult to test manually. In order to cut down on costs, save time, and increase reliability, the model based testing approach is the best solution. Such an approach does not require applications or codes prior to generating test cases, so it leads to the early detection of faults, which helps in reducing the development time. Several model-based testing approaches have used different UML models but very few works have been reported to show the generation of test cases that use events. Test cases that use events are an apt choice for these types of systems. However, these works have considered events that happen at a user interface level in a system while other events that happen in a system are not considered. Such works have limited applications in testing the GUI of a system. In this paper, a novel model-based testing approach is presented using business events, state events, and control events that have been captured directly from requirement specifications. The proposed approach documents events in event templates and then builds an event-flow model and a fault model for a system. Test coverage criterion and an algorithm are designed using these models to generate event sequence based test scenarios and test cases. Unlike other event based approaches, our approach is able to detect the proposed faults in a system. A prototype tool is developed to automate and evaluate the applicability of the entire process. Results have shown that the proposed approach and supportive tool is able to successfully derive test scenarios and test cases from the requirement specifications of safety critical systems, real time systems, and event based systems.','10.3745/JIPS.2012.8.2.213',839,1142,0,0,NULL,NULL),(217,2012,8,2,241,0,'Fault Prediction Using Statistical and Machine Learning Methods for Improving Software Quality','Empirical Validation, Object Oriented, Receiver Operating Characteristics, Statistical Methods, Machine Learning, Fault Prediction','Ruchika Malhotra and Ankita Jain','dlibrary/JIPS_v08_no2_paper03.pdf','An understanding of quality attributes is relevant for the software organization to deliver high software reliability. An empirical assessment of metrics to predict the quality attributes is essential in order to gain insight about the quality of software in the early phases of software development and to ensure corrective actions. In this paper, we predict a model to estimate fault proneness using Object Oriented CK metrics and QMOOD metrics. We apply one statistical method and six machine learning methods to predict the models. The proposed models are validated using dataset collected from Open Source software. The results are analyzed using Area Under the Curve (AUC) obtained from Receiver Operating Characteristics (ROC) analysis. The results show that the model predicted using the random forest and bagging methods outperformed all the other models. Hence, based on these results it is reasonable to claim that quality models have a significant relevance with Object Oriented metrics and that machine learning methods have a comparable performance with statistical methods','10.3745/JIPS.2012.8.2.241',1034,1003,0,0,NULL,NULL),(218,2012,8,2,263,0,'Dynamic Replication Based on Availability and Popularity in the Presence of Failures','Data Grid, Dynamic Replication, Availability, Failures, Best Client, Best Responsible, Data Management','Bakhta Meroufel and Ghalem Belalem','dlibrary/JIPS_v08_no2_paper04.pdf','The data grid provides geographically distributed resources for large-scale applications. It generates a large set of data. The replication of this data in several sites of the grid is an effective solution for achieving good performance. In this paper we propose an approach of dynamic replication in a hierarchical grid that takes into account crash failures in the system. The replication decision is taken based on two parameters: the availability and popularity of the data. The administrator requires a minimum rate of availability for each piece of data according to its access history in previous periods, but this availability may increase if the demand is high on this data. We also proposed a strategy to keep the desired availability respected even in case of a failure or rarity (nopopularity) of the data. The simulation results show the effectiveness of our replication strategy in terms of response time, the unavailability of requests, and availability','10.3745/JIPS.2012.8.2.263',758,535,0,0,NULL,NULL),(219,2012,8,2,279,0,'Expressive Exceptions for Safe Pervasive Spaces','Exceptions, Safety, Programming models for Pervasive Systems, Pervasive Computing, Contexts, Situations','Eun-Sun Cho and Sumi Helal','dlibrary/JIPS_v08_no2_paper05.pdf','Uncertainty and dynamism surrounding pervasive systems require new and sophisticated approaches to defining, detecting, and handling complex exceptions. This is because the possible erroneous conditions in pervasive systems are more complicated than conditions found in traditional applications. We devised a novel exception description and detection mechanism based on “situation”- a novel extension of context, which allows programmers to devise their own handling routines targeting sophisticated exceptions. This paper introduces the syntax of a language support that empowers the expressiveness of exceptions and their handlers, and suggests an implementation algorithm with a straw man analysis of overhead','10.3745/JIPS.2012.8.2.279',761,534,0,0,NULL,NULL),(220,2012,8,2,301,0,'The Use of MSVM and HMM for Sentence Alignment','Sentence Alignment, English/ Arabic Parallel Corpus, Parallel Corpora, Machine Translation, Multi-Class Support Vector Machine, Hidden Markov model','Mohamed Abdel Fattah','dlibrary/JIPS_v08_no2_paper06.pdf','In this paper, two new approaches to align English-Arabic sentences in bilingual parallel corpora based on the Multi-Class Support Vector Machine (MSVM) and the Hidden Markov Model (HMM) classifiers are presented. A feature vector is extracted from the text pair that is under consideration. This vector contains text features such as length, punctuation score, and cognate score values. A set of manually prepared training data was assigned to train the Multi-Class Support Vector Machine and Hidden Markov Model. Another set of data was used for testing. The results of the MSVM and HMM outperform the results of the length based approach. Moreover these new approaches are valid for any language pairs and are quite flexible since the feature vector may contain less, more, or different features, such as a lexical matching feature and Hanzi characters in Japanese-Chinese texts, than the ones used in the current research','10.3745/JIPS.2012.8.2.301',744,642,0,0,NULL,NULL),(221,2012,8,2,315,0,'A Framework for Processing Brain Waves Used in a Brain-computer Interface','Brain-Computer Interface, BCI Toolkit, BCI Framework, EEG, Brain Wave','Yunsick Sung, Kyungeun Cho and Kyhyun Um','dlibrary/JIPS_v08_no2_paper07.pdf','Recently, methodologies for developing brain-computer interface (BCI) games using the BCI have been actively researched. The existing general framework for processing brain waves does not provide the functions required to develop BCI games. Thus, developing BCI games is difficult and requires a large amount of time. Effective BCI game development requires a BCI game framework. Therefore the BCI game framework should provide the functions to generate discrete values, events, and converted waves considering the difference between the brain waves of users and the BCIs of those. In this paper, BCI game frameworks for processing brain waves for BCI games are proposed. A variety of processes for converting brain waves to apply the measured brain waves to the games are also proposed. In an experiment the frameworks proposed were applied to a BCI game for visual perception training. Furthermore, it was verified that the time required for BCI game development was reduced when the framework proposed in the experiment was applied','10.3745/JIPS.2012.8.2.315',867,514,0,0,NULL,NULL),(222,2012,8,2,331,0,'TBBench: A Micro-Benchmark Suite for Intel Threading Building Blocks','TBB, Micro-Benchmarks, Multi-Core, Parallel Overhead','Ami Marowka','dlibrary/JIPS_v08_no2_paper08.pdf','Task-based programming is becoming the state-of-the-art method of choice for extracting the desired performance from multi-core chips. It expresses a program in terms of lightweight logical tasks rather than heavyweight threads. Intel Threading Building Blocks (TBB) is a task-based parallel programming paradigm for multi-core processors. The performance gain of this paradigm depends to a great extent on the efficiency of its parallel constructs. The parallel overheads incurred by parallel constructs determine the ability for creating large-scale parallel programs, especially in the case of fine-grain parallelism. This paper presents a study of TBB parallelization overheads. For this purpose, a TBB micro-benchmarks suite called TBBench has been developed. We use TBBench to evaluate the parallelization overheads of TBB on different multi-core machines and different compilers. We report in detail in this paper on the relative overheads and analyze the running results.','10.3745/JIPS.2012.8.2.331',755,1807,0,0,NULL,NULL),(223,2012,8,2,347,0,'Visual Monitoring System of Multi-Hosts Behavior for Trustworthiness with Mobile Cloud','Hardware Hardening, TPM, TPB, Mobile Cloud, System Behavior Monitoring, BiT Profiling','Eun-Ha Song, Hyun-Woo Kim and Young-Sik Jeong','dlibrary/JIPS_v08_no2_paper09.pdf','Recently, security researches have been processed on the method to cover a broader range of hacking attacks at the low level in the perspective of hardware. This system security applies not only to individuals\' computer systems but also to cloud environments. \"Cloud\" concerns operations on the web. Therefore it is exposed to a lot of risks and the security of its spaces where data is stored is vulnerable. Accordingly, in order to reduce threat factors to security, the TCG proposed a highly reliable platform based on a semiconductor-chip, the TPM. However, there have been no technologies up to date that enables a real-time visual monitoring of the security status of a PC that is operated based on the TPM. And the TPB has provided the function in a visual method to monitor system status and resources only for the system behavior of a single host. Therefore, this paper will propose a m-TMS (Mobile Trusted Monitoring System) that monitors the trusted state of a computing environment in which a TPM chip-based TPB is mounted and the current status of its system resources in a mobile device environment resulting from the development of network service technology. The m-TMS is provided to users so that system resources of CPU, RAM, and process, which are the monitoring objects in a computer system, may be monitored. Moreover, converting and detouring single entities like a PC or target addresses, which are attack pattern methods that pose a threat to the computer system security, are combined. The branch instruction trace function is monitored using a BiT Profiling tool through which processes attacked or those suspected of being attacked may be traced, thereby enabling users to actively respond','10.3745/JIPS.2012.8.2.347',816,429,0,0,NULL,NULL),(224,2012,8,2,359,0,'Automatic Detection of Texture-defects using Texture-periodicity and Jensen-Shannon Divergence','Periodicity, Jensen-Shannon Divergence, Cluster, Defect','V. Asha, N.U. Bhajantri and P. Nagabhushan','dlibrary/JIPS_v08_no2_paper10.pdf','In this paper, we propose a new machine vision algorithm for automatic defect detection on patterned textures with the help of texture-periodicity and the Jensen- Shannon Divergence, which is a symmetrized and smoothed version of the Kullback- Leibler Divergence. Input defective images are split into several blocks of the same size as the size of the periodic unit of the image. Based on histograms of the periodic blocks, Jensen-Shannon Divergence measures are calculated for each periodic block with respect to itself and all other periodic blocks and a dissimilarity matrix is obtained. This dissimilarity matrix is utilized to get a matrix of true-metrics, which is later subjected to Ward\"\'\"s hierarchical clustering to automatically identify defective and defect-free blocks. Results from experiments on real fabric images belonging to 3 major wallpaper groups, namely, pmm, p2, and p4m with defects, show that the proposed method is robust in finding fabric defects with a very high success rates without any human intervention','10.3745/JIPS.2012.8.2.359',799,1021,0,0,NULL,NULL),(225,2012,8,2,375,0,'Efficient and General PVSS Based on ElGamal Encryption','ElGamal, PVSS','Kun Peng','dlibrary/JIPS_v08_no2_paper11.pdf','PVSS stands for publicly verifiable secret sharing. In PVSS, a dealer shares a secret among multiple share holders. He encrypts the shares using the shareholders\"\'\" encryption algorithms and publicly proves that the encrypted shares are valid. Most of the existing PVSS schemes do not employ an ElGamal encryption to encrypt the shares. Instead, they usually employ other encryption algorithms like a RSA encryption and Paillier encryption. Those encryption algorithms do not support the shareholders\"\'\" encryption algorithms to employ the same decryption modulus. As a result, PVSS based on those encryption algorithms must employ additional range proofs to guarantee the validity of the shares obtained by the shareholders. Although the shareholders can employ ElGamal encryptions with the same decryption modulus in PVSS such that the range proof can be avoided, there are only two PVSS schemes based on ElGamal encryption. Moreover, the two schemes have their drawbacks. One of them employs a costly repeating-proof mechanism, which needs to repeat the dealer\"\'\"s proof at least scores of times to achieve satisfactory soundness. The other requires that the dealer must know the discrete logarithm of the secret to share and thus weakens the generality and it cannot be employed in many applications. A new PVSS scheme based on an ElGamal encryption is proposed in this paper. It employs the same decryption modulus for all the shareholders\"\'\" ElGamal encryption algorithms, so it does not need any range proof. Moreover, it is a general PVSS technique without any special limitation. Finally, an encryption-improving technique is proposed to achieve very high efficiency in the new PVSS scheme. It only needs a number of exponentiations in large cyclic groups that are linear in the number of the shareholders, while all the existing PVSS schemes need at least a number of exponentiations in large cyclic groups that are linear in the square of the number of the shareholders','10.3745/JIPS.2012.8.2.375',705,428,0,0,NULL,NULL),(226,2012,8,3,389,0,'Texture Comparison with an Orientation Matching Scheme','Orientation Matching, Texture Analysis, Texture Comparison, K-means Clustering','Nguyen Cao Truong Hai, Do-Yeon Kim and Hyuk-Ro Park','dlibrary/JIPS_v08_no3_paper01.pdf','Texture is an important visual feature for image analysis. Many approaches have been proposed to model and analyze texture features. Although these approaches significantly contribute to various image-based applications, most of these methods are sensitive to the changes in the scale and orientation of the texture pattern. Because textures vary in scale and orientations frequently, this easily leads to pattern mismatching if the features are compared to each other without considering the scale and/or orientation of textures. This paper suggests an Orientation Matching Scheme (OMS) to ease the problem of mismatching rotated patterns. In OMS, a pair of texture features will be compared to each other at various orientations to identify the best matched direction for comparison. A database including rotated texture images was generated for experiments. A synthetic retrieving experiment was conducted on the generated database to examine the performance of the proposed scheme. We also applied OMS to the similarity computation in a K-means clustering algorithm. The purpose of using K-means is to examine the scheme exhaustively in unpromising conditions, where initialized seeds are randomly selected and algorithms work heuristically. Results from both types of experiments show that the proposed OMS can help improve the performance when dealing with rotated patterns.','10.3745/JIPS.2012.8.3.389',937,444,0,0,NULL,NULL),(227,2012,8,3,399,0,'A Vision-Based Method to Find Fingertips in a Closed Hand','Hand Shape Parameters, Fingertips Detection, Skin Filter, Natural Computing, Corner Detection','Ankit Chaudhary, Kapil Vatwani, Tushar Agrawal and J.L. Raheja','dlibrary/JIPS_v08_no3_paper02.pdf','Hand gesture recognition is an important area of research in the field of Human Computer Interaction (HCI). The geometric attributes of the hand play an important role in hand shape reconstruction and gesture recognition. That said, fingertips are one of the important attributes for the detection of hand gestures and can provide valuable information from hand images. Many methods are available in scientific literature for fingertips detection with an open hand but very poor results are available for fingertips detection when the hand is closed. This paper presents a new method for the detection of fingertips in a closed hand using the corner detection method and an advanced edge detection algorithm. It is important to note that the skin color segmentation methodology did not work for fingertips detection in a closed hand. Thus the proposed method applied Gabor filter techniques for the detection of edges and then applied the corner detection algorithm for the detection of fingertips through the edges. To check the accuracy of the method, this method was tested on a vast number of images taken with a webcam. The method resulted in a higher accuracy rate of detections from the images. The method was further implemented on video for testing its validity on real time image capturing. These closed hand fingertips detection would help in controlling an electro-mechanical robotic hand via hand gesture in a natural way.','10.3745/JIPS.2012.8.3.399',1075,450,0,0,NULL,NULL),(228,2012,8,3,409,0,'A Method for Learning Macro-Actions for Virtual Characters Using Programming by Demonstration and Reinforcement Learning','Reinforcement Learning, Monte Carlo Method, Behavior Generation Model, Programming B y Demonstration, Macro-Action, Multi-Step Action','Yunsick Sung and Kyungeun Cho','dlibrary/JIPS_v08_no3_paper03.pdf','The decision-making by agents in games is commonly based on reinforcement learning. To improve the quality of agents, it is necessary to solve the problems of the time and state space that are required for learning. Such problems can be solved by Macro-Actions, which are defined and executed by a sequence of primitive actions. In this line of research, the learning time is reduced by cutting down the number of policy decisions by agents. Macro-Actions were originally defined as combinations of the same primitive actions. Based on studies that showed the generation of Macro-Actions by learning, Macro-Actions are now thought to consist of diverse kinds of primitive actions. However an enormous amount of learning time and state space are required to generate Macro-Actions. To resolve these issues, we can apply insights from studies on the learning of tasks through Programming by Demonstration (PbD) to generate Macro- Actions that reduce the learning time and state space. In this paper, we propose a method to define and execute Macro-Actions. Macro-Actions are learned from a human subject via PbD and a policy is learned by reinforcement learning. In an experiment, the proposed method was applied to a car simulation to verify the scalability of the proposed method. Data was collected from the driving control of a human subject, and then the Macro- Actions that are required for running a car were generated. Furthermore, the policy that is necessary for driving on a track was learned. The acquisition of Macro-Actions by PbD reduced the driving time by about 16% compared to the case in which Macro-Actions were directly defined by a human subject. In addition, the learning time was also reduced by a faster convergence of the optimum policies.','10.3745/JIPS.2012.8.3.409',881,381,0,0,NULL,NULL),(229,2012,8,3,421,0,'A New Approach to Fingerprint Detection Using a Combination of Minutiae Points and Invariant Moments Parameters','Random Variable, Skewness, Kurtosis, Invariant Moment, Termination And Bifurcation Points, Virtual Core Point','Sarnali Basak, Md. Imdadul Islam and M. R. Amin','dlibrary/JIPS_v08_no3_paper04.pdf','Different types of fingerprint detection algorithms that are based on extraction of minutiae points are prevalent in recent literature. In this paper, we propose a new algorithm to locate the virtual core point/centroid of an image. The Euclidean distance between the virtual core point and the minutiae points is taken as a random variable. The mean, variance, skewness, and kurtosis of the random variable are taken as the statistical parameters of the image to observe the similarities or dissimilarities among fingerprints from the same or different persons. Finally, we verified our observations with a moment parameter-based analysis of some previous works.','10.3745/JIPS.2012.8.3.421',887,582,0,0,NULL,NULL),(230,2012,8,3,437,0,'Using an Adaptive Search Tree to Predict User Location','Location Prediction, Learning System, Search Tree, Context-Awareness','Sechang Oh','dlibrary/JIPS_v08_no3_paper05.pdf','In this paper, we propose a method for predicting a user’s location based on their past movement patterns. There is no restriction on the length of past movement patterns when using this method to predict the current location. For this purpose, a modified search tree has been devised. The search tree is constructed in an effective manner while it additionally learns the movement patterns of a user one by one. In fact, the time complexity of the learning process for a movement pattern is linear. In this process, the search tree expands to take into consideration more details about the movement patterns when a pattern that conflicts with an existing trained pattern is found. In this manner, the search tree is trained to make an exact matching, as needed, for location prediction. In the experiments, the results showed that this method is highly accurate in comparison with more complex and sophisticated methods. Also, the accuracy deviation of users of this method is significantly lower than for any other methods. This means that this method is highly stable for the variations of behavioral patterns as compared to any other method. Finally, 1.47 locations were considered on average for making a prediction with this method. This shows that the prediction process is very efficient','10.3745/JIPS.2012.8.3.437',757,376,0,0,NULL,NULL),(231,2012,8,3,445,0,'Iris Recognition Using Ridgelets','Ridgelets, Texture, Wavelets, Biometrics, Features, Database','Lenina Birgale and Manesh Kokare','dlibrary/JIPS_v08_no3_paper06.pdf','Image feature extraction is one of the basic works for biometric analysis. This paper presents the novel concept of application of ridgelets for iris recognition systems. Ridgelet transforms are the combination of Radon transforms and Wavelet transforms. They are suitable for extracting the abundantly present textural data that is in an iris. The technique proposed here uses the ridgelets to form an iris signature and to represent the iris. This paper contributes towards creating an improved iris recognition system. There is a reduction in the feature vector size, which is 1X4 in size. The False Acceptance Rate (FAR) and False Rejection Rate (FRR) were also reduced and the accuracy increased. The proposed method also avoids the iris normalization process that is traditionally used in iris recognition systems. Experimental results indicate that the proposed method achieves an accuracy of 99.82%, 0.1309% FAR, and 0.0434% FRR.','10.3745/JIPS.2012.8.3.445',784,1001,0,0,NULL,NULL),(232,2012,8,3,459,0,'Web-Based Computational System for Protein- Protein Interaction Inference','Protein-Protein Interactions (PPIs), WASPI (Web-based Assistant System for Protein-protein interaction Inference), InterPro, InterProScan, BLAST','Ki-Bong Kim','dlibrary/JIPS_v08_no3_paper07.pdf','Recently, high-throughput technologies such as the two-hybrid system, protein chip, Mass Spectrometry, and the phage display have furnished a lot of data on protein-protein interactions (PPIs), but the data has not been accurate so far and the quantity has also been limited. In this respect, computational techniques for the prediction and validation of PPIs have been developed. However, existing computational methods do not take into account the fact that a PPI is actually originated from the interactions of domains that each protein contains. So, in this work, the information on domain modules of individual proteins has been employed in order to find out the protein interaction relationship. The system developed here, WASPI (Web-based Assistant System for Protein-protein interaction Inference), has been implemented to provide many functional insights into the protein interactions and their domains. To achieve those objectives, several preprocessing steps have been taken. First, the domain module information of interacting proteins was extracted by taking advantage of the InterPro database, which includes protein families, domains, and functional sites. The InterProScan program was used in this preprocess. Second, the homology comparison with the GO (Gene Ontology) and COG (Clusters of Orthologous Groups) with an E-value of 10-5, 10-3 respectively, was employed to obtain the information on the function and annotation of each interacting protein of a secondary PPI database in the WASPI. The BLAST program was utilized for the homology comparison','10.3745/JIPS.2012.8.3.459',734,398,0,0,NULL,NULL),(233,2012,8,3,471,0,'Performance Evaluation of Multi-Hop Communication Based on a Mobile Multi-Robot System in a Subterranean Laneway','Multi-hop Communication, Wireless Sensor Network, Multi-Robot System, Disaster Exploration, ZigBee Technology, Underground Environment','Qing-Ling Liu and Duk-Hwan Oh','dlibrary/JIPS_v08_no3_paper08.pdf','For disaster exploration and surveillance application, this paper aims to present a novel application of a multi-robot agent based on WSN and to evaluate a multihop communication caused by the robotics correspondingly, which are used in the uncertain and unknown subterranean tunnel. A Primary-Scout Multi-Robot System (PSMRS) was proposed. A chain topology in a subterranean environment was implemented using a trimmed ZigBee2006 protocol stack to build the multi-hop communication network. The ZigBee IC-CC2530 modular circuit was adapted by mounting it on the PS-MRS. A physical experiment based on the strategy of PS-MRS was used in this paper to evaluate the efficiency of multi-hop communication and to realize the delivery of data packets in an unknown and uncertain underground laboratory environment','10.3745/JIPS.2012.8.3.471',836,542,0,0,NULL,NULL),(234,2012,8,3,483,0,'Face Recognition Based on PCA on Wavelet Subband of Average-Half-Face','Face Recognition, Princ ipal Component Analysis, Subband, Wavelet Transform','M.P. Satone and Dr. G.K. Kharate','dlibrary/JIPS_v08_no3_paper09.pdf','Many recent events, such as terrorist attacks, exposed defects in most sophisticated security systems. Therefore, it is necessary to improve security data systems based on the body or behavioral characteristics, often called biometrics. Together with the growing interest in the development of human and computer interface and biometric identification, human face recognition has become an active research area. Face recognition appears to offer several advantages over other biometric methods. Nowadays, Principal Component Analysis (PCA) has been widely adopted for the face recognition algorithm. Yet still, PCA has limitations such as poor discriminatory power and large computational load. This paper proposes a novel algorithm for face recognition using a mid band frequency component of partial information which is used for PCA representation. Because the human face has even symmetry, half of a face is sufficient for face recognition. This partial information saves storage and computation time. In comparison with the traditional use of PCA, the proposed method gives better recognition accuracy and discriminatory power. Furthermore, the proposed method reduces the computational load and storage significantly','10.3745/JIPS.2012.8.3.483',925,842,0,0,NULL,NULL),(235,2012,8,3,495,0,'Designing an Efficient and Secure Credit Cardbased Payment System with Web Services Based on the ANSI X9.59-2006','Payment Protocols, Electronic Commerce, SET, X9.59, Web Services','Chi Po Cheong, Simon Fong, Pouwan Lei, Chris Chatwin and Rupert Young','dlibrary/JIPS_v08_no3_paper10.pdf','A secure Electronic Payment System (EPS) is essential for the booming online shopping market. A successful EPS supports the transfer of electronic money and sensitive information with security, accuracy, and integrity between the seller and buyer over the Internet. SET, CyberCash, Paypal, and iKP are the most popular Credit Card- Based EPSs (CCBEPSs). Some CCBEPSs only use SSL to provide a secure communication channel. Hence, they only prevent “Man in the Middle” fraud but do not protect the sensitive cardholder information such as the credit card number from being passed onto the merchant, who may be unscrupulous. Other CCBEPSs use complex mechanisms such as cryptography, certificate authorities, etc. to fulfill the security schemes. However, factors such as ease of use for the cardholder and the implementation costs for each party are frequently overlooked. In this paper, we propose a Web service based new payment system, based on ANSI X9.59-2006 with extra features added on top of this standard. X9.59 is an Account Based Digital Signature (ABDS) and consumeroriented payment system. It utilizes the existing financial network and financial messages to complete the payment process. However, there are a number of limitations in this standard. This research provides a solution to solve the limitations of X9.59 by adding a merchant authentication feature during the payment cycle without any addenda records to be added in the existing financial messages. We have conducted performance testing on the proposed system via a comparison with SET and X9.59 using simulation to analyze their levels of performance and security.','10.3745/JIPS.2012.8.3.495',1154,549,0,0,NULL,NULL),(236,2012,8,3,521,0,'Design and Development of m-Learning Service Based on 3G Cellular Phones','m-Learning, e-Learning Service Platform, Mobile Education Device, Cellular Phone, 3G Networks, H.264','Kwang Sik Chung and Jeong Eun Lee','dlibrary/JIPS_v08_no3_paper11.pdf','As the knowledge society matures, not only distant, but also off-line universities are trying to provide learners with on-line educational contents. Particularly, high effectiveness of mobile devices for e-Learning has been demonstrated by the university sector, which uses distant learning that is based on blended learning. In this paper, we analyzed previous m-Learning scenarios and future technology prospects. Based on the proposed m-Learning scenario, we designed cellular phonebased educational contents and service structure, implemented m-Learning system, and analyzed m-Learning service satisfaction. The design principles of the m-Learning service are 1) to provide learners with m-Learning environment with both cellular phones and desktop computers; 2) to serve announcements, discussion boards, Q&A boards, course materials, and exercises on cellular phones and desktop computers; and 3) to serve learning activities like the reviewing of full lectures, discussions, and writing term papers using desktop computers and cellular phones. The m-Learning service was developed on a cellular phone that supports H.264 codex in 3G communication technology. Some of the functions of the m-Learning design principles are implemented in a 3G cellular phone. The contents of lectures are provided in the forms of video, text, audio, and video with text. One-way educational contents are complemented by exercises (quizzes)','10.3745/JIPS.2012.8.3.521',929,667,0,0,NULL,NULL),(237,2012,8,4,539,0,'Evaluation of an Abstract Component Model for Embedded Systems Development','Software Development Management, Software Reusability, Modeling','Christian Bunse, Yunja Choi and Hans Gerhard Gross','dlibrary/JIPS_v08_no4_paper1.pdf','Model-driven and component-oriented development is increasingly being used in the development of embedded systems. When combined, both paradigms provide several advantages, such as higher reuse rates, and improved system quality. Performing model-driven and component-oriented development should be accompanied by a component model and a method that prescribes how the component model is used. This article provides an overview on the MARMOT method, which consists of an abstract component model and a methodology for the development of embedded systems. The paper describes a feasibility study that demonstrates MARMOT\"\'\"s capability to alleviate system design, verification, implementation, and reuse. Results indicate that model-driven and component-based development following the MARMOT method outperforms Agile development for embedded systems, leads to maintainable systems, and higher than normal reuse rates.','10.3745/JIPS.2012.8.4.539',1191,629,0,0,NULL,NULL),(238,2012,8,4,555,0,'An Adaptive Workflow Scheduling Scheme Based on an Estimated Data Processing Rate for Next Generation Sequencing in Cloud Computing','Resource-Provisioning, Bio-Workflow Broker, Next-Generation Sequencing','Byungsang Kim, Chan-Hyun Youn, Yong-Sung Park, Yonggyu Lee and Wan Choi','dlibrary/JIPS_v08_no4_paper2.pdf','The cloud environment makes it possible to analyze large data sets in a scalable computing infrastructure. In the bioinformatics field, the applications are composed of the complex workflow tasks, which require huge data storage as well as a computing-intensive parallel workload. Many approaches have been introduced in distributed solutions. However, they focus on static resource provisioning with a batchprocessing scheme in a local computing farm and data storage. In the case of a largescale workflow system, it is inevitable and valuable to outsource the entire or a part of their tasks to public clouds for reducing resource costs. The problems, however, occurred at the transfer time for huge dataset as well as there being an unbalanced completion time of different problem sizes. In this paper, we propose an adaptive resourceprovisioning scheme that includes run-time data distribution and collection services for hiding the data transfer time. The proposed adaptive resource-provisioning scheme optimizes the allocation ratio of computing elements to the different datasets in order to minimize the total makespan under resource constraints. We conducted the experiments with a well-known sequence alignment algorithm and the results showed that the proposed scheme is efficient for the cloud environment.','10.3745/JIPS.2012.8.4.555',1218,533,0,0,NULL,NULL),(239,2012,8,4,567,0,'A Strong Designated Verifiable DL Based Signcryption Scheme','Designated Verifiable, Discrete Logarithm Problem, Chosen Ciphertext Attack, Nonrepudiation','Sujata Mohanty and Banshidhar Majhi','dlibrary/JIPS_v08_no4_paper3.pdf','This paper presents a strong designated verifiable signcryption scheme, in which a message is signcrypted by a signcryptor and only a specific receiver, who called a \"designated verifier\", verifies it using his own secret key. The scheme is secure, as an adversary can not verify the signature even if the secret key of the signer is compromised or leaked. The security of the proposed scheme lies in the complexity of solving two computationally hard problems, namely, the Discrete Logarithm Problem (DLP) and the Integer Factorization Problem (IFP). The security analysis of the scheme has been done and it is proved that, the proposed scheme can withstand an adaptive chosen ciphertext attack. This scheme can be very useful in organizations where there is a need to send confidential documents to a specific recipient. This scheme can also be applicable to real life scenarios, such as, e-commerce applications, e-banking and e-voting.','10.3745/JIPS.2012.8.4.567',967,403,0,0,NULL,NULL),(240,2012,8,4,575,0,'An Active Co-Training Algorithm for Biomedical Named-Entity Recognition','Biomedical Named-Entity Recognition, Co-Training, Semi-Supervised Learning, Feature Processing, Text Mining','Tsendsuren Munkhdalai, Meijing Li, Unil Yun, Oyun-Erdene Namsrai and Keun Ho Ryu','dlibrary/JIPS_v08_no4_paper4.pdf','Exploiting unlabeled text data with a relatively small labeled corpus has been an active and challenging research topic in text mining, due to the recent growth of the amount of biomedical literature. Biomedical named-entity recognition is an essential prerequisite task before effective text mining of biomedical literature can begin. This paper proposes an Active Co-Training (ACT) algorithm for biomedical named-entity recognition. ACT is a semi-supervised learning method in which two classifiers based on two different feature sets iteratively learn from informative examples that have been queried from the unlabeled data. We design a new classification problem to measure the informativeness of an example in unlabeled data. In this classification problem, the examples are classified based on a joint view of a feature set to be informative/non-informative to both classifiers. To form the training data for the classification problem, we adopt a query-bycommittee method. Therefore, in the ACT, both classifiers are considered to be one committee, which is used on the labeled data to give the informativeness label to each example. The ACT method outperforms the traditional co-training algorithm in terms of fmeasure as well as the number of training iterations performed to build a good classification model. The proposed method tends to efficiently exploit a large amount of unlabeled data by selecting a small number of examples having not only useful information but also a comprehensive pattern.','10.3745/JIPS.2012.8.4.575',1218,677,0,0,NULL,NULL),(241,2012,8,4,589,0,'A Survey of QoS Based Routing Protocols for Wireless Sensor Networks','Wireless Sensor Networks, Quality of Service, Reliability, Energy Efficiency, End-To-End Delay, Critical Data','R.Sumathi and M.G.Srinivas','dlibrary/JIPS_v08_no4_paper5.pdf','With the increasing demand for real time applications in the Wireless Senor Network (WSN), real time critical events anticipate an efficient quality-of-service (QoS) based routing for data delivery from the network infrastructure. Designing such QoS based routing protocol to meet the reliability and delay guarantee of critical events while preserving the energy efficiency is a challenging task. Considerable research has been focused on developing robust energy efficient QoS based routing protocols. In this paper, we present the state of the research by summarizing the work on QoS based routing protocols that has already been published and by highlighting the QoS issues that are being addressed. The performance comparison of QoS based routing protocols such as SAR, MMSPEED, MCMP, MCBR, and EQSR has also been analyzed using ns-2 for various parameters.','10.3745/JIPS.2012.8.4.589',1294,1887,0,0,NULL,NULL),(242,2012,8,4,603,0,'Design and Simulation of a Flow Mobility Scheme Based on Proxy Mobile IPv6','Flow Mobility, Proxy Mobile IPv6','Hyon-Young Choi, Sung-Gi Min, Youn-Hee Han and Rajeev Koodli','dlibrary/JIPS_v08_no4_paper6.pdf','Proxy Mobile IPv6 (PMIPv6) is a network-based mobility support protocol and it does not require Mobile Nodes (MNs) to be involved in the mobility support signaling. In the case when multiple interfaces are active in an MN simultaneously, each data flow can be dynamically allocated to and redirected between different access networks to adapt to the dynamically changing network status and to balance the workload. Such a flow redistribution control is called \"flow mobility\". In the existing PMIPv6-based flow mobility support, although the MN\"\'\"s logical interface can solve the well-known problems of flow mobility in a heterogeneous network, some missing procedures, such as an MN-derived flow handover, make PMIPv6-based flow mobility incomplete. In this paper, an enhanced flow mobility support is proposed for actualizing the flow mobility support in PMIPv6. The proposed scheme is also based on the MN\"\'\"s logical interface, which hides the physical interfaces from the network layer and above. As new functional modules, the flow interface manager is placed at the MN\"\'\"s logical interface and the flow binding manager in the Local Mobility Anchor (LMA) is paired with the MN\"\'\"s flow interface manager. They manage the flow bindings, and select the proper access technology to send packets. In this paper, we provide the complete flow mobility procedures which begin with the following three different triggering cases: the MN\"\'\"s new connection/disconnection, the LMA\"\'\"s decision, and the MN\"\'\"s request. Simulation using the ns-3 network simulator is performed to verify the proposed procedures and we show the network throughput variation caused by the network offload using the proposed procedures.','10.3745/JIPS.2012.8.4.603',1207,713,0,0,NULL,NULL),(243,2012,8,4,621,0,'A Comparative Study of Estimation by Analogy using Data Mining Techniques','Software Estimations, Estimation by Analogy, Grey Relational Analysis, Robust Regression, Data Mining Techniques','Geeta Nagpal, Moin Uddin and Arvinder Kaur','dlibrary/JIPS_v08_no4_paper7.pdf','Software Estimations provide an inclusive set of directives for software project developers, project managers, and the management in order to produce more realistic estimates based on deficient, uncertain, and noisy data. A range of estimation models are being explored in the industry, as well as in academia, for research purposes but choosing the best model is quite intricate. Estimation by Analogy (EbA) is a form of case based reasoning, which uses fuzzy logic, grey system theory or machine-learning techniques, etc. for optimization. This research compares the estimation accuracy of some conventional data mining models with a hybrid model. Different data mining models are under consideration, including linear regression models like the ordinary least square and ridge regression, and nonlinear models like neural networks, support vector machines, and multivariate adaptive regression splines, etc. A precise and comprehensible predictive model based on the integration of GRA and regression has been introduced and compared. Empirical results have shown that regression when used with GRA gives outstanding results; indicating that the methodology has great potential and can be used as a candidate approach for software effort estimation.','10.3745/JIPS.2012.8.4.621',1043,1360,0,0,NULL,NULL),(244,2012,8,4,653,0,'Online Recognition of Handwritten Korean and English Characters','Online Handwriting Recognition, Hidden Markov Model, Stochastic Grammar, Hierarchical Clustering, Position Verifier','Ming Ma, Dong-Won Park, Soo Kyun Kim and Syungog An','dlibrary/JIPS_v08_no4_paper8.pdf','In this study, an improved HMM based recognition model is proposed for online English and Korean handwritten characters. The pattern elements of the handwriting model are sub character strokes and ligatures. To deal with the problem of handwriting style variations, a modified Hierarchical Clustering approach is introduced to partition different writing styles into several classes. For each of the English letters and each primitive grapheme in Korean characters, one HMM that models the temporal and spatial variability of the handwriting is constructed based on each class. Then the HMMs of Korean graphemes are concatenated to form the Korean character models. The recognition of handwritten characters is implemented by a modified level building algorithm, which incorporates the Korean character combination rules within the efficient network search procedure. Due to the limitation of the HMM based method, a postprocessing procedure that takes the global and structural features into account is proposed. Experiments showed that the proposed recognition system achieved a high writer independent recognition rate on unconstrained samples of both English and Korean characters. The comparison with other schemes of HMM-based recognition was also performed to evaluate the system','10.3745/JIPS.2012.8.4.653',1141,1000,0,0,NULL,NULL),(245,2012,8,4,669,0,'ECG Denoising by Modeling Wavelet Sub-Band Coefficients using Kernel Density Estimation','Kernel Density Estimation, Discrete Wavelet Transform, Probability Density Function (PDF), Signal to Noise Ratio','Shubhada Ardhapurkar, Ramchandra Manthalkar and Suhas Gajre','dlibrary/JIPS_v08_no4_paper9.pdf','Discrete wavelet transforms are extensively preferred in biomedical signal processing for denoising, feature extraction, and compression. This paper presents a new denoising method based on the modeling of discrete wavelet coefficients of ECG in selected sub-bands with Kernel density estimation. The modeling provides a statistical distribution of information and noise. A Gaussian kernel with bounded support is used for modeling sub-band coefficients and thresholds and is estimated by placing a sliding window on a normalized cumulative density function. We evaluated this approach on offline noisy ECG records from the Cardiovascular Research Centre of the University of Glasgow and on records from the MIT-BIH Arrythmia database. Results show that our proposed technique has a more reliable physical basis and provides improvement in the Signal-to-Noise Ratio (SNR) and Percentage RMS Difference (PRD). The morphological information of ECG signals is found to be unaffected after employing denoising. This is quantified by calculating the mean square error between the feature vectors of original and denoised signal. MSE values are less than 0.05 for most of the cases.','10.3745/JIPS.2012.8.4.669',1008,1204,0,0,NULL,NULL),(246,2012,8,4,685,0,'Evaluation of the Image Backtrack-Based Fast Direct Mode Decision Algorithm','H.264/AVC, Bi-Directional Prediction, Image Backtracking, Fast Algorithm, Mode Decision','Yungho Choi and Neungsoo Park','dlibrary/JIPS_v08_no4_paper10.pdf','B frame bi-directional predictions and the DIRECT mode coding of the H.264 video compression standard necessitate a complex mode decision process, resulting in a long computation time. To make H.264 feasible, this paper proposes an image backtrackbased fast (IBFD) algorithm and evaluates the performances of two promising fast algorithms (i.e., AFDM and IBFD). Evaluation results show that an image backtrackbased fast (IBFD) algorithm can determine DIRECT mode macroblocks with 13% higher accuracy, as compared with the AFDM. Furthermore, IBFD is shown to reduce the motion estimation time of B frames by up to 23% with a negligible quality degradation','10.3745/JIPS.2012.8.4.685',896,495,0,0,NULL,NULL),(247,2012,8,4,693,0,'Machine Learning Based Keyphrase Extraction: Comparing Decision Trees, Naïve Bayes, and Artificial Neural Networks','Keyphrase Extraction, Decision Tree, Naïve Bayes, Artificial Neural Networks, Machine Learning, WEKA','Kamal Sarkar, Mita Nasipuri and Suranjan Ghose','dlibrary/JIPS_v08_no4_paper11.pdf','The paper presents three machine learning based keyphrase extraction methods that respectively use Decision Trees, Naïve Bayes, and Artificial Neural Networks for keyphrase extraction. We consider keyphrases as being phrases that consist of one or more words and as representing the important concepts in a text document. The three machine learning based keyphrase extraction methods that we use for experimentation have been compared with a publicly available keyphrase extraction system called KEA. The experimental results show that the Neural Network based keyphrase extraction method outperforms two other keyphrase extraction methods that use the Decision Tree and Naïve Bayes. The results also show that the Neural Network based method performs better than KEA.','10.3745/JIPS.2012.8.4.693',1259,906,0,0,NULL,NULL),(248,2012,8,4,713,0,'Enhanced FFD-AABB Collision Algorithm for Deformable Objects','FFD-AABB Algorithm, Physically-Based Simulation, Deformable Objects, Collision Detection, Bounding Sphere','JaeHong Jeon, Min-Hyung Choi and Min Hong','dlibrary/JIPS_v08_no4_paper12.pdf','Unlike FEM (Finite Element Method), which provides an accurate deformation of soft objects, FFD (Free Form Deformation) based methods have been widely used for a quick and responsive representation of deformable objects in real-time applications such as computer games, animations, or simulations. The FFD-AABB (Free Form Deformation Axis Aligned Bounding Box) algorithm was also suggested to address the collision handling problems between deformable objects at an interactive rate. This paper proposes an enhanced FFD-AABB algorithm to improve the frame rate of simulation by adding the bounding sphere based collision test between 3D deformable objects. We provide a comparative analysis with previous methods and the result of proposed method shows about an 85% performance improvement.','10.3745/JIPS.2012.8.4.713',1008,669,0,0,NULL,NULL),(249,2012,8,4,721,0,'Proactive: Comprehensive Access to Job Information','Job recommendation, explicit preference, implicit preference, personalized information retrieval','Danielle Lee and Peter Brusilovsky','dlibrary/JIPS_v08_no4_paper13.pdf','The Internet has become an increasingly important source for finding the right employees, so more and more companies post their job openings on the Web. The large amount and dynamic nature of career recruiting information causes information overload problems for job seekers. To assist Internet users in searching for the right job, a range of research and commercial systems were developed over the past 10 years. Surprisingly, the majority of existing job search systems support just one, rarely two ways of information access. In contrast, our work focused on exploring a value of comprehensive access to job information in a single system (i.e., a system which supports multiple ways). We designed Proactive, a recommendation system providing comprehensive and personalized information access. To assist the varied needs of users, Proactive has four information retrieval methods – a navigable list of jobs, keyword-based search, implicit preference-based recommendations, and explicit preference-based recommendations. This paper introduces the Proactive and reports the results of a study focusing on the experimental evaluation of these methods. The goal of the study was to assess whether all of the methods are necessary for users to find relevant jobs and to what extent different methods can meet different users’ information requirements.','10.3745/JIPS.2012.8.4.721',1019,588,0,0,NULL,NULL),(250,2012,8,4,739,0,'Performance Anomaly of the IEEE 802.11 DCF in Different Frame Error Rate Conditions','IEEE 802.11 DCF, Wireless LAN, Throughput and Delay Performance','Koohong Kang','dlibrary/JIPS_v08_no4_paper14.pdf','We propose an analytic model to compute the station’s saturated throughput and packet delay performance of the IEEE 802.11 DCF (Distributed Coordination Function) in which frame transmission error rates in the channel are different from each other. Our analytic model shows that a station experiencing worse frame error rates than the others suffers severe performance degradation below its deserved throughput and delay performance. 802.11 DCF adopts an exponential back-off scheme. When some stations suffer from high frame error rates, their back-off stages should be increased so that others get the benefit from the smaller collision probabilities. This impact is then recursively applied to degrade the performance of the victim stations. In particular, we show that the performance is considerably degraded even if the frame error rate of the victim station satisfies the receiver input level sensitivity that has been specified in the IEEE 802.11 standard. We also verify the analytic results by the OPNET simulations.','10.3745/JIPS.2012.8.4.739',950,837,0,0,NULL,NULL),(251,2013,9,1,1,0,'Dynamic knowledge mapping guided by data mining: Application on Healthcare','Knowledge Management, Knowledge Mapping (Knowledge Cartography), Knowledge Representation, Boolean Modeling, Cellular Machine, Data Mining, Boolean Inference Engine','Menaouer Brahami, Baghdad Atmani and Nada Matta','dlibrary/JIPS_v09_no1_paper1.pdf','The capitalization of know-how, knowledge management, and the control of the constantly growing information mass has become the new strategic challenge for organizations that aim to capture the entire wealth of knowledge (tacit and explicit). Thus, knowledge mapping is a means of (cognitive) navigation to access the resources of the strategic heritage knowledge of an organization. In this paper, we present a new mapping approach based on the Boolean modeling of critical domain knowledge and on the use of different data sources via the data mining technique in order to improve the process of acquiring knowledge explicitly. To evaluate our approach, we have initiated a process of mapping that is guided by machine learning that is artificially operated in the following two stages: data mining and automatic mapping. Data mining is be initially run from an induction of Boolean case studies (explicit). The mapping rules are then used to automatically improve the Boolean model of the mapping of critical knowledge','10.3745/JIPS.2013.9.1.001',1217,378,0,0,NULL,NULL),(252,2013,9,1,31,0,'A Feature Selection-based Ensemble Method for Arrhythmia Classification','Data Mining, Ensemble Method, Feature Selection, Arrhythmia Classification','Erdenetuya Namsrai, Tsendsuren Munkhdalai, Meijing Li, Jung-Hoon Shin, Oyun-Erdene Namsrai and Keun Ho Ryu','dlibrary/JIPS_v09_no1_paper2.pdf','In this paper, a novel method is proposed to build an ensemble of classifiers by using a feature selection schema. The feature selection schema identifies the best feature sets that affect the arrhythmia classification. Firstly, a number of feature subsets are extracted by applying the feature selection schema to the original dataset. Then classification models are built by using the each feature subset. Finally, we combine the classification models by adopting a voting approach to form a classification ensemble. The voting approach in our method involves both classification error rate and feature selection rate to calculate the score of the each classifier in the ensemble. In our method, the feature selection rate depends on the extracting order of the feature subsets. In the experiment, we applied our method to arrhythmia dataset and generated three top disjointed feature sets. We then built three classifiers based on the top-three feature subsets and formed the classifier ensemble by using the voting approach. Our method can improve the classification accuracy in high dimensional dataset. The performance of each classifier and the performance of their ensemble were higher than the performance of the classifier that was based on whole feature space of the dataset. The classification performance was improved and a more stable classification model could be constructed with the proposed approach.','10.3745/JIPS.2013.9.1.031',976,943,0,0,NULL,NULL),(253,2013,9,1,41,0,'A Dynamic Zigbee Protocol for Reducing Power Consumption','Zigbee, Low Power Protocol, Beacon, Power Consumption','Do-keun Kwon, Ki hyun Chung and Kyunghee Choi','dlibrary/JIPS_v09_no1_paper3.pdf','One of the obstacles preventing the Zigbee protocol from being widely used is the excessive power consumption of Zigbee devices in low bandwidth and low power requirement applications. This paper proposes a protocol that resolves the power efficiency problem. The proposed protocol reduces the power consumption of Zigbee devices in beacon-enabled networks without increasing the time taken by Zigbee peripherals to communicate with their coordinator. The proposed protocol utilizes a beacon control mechanism called a “sleep pattern,” which is updated based on the previous event statistics. It determines exactly when Zigbee peripherals wake up or sleep. A simulation of the proposed protocol using realistic parameters and an experiment using commercial products yielded similar results, demonstrating that the protocol may be a solution to reduce the power consumption of Zigbee devices','10.3745/JIPS.2013.9.1.041',750,351,0,0,NULL,NULL),(254,2013,9,1,53,0,'A Cross-Layer Unequal Error Protection Scheme for Prioritized H.264 Video using RCPC Codes and Hierarchical QAM','Wireless Transmission, Unequal Error Protection (UEP), Rate-Compatible Punctured Convolutional (RCPC) Code, Hierarchical Modulation, H.264/AVC Video Coding','Wei-Ho Chung, Sunil Kumar, Seethal Paluri, Santosh Nagaraj, Annamalai Annamalai Jr. and John D. Matyjas','dlibrary/JIPS_v09_no1_paper4.pdf','We investigate the rate-compatible punctured convolutional (RCPC) codes concatenated with hierarchical QAM for designing a cross-layer unequal error protection scheme for H.264 coded sequences. We first divide the H.264 encoded video slices into three priority classes based on their relative importance. We investigate the system constraints and propose an optimization formulation to compute the optimal parameters of the proposed system for the given source significance information. An upper bound to the significance-weighted bit error rate in the proposed system is derived as a function of system parameters, including the code rate and geometry of the constellation. An example is given with design rules for H.264 video communications and 3.5-4 dB PSNR improvement over existing RCPC based techniques for AWGN wireless channels is shown through simulations.','10.3745/JIPS.2013.9.1.053',825,346,0,0,NULL,NULL),(255,2013,9,1,69,0,'Agile Software Development Framework in a Small Project Environment','Agile Methods, Small Software Projects, Industrial Case Study','Seiyoung Lee and Hwan-Seung Yong','dlibrary/JIPS_v09_no1_paper5.pdf','Agile methods are highly attractive for small projects, but no agile method works well as a standalone system. Therefore, some adaption or customization is always required. In this paper, the Agile Framework for Small Projects (AFSP) was applied to four industry cases. The AFSP provides a structured way for software organizations to adopt agile practices and evaluate the results. The framework includes an extended Scrum process and agile practices, which are based on agility and critical success factors in agile software projects that are selected from Scrum, XP, FDD, DSDM and Crystal Clear. AFSP also helps software managers and developers effectively use agile engineering techniques throughout the software development lifecycle. The case study projects were evaluated on the basis of risk-based agility factors, the agility of the adopted practices, agile adoption levels, and the degree of the agile project success. The analysis of the results showed that the framework used in the aforementioned cases was effective','10.3745/JIPS.2013.9.1.069',828,1153,0,0,NULL,NULL),(256,2013,9,1,89,0,'A Fuzzy Impulse Noise Filter Based on Boundary Discriminative Noise Detection','Impulse Noise, Decision Boundaries, Color Components, Fuzzy Filter, Membership Function','Om Prakash Verma and Shweta Singh','dlibrary/JIPS_v09_no1_paper6.pdf','The paper presents a fuzzy based impulse noise filter for both gray scale and color images. The proposed approach is based on the technique of boundary discriminative noise detection. The algorithm is a multi-step process comprising detection, filtering and color correction stages. The detection procedure classifies the pixels as corrupted and uncorrupted by computing decision boundaries, which are fuzzified to improve the outputs obtained. In the case of color images, a correction term is added by examining the interactions between the color components for further improvement. Quantitative and qualitative analysis, performed on standard gray scale and color image, shows improved performance of the proposed technique over existing state-of-the-art algorithms in terms of Peak Signal to Noise Ratio (PSNR) and color difference metrics. The analysis proves the applicability of the proposed algorithm to random valued impulse noise','10.3745/JIPS.2013.9.1.089',807,734,0,0,NULL,NULL),(257,2013,9,1,103,0,'A TRUS Prostate Segmentation using Gabor Texture Features and Snake-like Contour','Gabor Filter Bank, Support Vector Machines, Prostate Segmentation','Sung Gyun Kim and Yeong Geon Seo','dlibrary/JIPS_v09_no1_paper7.pdf','Prostate cancer is one of the most frequent cancers in men and is a major cause of mortality in the most of countries. In many diagnostic and treatment procedures for prostate disease accurate detection of prostate boundaries in transrectal ultrasound(TRUS) images is required. This is a challenging and difficult task due to weak prostate boundaries, speckle noise and the short range of gray levels. In this paper a method for automatic prostate segmentation in TRUS images using Gabor feature extraction and snake-like contour is presented. This method involves preprocessing, extracting Gabor feature, training, and prostate segmentation. The speckle reduction for preprocessing step has been achieved by using stick filter and top-hat transform has been implemented for smoothing the contour. A Gabor filter bank for extraction of rotation- invariant texture features has been implemented. A support vector machine(SVM) for training step has been used to get each feature of prostate and nonprostate. Finally, the boundary of prostate is extracted by the snake-like contour algorithm. A number of experiments are conducted to validate this method and results showed that this new algorithm extracted the prostate boundary with less than 10.2% of the accuracy which is relative to boundary provided manually by experts','10.3745/JIPS.2013.9.1.103',738,513,0,0,NULL,NULL),(258,2013,9,1,117,0,'Optical Character Recognition for Hindi Language Using a Neural-network Approach','OCR, Pre-processing, Segmentation, Feature Vector, Classification, Artificial Neural Network (ANN)','Divakar Yadav, Sonia Sánchez-Cuadrado and Jorge Morato','dlibrary/JIPS_v09_no1_paper81.pdf','Hindi is the most widely spoken language in India, with more than 300 million speakers. As there is no separation between the characters of texts written in Hindi as there is in English, the Optical Character Recognition (OCR) systems developed for the Hindi language carry a very poor recognition rate. In this paper we propose an OCR for printed Hindi text in Devanagari script, using Artificial Neural Network (ANN), which improves its efficiency. One of the major reasons for the poor recognition rate is error in character segmentation. The presence of touching characters in the scanned documents further complicates the segmentation process, creating a major problem when designing an effective character segmentation technique. Preprocessing, character segmentation, feature extraction, and finally, classification and recognition are the major steps which are followed by a general OCR.\r\nThe preprocessing tasks considered in the paper are conversion of gray scaled images to binary images, image rectification, and segmentation of the document\"\'\"s textual contents into paragraphs, lines, words, and then at the level of basic symbols. The basic symbols, obtained as the fundamental unit from the segmentation process, are recognized by the neural classifier.\r\nIn this work, three feature extraction techniques-: histogram of projection based on mean distance, histogram of projection based on pixel value, and vertical zero crossing, have been used to improve the rate of recognition. These feature extraction techniques are powerful enough to extract features of even distorted characters/symbols. For development of the neural classifier, a back-propagation neural network with two hidden layers is used. The classifier is trained and tested for printed Hindi texts. A performance of approximately 90% correct recognition rate is achieved.','10.3745/JIPS.2013.9.1.117',952,1837,0,0,NULL,NULL),(259,2013,9,1,141,0,'A Robust Face Detection Method Based on Skin Color and Edges','Face Detection, Image Enhancement, Skin Tone Percentage Index, Canny Edge, Facial Features','Deepak Ghimire and Joonwhoan Lee','dlibrary/JIPS_v09_no1_paper9.pdf','In this paper we propose a method to detect human faces in color images. Many existing systems use a window-based classifier that scans the entire image for the presence of the human face and such systems suffers from scale variation, pose variation, illumination changes, etc. Here, we propose a lighting insensitive face detection method based upon the edge and skin tone information of the input color image. First, image enhancement is performed, especially if the image is acquired from an unconstrained illumination condition. Next, skin segmentation in YCbCr and RGB space is conducted. The result of skin segmentation is refined using the skin tone percentage index method. The edges of the input image are combined with the skin tone image to separate all non- face regions from candidate faces. Candidate verification using primitive shape features of the face is applied to decide which of the candidate regions corresponds to a face. The advantage of the proposed method is that it can detect faces that are of different sizes, in different poses, and that are making different expressions under unconstrained illumination conditions','10.3745/JIPS.2013.9.1.141',928,770,0,0,NULL,NULL),(260,2013,9,1,157,0,'Performance Improvement of a Movie Recommendation System based on Personal Propensity and Secure Collaborative Filtering','Collaborative Filtering, Movie Recommendation System, Personal Propensity, Security, Push Stack','Woon-hae Jeong, Se-jun Kim, Doo-soon Park and Jin Kwak','dlibrary/JIPS_v09_no1_paper10.pdf','There are many recommendation systems available to provide users with personalized services. Among them, the most frequently used in electronic commerce is \"\'\"collaborative filtering\"\'\", which is a technique that provides a process of filtering customer information for the preparation of profiles and making recommendations of products that are expected to be preferred by other users, based on such information profiles. Collaborative filtering systems, however, have in their nature both technical issues such as sparsity, scalability, and transparency, as well as security issues in the collection of the information that becomes the basis for preparation of the profiles. In this paper, we suggest a movie recommendation system, based on the selection of optimal personal propensity variables and the utilization of a secure collaborating filtering system, in order to provide a solution to such sparsity and scalability issues. At the same time,we adopt \"\'\"push attack\"\'\" principles to deal with the security vulnerability of collaborative filtering systems. Furthermore, we assess the system\"\'\"s applicability by using the open database MovieLens, and present a personal propensity framework for improvement in the performance of recommender systems. We successfully come up with a movie recommendation system through the selection of optimal personalization factors and the embodiment of a safe collaborative filtering system','10.3745/JIPS.2013.9.1.157',900,461,0,0,NULL,NULL),(261,2013,9,1,173,0,'Region-Based Facial Expression Recognition in Still Images','Facial Expression Recognition (FER), Facial Features Detection, Facial Features Extraction, Cascade Classifier, LBP, One-Vs-Rest SVM','Gawed M. Nagi, Rahmita Rahmat, Fatimah Khalid and Muhamad Taufik','dlibrary/JIPS_v09_no1_paper11.pdf','In Facial Expression Recognition Systems (FERS), only particular regions of the face are utilized for discrimination. The areas of the eyes, eyebrows, nose, and mouth are the most important features in any FERS. Applying facial features descriptors such as the local binary pattern (LBP) on such areas results in an effective and efficient FERS. In this paper, we propose an automatic facial expression recognition system. Unlike other systems, it detects and extracts the informative and discriminant regions of the face (i.e., eyes, nose, and mouth areas) using Haar-feature based cascade classifiers and these region-based features are stored into separate image files as a preprocessing step. Then, LBP is applied to these image files for facial texture representation and a feature-vector per subject is obtained by concatenating the resulting LBP histograms of the decomposed region-based features. The one-vs.-rest SVM, which is a popular multi-classification method, is employed with the Radial Basis Function (RBF) for facial expression classification. Experimental results show that this approach yields good performance for both frontal and near-frontal facial images in terms of accuracy and time complexity. Cohn-Kanade and JAFFE, which are benchmark facial expression datasets, are used to evaluate this approach.','10.3745/JIPS.2013.9.1.173',908,492,0,0,NULL,NULL),(262,2013,9,2,189,0,'The Confinement Problem: 40 Years Later','Confinement Problem, Covert Channels, Virtualization, Isolation, Taint Tracking','Alex Crowell, Beng Heng Ng, Earlence Fernandes and Atul Prakash','dlibrary/JIPS_v09_no2_paper1.pdf','The confinement problem was first noted four decades ago. Since then, a huge amount of efforts have been spent on defining and mitigating the problem. The evolution of technologies from traditional operating systems to mobile and cloud computing brings about new security challenges. It is perhaps timely that we review the work that has been done. We discuss the foundational principles from classical works, as well as the efforts towards solving the confinement problem in three domains: operating systems, mobile computing, and cloud computing. While common issues exist across all three domains, unique challenges arise for each of them, which we discuss.','10.3745/JIPS.2013.9.2.189',3029,816,14,0,NULL,NULL),(263,2013,9,2,205,0,'An Analysis of Replication Enhancement for a High Availability Cluster','High-Availability Cluster, Replication Enhancement, SRM, DRBD','Sehoon Park, Im Y. Jung, Heonsang Eom and Heon Y. Yeom','dlibrary/JIPS_v09_no2_paper2.pdf','In this paper, we analyze a technique for building a high-availability (HA) cluster system. We propose what we have termed the ‘Selective Replication Manager (SRM),’ which improves the throughput performance and reduces the latency of disk devices by means of a Distributed Replicated Block Device (DRBD), which is integrated in the recent Linux Kernel (version 2.6.33 or higher) and that still provides HA and failover capabilities. The proposed technique can be applied to any disk replication and database system with little customization and with a reasonably low performance overhead. We demonstrate that this approach using SRM increases the disk replication speed and reduces latency by 17% and 7%, respectively, as compared to the existing DRBD solution. This approach represents a good effort to increase HA with a minimum amount of risk and cost in terms of commodity hardware','10.3745/JIPS.2013.9.2.205',869,270,0,0,NULL,NULL),(264,2013,9,2,217,0,'An Improved Approach to Ranking Web Documents','Ranking, Ordering, WWW, Information Retrieval, Contextual Relevance, Contextual Sense, Web Documents','Pooja Gupta, Sandeep K. Singh, Divakar Yadav and A. K. Sharma','dlibrary/JIPS_v09_no2_paper3.pdf','Ranking thousands of web documents so that they are matched in response to a user query is really a challenging task. For this purpose, search engines use different ranking mechanisms on apparently related resultant web documents to decide the order in which documents should be displayed. Existing ranking mechanisms decide on the order of a web page based on the amount and popularity of the links pointed to and emerging from it. Sometime search engines result in placing less relevant documents in the top positions in response to a user query. There is a strong need to improve the ranking strategy. In this paper, a novel ranking mechanism is being proposed to rank the web documents that consider both the HTML structure of a page and the contextual senses of keywords that are present within it and its back-links. The approach has been tested on data sets of URLs and on their back-links in relation to different topics. The experimental result shows that the overall search results, in response to user queries, are improved. The ordering of the links that have been obtained is compared with the ordering that has been done by using the page rank score. The results obtained thereafter shows that the proposed mechanism contextually puts more related web pages in the top order, as compared to the page rank score.','10.3745/JIPS.2013.9.2.217',864,278,0,0,NULL,NULL),(265,2013,9,2,237,0,'A Study of Wireless Sensor Network Routing Protocols for Maintenance Access Hatch Condition Surveillance','Maintenance Hatch, Underground Facilities, WSN, Routing Protocol, ns-2','Hoo-Rock Lee, Kyung-Yul Chung and Kyoung-Son Jhang','dlibrary/JIPS_v09_no2_paper4.pdf','Maintenance Access Hatches are used to ensure urban safety and aesthetics while facilitating the management of power lines, telecommunication lines, and gas pipes. Such facilities necessitate affordable and effective surveillance. In this paper, we propose a FiCHS (Fixed Cluster head centralized Hierarchical Static clustering) routing protocol that is suitable for underground maintenance hatches using WSN (Wireless Sensor Network) technology. FiCHS is compared with three other protocols, LEACH, LEACH-C, and a simplified LEACH, based on an ns-2 simulation. FiCHS was observed to exhibit the highest levels of power and data transfer efficiency.','10.3745/JIPS.2013.9.2.237',1004,371,0,0,NULL,NULL),(266,2013,9,2,247,0,'A Secure Network for Mobile Wireless Service','Mobile Wireless Network, Security','Kun Peng','dlibrary/JIPS_v09_no2_paper5.pdf','A new secure network communication technique that has been designed for mobile wireless services, is presented in this paper. Its network services are mobile, distributed, seamless, and secure. We focus on the security of the scheme and achieve anonymity and reliability by using cryptographic techniques like blind signature and the electronic coin. The question we address in this paper is, “What is the best way to protect the privacy and anonymity of users of mobile wireless networks, especially in practical applications like e-commerce?” The new scheme is a flexible solution that answers this question. It efficiently protects user\"\'\"s privacy and anonymity in mobile wireless networks and supports various applications. It is employed to implement a secure e-auction as an example, in order to show its advantages in practical network applications.','10.3745/JIPS.2013.9.2.247',744,251,0,0,NULL,NULL),(267,2013,9,2,259,0,'An Integrated Neural Network Model for Domain Action Determination in Goal-Oriented Dialogues','Domain Action, Speech Act, Concept Sequence, Neural Network','Hyunjung Lee, Harksoo Kim and Jungyun Seo','dlibrary/JIPS_v09_no2_paper6.pdf','A speaker’s intentions can be represented by domain actions (domain- independent speech act and domain-dependent concept sequence pairs). Therefore, it is essential that domain actions be determined when implementing dialogue systems because a dialogue system should determine users’ intentions from their utterances and should create counterpart intentions to the users’ intentions. In this paper, a neural network model is proposed for classifying a user’s domain actions and planning a system’s domain actions. An integrated neural network model is proposed for simultaneously determining user and system domain actions using the same framework. The proposed model performed better than previous non-integrated models in an experiment using a goal-oriented dialogue corpus. This result shows that the proposed integration method contributes to improving domain action determination performance.','10.3745/JIPS.2013.9.2.259',661,239,0,0,NULL,NULL),(268,2013,9,2,271,0,'Modified Multi-Chaotic Systems that are Based on Pixel Shuffle for Image Encryption','Chaotic Systems, Number of Pixel Change Rate, Unified Average Changed Intensity, Correlation Coefficient, Entropy','Om Prakash Verma, Munazza Nizam and Musheer Ahmad','dlibrary/JIPS_v09_no2_paper7.pdf','Recently, a pixel-chaotic-shuffling (PCS) method has been proposed by Huang et al. for encrypting color images using multiple chaotic systems like the Henon, the Lorenz, the Chua, and the Rossler systems. All of which have great encryption performance. The authors claimed that their pixel-chaotic-shuffle (PCS) encryption method has high confidential security. However, the security analysis of the PCS method against the chosen-plaintext attack (CPA) and known-plaintext attack (KPA) performed by Solak et al. successfully breaks the PCS encryption scheme without knowing the secret key. In this paper we present an improved shuffling pattern for the plaintext image bits to make the cryptosystem proposed by Huang et al. resistant to chosen-plaintext attack and known-plaintext attack. The modifications in the existing PCS encryption method are proposed to improve its security performance against the potential attacks described above. The Number of Pixel Change Rate (NPCR), Unified Average Changed Intensity (UACI), information entropy, and correlation coefficient analysis are performed to evaluate the statistical performance of the modified PCS method. The simulation analysis reveals that the modified PCS method has better statistical features and is more resistant to attacks than Huang et al.’s PCS method.','10.3745/JIPS.2013.9.2.271',807,390,0,0,NULL,NULL),(269,2013,9,2,287,0,'A Secure Index Management Scheme  for Providing Data Sharing in Cloud Storage','Searchable Encryption, Proxy Re-Encryption, Index Management, Cloud Computing, Cloud Storage','Sun-Ho Lee and Im-Yeong Lee','dlibrary/JIPS_v09_no2_paper8.pdf','Cloud storage is provided as a service in order to keep pace with the increasing use of digital information. It can be used to store data via networks and various devices and is easy to access. Unlike existing removable storage, many users can use cloud storage because it has no storage capacity limit and does not require a storage medium. Cloud storage reliability has become a topic of importance, as many users employ it for saving great volumes of data. For protection against unethical administrators and attackers, a variety of cryptography systems, such as searchable encryption and proxy re-encryption, are being applied to cloud storage systems. However, the existing searchable encryption technology is inconvenient to use in a cloud storage environment where users upload their data. This is because this data is shared with others, as necessary, and the users with whom the data is shared change frequently. In this paper, we propose a searchable re-encryption scheme in which a user can safely share data with others by generating a searchable encryption index and then re-encrypt it.','10.3745/JIPS.2013.9.2.287',808,321,0,0,NULL,NULL),(270,2013,9,2,301,0,'On the Minimization of Crosstalk Conflicts in a Destination Based Modified Omega Network','Optical Multistage Interconnection Network, Crosstalk, Time Domain Approach, Omega Network, Destination Based Modified Omega Network, Crosstalk Free Modified Omega Network','Ved Prakash Bhardwaj and Nitin','dlibrary/JIPS_v09_no2_paper9.pdf','In a parallel processing system, Multi-stage Interconnection Networks (MINs) play a vital role in making the network reliable and cost effective. The MIN is an important piece of architecture for a multiprocessor system, and it has a good impact in the field of communication. Optical Multi-stage Interconnection Networks (OMINs) are the advanced version of MINs. The main problem with OMINs is crosstalk. This paper, presents the (1) Destination Based Modified Omega Network (DBMON) and the (2) Destination Based Scheduling Algorithm (DBSA). DBSA does the scheduling for a source and their corresponding destination address for messages transmission and these scheduled addresses are passed through DBMON. Furthermore, the performance of DBMON is compared with the Crosstalk-Free Modified Omega Network (CFMON). CFMON also minimizes the crosstalk in a minimum number of passes. Results show that DBMON is better than CFMON in terms of the average number of passes and execution time. DBSA can transmit all the messages in only two passes from any source to any destination, through DBMON and without crosstalk. This network is the modified form of the original omega network. Crosstalk minimization is the main objective of the proposed algorithm and proposed network.','10.3745/JIPS.2013.9.2.301',801,286,0,0,NULL,NULL),(271,2013,9,2,315,0,'An Improvement Video Search Method for VP-Tree by using a Trigonometric Inequality','Vantage Point; VP-Tree; Trigonometric Inequality; Search Algorithm; Range Search; Nearest Neighbor Search; AESA algorithm; Multimedia Database','Samuel Sangkon Lee, Masami Shishibori and Chia Y. Han','dlibrary/JIPS_v09_no2_paper10.pdf','This paper presents an approach for improving the use of VP-tree in video indexing and searching. A vantage-point tree or VP-tree is one of the metric space-based indexing methods used in multimedia database searches and data retrieval. Instead of relying on the Euclidean distance as a measure of search space, the proposed approach focuses on the trigonometric inequality for compressing the search range, which thus, improves the search performance. A test result of using 10,000 video files shows that this method reduced the search time by 5-12%, as compared to the existing method that uses the AESA algorithm.','10.3745/JIPS.2013.9.2.315',670,260,0,0,NULL,NULL),(272,2013,9,2,333,0,'Adaptive Cross-Device Gait Recognition Using a Mobile Accelerometer','Gait Recognition, Mobile Security, Accelerometer, Pattern Recognition, Authentication, Identification, Signal Processing','Thang Hoang, Thuc Nguyen, Chuyen Luong, Son Do  and Deokjai Choi','dlibrary/JIPS_v09_no2_paper11.pdf','Mobile authentication/identification has grown into a priority issue nowadays because of its existing outdated mechanisms, such as PINs or passwords. In this paper, we introduce gait recognition by using a mobile accelerometer as not only effective but also as an implicit identification model. Unlike previous works, the gait recognition only performs well with a particular mobile specification (e.g., a fixed sampling rate). Our work focuses on constructing a unique adaptive mechanism that could be independently deployed with the specification of mobile devices. To do this, the impact of the sampling rate on the preprocessing steps, such as noise elimination, data segmentation, and feature extraction, is examined in depth.  Moreover, the degrees of agreement between the gait features that were extracted from two different mobiles, including both the Average Error Rate (AER) and Intra-class Correlation Coefficients (ICC), are assessed to evaluate the possibility of constructing a device-independent mechanism. We achieved the classification accuracy approximately 91.33 ± 0.67 % for both devices, which showed that it is feasible and reliable to construct adaptive cross-device gait recognition on a mobile phone.','10.3745/JIPS.2013.9.2.333',1077,378,0,0,NULL,NULL),(273,2013,9,3,349,0,'Interactive Semantic Image Retrieval','Content-based Image Retrieval (CBIR), Relevance Feedback (RF), Rotated Complex Wavelet Filt ers (RCWFs), Dual Tree Complex Wavelet, and Image retrieval','Pushpa B. Patil and Manesh B. Kokare','dlibrary/JIPS_v09_no3_paper1.pdf','The big challenge in current content-based image retrieval systems is to reduce the semantic gap between the low level-features and high-level concepts. In this paper, we have proposed a novel framework for efficient image retrieval to improve the retrieval results significantly as a means to addressing this problem. In our proposed method, we first extracted a strong set of image features by using the dual-tree rotated complex wavelet filters (DT-RCWF) and dual tree-complex wavelet transform (DT-CWT) jointly, which obtains features in 12 different directions. Second, we presented a relevance feedback (RF) framework for efficient image retrieval by employing a support vector machine (SVM), which learns the semantic relationship among images using the knowledge, based on the user interaction. Extensive experiments show that there is a significant improvement in retrieval performance with the proposed method using SVMRF compared with the retrieval performance without RF. The proposed method improves retrieval p erformance from 78.5% to 92.29% on the texture database in terms of retrieval accuracy and from 57.20% to 94.2% on the Corel image database, in terms of precision in a much lower number of iterations.','10.3745/JIPS.2013.9.3.349',837,427,0,0,NULL,NULL),(274,2013,9,3,365,0,'An Efficient Load Balancing Scheme for Multi-Gateways in Wireless Mesh Networks','Wireless Mesh Network, Internet Gateway, Multi-Gateway Multi-Root, Load Balancing','Junping Liu and Sang-Hwa Chung','dlibrary/JIPS_v09_no3_paper2.pdf','In Wireless Mesh Networks (WMNs), we usually deploy multiple Internet Gateways (IGWs) to improve the capacity of WMNs. As most of the traffic is oriented towards the Internet and may not be distributed evenly among different IGWs, some IGWs may suffer from bottleneck problem. To solve the IGW bottleneck problem, we propose an efficient scheme to balance the load among different IGWs within a WMN. Our proposed load-balancing scheme consists of two parts: a traffic load calculation module and a traffic load migration algorithm. The IGW can judge whether the congestion has occurred or will occur by using a linear smoothing forecasting method. When the IGW detects that the congestion has occurred or will occur, it will firstly select another available IGW that has the lightest traffic load as the secondary IGW and then inform some mesh routers (MPs) which have been selected by using the Knapsack Algorithm to change to the secondary IGW. The MPs can return to their primary IGW by using a regression algorithm. Our Qualnet 5.0 experiment results show that our proposed scheme gives up to 18% end-to-end delay improvement compared with the existing schemes.','10.3745/JIPS.2013.9.3.365',775,260,0,0,NULL,NULL),(275,2013,9,3,379,0,'Round Robin with Server Affinity: A VM Load Balancing Algorithm for Cloud Based Infrastructure','Virtual Machine (VM), Server affinity, VM load balancer, CloudAnalyst, Data center, Cloudlet','Komal Mahajan, Ansuyia Makroo and Deepak Dahiya','dlibrary/JIPS_v09_no3_paper3.pdf','Cloud computing is an evolving computing paradigm that has influenced every other entity in the globalized industry, whether it is in the public sector or the private sector. Considering the growing importance of cloud, finding new ways to improve cloud services is an area of concern and research focus. The limitation of the available Virtual Machine Load balancing policies for cloud is that they do not save the state of the previous allocation of a virtual machine to a request from a Userbase and the algorithm requires execution each time a new request for Virtual Machine allocation is received from the Userbase. This problem can be resolved by developing an efficient virtual machine load balancing algorithm for the cloud and by doing a comparative analysis of the proposed algorithm with the existing algorithms.','10.3745/JIPS.2013.9.3.379',748,582,0,0,NULL,NULL),(276,2013,9,3,395,0,'Classifying Malicious Web Pages by Using an Adaptive Support Vector Machine','adaptive classification, malicious web pages, support vector machine','Young Sup Hwang, Jin Baek Kwon, Jae Chan Moon and Seong Je Cho','dlibrary/JIPS_v09_no3_paper4.pdf','In order to classify a web page as being benign or malicious, we designed 14 basic and 16 extended features. The basic features that we implemented were selected to represent the essential characteristics of a web page. The system heuristically combines two basic features into one extended feature in order to effectively distinguish benign and malicious pages. The support vector machine can be trained to successfully classify pages by using these features. Because more and more malicious web pages are appearing, and they change so rapidly, classifiers that are trained by old data may misclassify some new pages. To overcome this problem, we selected an adaptive support vector machine (aSVM) as a classifier. The aSVM can learn training data and can quickly learn additional training data based on the support vectors it obtained during its previous learning session. Experimental results verified that the aSVM can classify malicious web pages adaptively.','10.3745/JIPS.2013.9.3.395',763,476,0,0,NULL,NULL),(277,2013,9,3,405,0,'A New Approach for Information Security using an Improved Steganography Technique','Adaptive LSB Steganography, AES; Hybrid Feature Detection, Random Pixel Embeddin g, Steganography, Two Component based LSB Steganography','Mamta Juneja and Parvinder Singh Sandhu','dlibrary/JIPS_v09_no3_paper5.pdf','This research paper proposes a secured, robust approach of information security using steganography. It presents two component based LSB (Least Significant Bit) steganography methods for embedding secret data in the least significant bits of blue components and partial green components of random pixel locations in the edges of images. An adaptive LSB based steganography is proposed for embedding data based on the data available in MSB’s (Most Significant Bits) of red, green, and blue components of randomly selected pixels across smooth areas. A hybrid feature detection filter is also proposed that performs better to predict edge areas even in noisy conditions. AES (Advanced Encryption Standard) and random pixel embedding is incorporated to provide two-tier security. The experimental results of the proposed approach are better in terms of PSNR and capacity. The comparison analysis of output results with other existing techniques is giving the proposed approach an edge over others. It has been thoroughly tested for various steganalysis attacks like visual analysis, histogram analysis, chi-square, and RS analysis and could sustain all these attacks very well.','10.3745/JIPS.2013.9.3.405',752,421,0,0,NULL,NULL),(278,2013,9,3,425,0,'An Architecture for Home-Oriented IPTV Service Platform on Residential Gateway','A Home Network, IPTV, Service Platform, Open Architecture, Home Electronic System (HES), Home Gateway Initiative (HGI)','Pyung Soo Kim','dlibrary/JIPS_v09_no3_paper6.pdf','In order for end-users in home networks to receive opportunities for useful services that go beyond legacy Internet Protocol TV (IPTV) services, this paper proposes a service platform that resides on the residential gateway (RG) for interworking between the home network and IPTV. This proposed service platform is called the home-oriented IPTV service platform (HISP) on the RG (HISP-RG). The proposed HISP-RG provides open architecture and functionalities to enable 3rd party IPTV service providers to locally and directly deliver home-oriented IPTV services to end-users in home networks. The HISP-RG can be an “add-on” and not a “built-in” solution for the existing standard RG. This paper introduces several home-oriented IPTV services that can be executed and delivered locally through the HISP-RG. Then, the open architecture and functionalities of the HISP-RG are defined and their requirements are specified. Finally, use cases of the HISP-RG for home-oriented IPTV services are presented.','10.3745/JIPS.2013.9.3.425',631,354,0,0,NULL,NULL),(279,2013,9,3,435,0,'A Regularity-Based Preprocessing Method for Collaborative Recommender Systems','Collaborative Recommender Systems, Inconsistencies, Rating Regularities','Raciel Yera Toledo, Yailé Caballero Mota and Milton García Borroto','dlibrary/JIPS_v09_no3_paper7.pdf','Recommender systems are popular applications that help users to identify items that they could be interested in. A recent research area on recommender systems focuses on detecting several kinds of inconsistencies associated with the user preferences. However, the majority of previous works in this direction just process anomalies that are intentionally introduced by users. In contrast, this paper is centered on finding the way to remove non-malicious anomalies, specifically in collaborative filtering systems. A review of the state-of-the-art in this field shows that no previous work has been carried out for recommendation systems and general data mining scenarios, to exactly perform this preprocessing task. More specifically, in this paper we propose a method that is based on the extraction of knowledge from the dataset in the form of rating regularities (similar to frequent patterns), and their use in order to remove anomalous preferences provided by users. Experiments show that the application of the procedure as a preprocessing step improves the performance of a data-mining task associated with the recommendation and also effectively detects the anomalous preferences.','10.3745/JIPS.2013.9.3.435',649,341,0,0,NULL,NULL),(280,2013,9,3,461,0,'Anonymous Authentication Scheme based on NTRU for the Protection of Payment Information in NFC Mobile Environment','NFC Mobile Payment, Zero Knowledge Proof, NTRU, Ring Signature','Sung-Wook Park and Im-Yeong Lee','dlibrary/JIPS_v09_no3_paper8.pdf','Recently, smart devices for various services have been developed using converged telecommunications, and the markets for near field communication mobile services is expected to grow rapidly. In particular, the realization of mobile NFC payment services is expected to go commercial, and it is widely attracting attention both on a domestic and global level. However, this realization would increase privacy infringement, as personal information is extensively used in the NFC technology. One example of such privacy infringement would be the case of the Google wallet service. In this paper, we propose an zero-knowledge proof scheme and ring signature based on NTRU for protecting user information in NFC mobile payment systems without directly using private financial information of the user.','10.3745/JIPS.2013.9.3.461',706,310,0,0,NULL,NULL),(281,2013,9,3,477,0,'Self-Localized Packet Forwarding in Wireless Sensor Networks','Localization, Node Density, Packet Forwarding, Redundancy, WSNs','Tarun Dubey and O. P. Sahu','dlibrary/JIPS_v09_no3_paper9.pdf','Wireless Sensor Networks (WSNs) are comprised of sensor nodes that forward data in the shape of packets inside a network. Proficient packet forwarding is a prerequisite in sensor networks since many tasks in the network, together with redundancy evaluation and localization, depend upon the methods of packet forwarding. With the motivation to develop a fault tolerant packet forwarding scheme a Self-Localized Packet Forwarding Algorithm (SLPFA) to control redundancy in WSNs is proposed in this paper. The proposed algorithm infuses the aspects of the gossip protocol for forwarding packets and the end to end performance of the proposed algorithm is evaluated for different values of node densities in the same deployment area by means of simulations.','10.3745/JIPS.2013.9.3.477',730,287,0,0,NULL,NULL),(282,2013,9,3,489,0,'A Simulation Model of Object Movement for Evaluating the Communication Load in Networked Virtual Environments','Networked Virtual Environments, Simulation Model, Load Distribution, Interest Management','Mingyu Lim and Yunjin Lee','dlibrary/JIPS_v09_no3_paper10.pdf','In this paper, we propose a common simulation model that can be reused for different performance evaluations of networked virtual environments. To this end, we analyzed the common features of NVEs, in which multiple regions compose a shared space, and where a user has his/her own interest area. Communication architecture can be client-server or peer-server models. In usual simulations, users move around the world while the number of users varies with the system. Our model provides various simulation parameters to customize the region configuration and user movement pattern. Furthermore, our model introduces a way to mimic a lot of users in a minimal experiment environment. The proposed model is integrated with our network framework, which supports various scalability approaches. We specifically applied our model to the interest management and load distribution schemes to evaluate communication overhead. With the proposed simulation model, a new simulation can be easily designed in a large-scale environment.','10.3745/JIPS.2013.9.3.489',681,250,0,0,NULL,NULL),(283,2013,9,3,499,0,'Hardware Software Co-Simulation of the Multiple Image Encryption Technique Using the Xilinx System Generator','Image Encryption, Latin Square','Panduranga H T, Dr. Naveen Kumar S K and Sharath Kumar H S','dlibrary/JIPS_v09_no3_paper11.pdf','Hardware-Software co-simulation of a multiple image encryption technique shall be described in this paper. Our proposed multiple image encryption technique is based on the Latin Square Image Cipher (LSIC). First, a carrier image that is based on the Latin Square is generated by using 256-bits of length key. The XOR operation is applied between an input image and the Latin Square Image to generate an encrypted image. Then, the XOR operation is applied between the encrypted image and the second input image to encrypt the second image. This process is continues until the nth input image is encrypted. We achieved hardware co-simulation of the proposed multiple image encryption technique by using the Xilinx System Generator (XSG). This encryption technique is modeled using Simulink and XSG Block set and synthesized onto Virtex 2 pro FPGA device. We validated our proposed technique by using the hardware software co-simulation method.','10.3745/JIPS.2013.9.3.499',1122,552,0,0,NULL,NULL),(284,2013,9,4,511,537,'Developing a Dynamic Materialized View Index for Efficiently Discovering Usable Views for Progressive Queries','Database, query processing, query optimization, progressive query, materialized view, index','Chao Zhu, Qiang Zhu, Calisto Zuzarte, and Wenbin Ma','dlibrary/JIPS_v09_no4_paper1.pdf','Numerous data intensive applications demand the efficient processing of a noew type of query, which is called a progressive query (PQ). A PQ consists of a set of unpredictable but inter-related step-queries (SQ) that are specified by its user in a sequence of steps. A conventional DBMS was not designed to efficiently process such PQs. In our earlier work, we introduced a materialized view based approach for efficiently processing PQs, where the focus was on selecting promising views for materialization. The problem of how to efficiently find usable views from the materialized set in order to answer the SQs for a PQ remains open. In this paper, we present a new index technique, called the Dynamic Materialized View Index(DMVI), to rapidly discover usable views for answering a given SQ. The structure of the proposed index is a special ordered tree where the SQ domain tables are used as search keys and some bitmaps are kept at the leaf nodes for refined filtering. A two-level priority rule is adopted to order domain tables in the tree, which facilitates the efficient maintenance of the tree by taking into account the dynamic characteristics of various types of materialized views for PQs. The bitmap encoding methods and the strategies/algorithms to construct, search, and maintain the DMVI are suggested. The extensive experimental results demonstrate that our index technique is quite promising in improving the performance of the materialized view based query processing approach for PQs','10.3745/JIPS.2013.9.4.511',1018,266,0,0,NULL,NULL),(285,2013,9,4,538,547,'Opinion Bias Detection Based on Social Opinions for Twitter','Social opinion, Personal opinion, Bias detection, Sentiment, Target','A-Rong Kwon and Kyung-Soon Lee','dlibrary/JIPS_v09_no4_paper2.pdf','In this paper, we propose a bias detection method that is based on personal and social opinions that express contrasting views on competing topics on Twitter. We used unsupervised polarity classification is conducted for learning social opinions on targets. The tf-idf algorithm is applied to extract targets to reflect sentiments and features of tweets. Our method addresses there being a lack of a sentiment lexicon when learning social opinions. To evaluate the effectiveness of our method, experiments were conducted on four issues using Twitter test collection. The proposed method achieved significant improvements over the baselines.','10.3745/JIPS.2013.9.4.538',763,325,0,0,NULL,NULL),(286,2013,9,4,548,566,'Developing a Web-Based Knowledge Product Outsourcing System at a University','Knowledge Product Outsourcing, Management, Web 2.0, IT in Education','Mark B. Onte and Dave E. Marcial','dlibrary/JIPS_v09_no4_paper3.pdf','The availability of technology and the abundance of experts in universities create an ample opportunity to provide a venue that allows a knowledge seeker to easily connect with and request advice from university experts. On the other hand, outsourcing provides opportunities and remains one of the emerging trends in organizations, and can very clearly observed in the Philippines. This paper describes teh development of a reliable web-based approach to Knowledge Product Outsourcing (KPO) services in the Silliman Online University Learning system. The system is called an \"e-Knowledge Box.\" It integrates Web 2.0 technologies and mechanisms, such as instant messaging, private messaging, document forwarding, video conferencing, online payments, net meetings, and social collaboration together into one system. Among the tools used are WAMP Server 2.0, PHP, BlabIM, Wordpress 3.0, Video Whisper, Red5, Adobe Dreamweaver CS4, and Virtual Box. The proposed system is integrated with the search engine in URLs, Web feeds, email links, social bookmarking, search engine sitemaps, and Web Analytics Direct Visitor Reports. The site demonstrates great web usability and has an excellent rating in functionality, language and content, online help and user guides, system and user feedback, consistency, and architectural and visual clarity. Likewise, the site was was reted as being very good for the following items: navigation navigation, user control, and error prevention and correction.','10.3745/JIPS.2013.9.4.548',864,902,0,0,NULL,NULL),(287,2013,9,4,567,574,'The Architectural Pattern of a Highly Extensible System for the Asynchronous Processing of a Large Amount of Data','Large data, UML Diagram, Object-Oriented Software','Ro Man Hwang, Soo Kyun Kim, Syungog An, and Dong-Won Park','dlibrary/JIPS_v09_no4_paper4.pdf','In this paper, we have proposed an architectural solution for a system for the visualization and modification of large amounts of data. The pattern is based on an asynchronous executio of programmable commands and a reflective approach of an object structure composition. The described pattern provides great flexibility, which helps adopting it easily to custom application needs. We have implemented a system based on the described pattern. The implemented system presents an innovative approach for a dynamic data object initialization and a flexible system for asynchronous interaction with data sources. We believe that this system can help software developers increase the quality and the production speed of their software products.','10.3745/JIPS.2013.9.4.567',708,282,0,0,NULL,NULL),(288,2013,9,4,575,591,'Simple Fuzzy Rule Based Edge Detection','Edge detection, Edge improvement, Fuzzy rules, Membership function','O.P. Verma, Veni Jain, and Rajni Gumber','dlibrary/JIPS_v09_no4_paper5.pdf','Most of the edge detection methods available in literature are gradient based, which further apply thresholding, to find the final edge map in an image. In this paper, we propose a novel method that is based on fuzzy logic is a mathematical logic that attempts to solve problems by assigning values to an imprecise spectrum of data in order to arrive at the most accurate conclusion possible. Here, the fuzzy logic is used to conclude whether a pixel is an edge pixel or not. The proposed technique begins by fuzzifying the gray values of a pixel into two fuzzy variables, namely the black and the white. Fuzzy rules are defined to find the edge pixels in the fuzzified image. The resultant edge map may contain some extraneous edges, which are further removed from the edge map by separately examining the intermediate intensity range pixels. Finally, the edge map is improved by finding some left out edge pixels by defining a new membership function for the pixels that have their entire 8-neighbourhood pixels classified as white. We have compared our proposed method with some of the existing standard edge detector operators that are available in the literature on image processing. The quantitative analysis of the proposed method is given in terms of entropy value.','10.3745/JIPS.2013.9.4.575',838,267,0,0,NULL,NULL),(289,2013,9,4,592,601,'Small Object Segmentation Based on Visual Saliency in Natural Images','Gaussian Mixture Model (GMM), Visual Saliency, Segmentation, Object Detection.','Huynh Trung Manh and Gueesang Lee','dlibrary/JIPS_v09_no4_paper6.pdf','Object segmentation is a challenging task in image processing and computer vision. In this paper, we present a visual attention based segmentation method to segment small sized interesting objects in natural images. Different from the traditional methods, we first search the region of interest by using our novel saliency-based method, which is mainly based on band-pass filtering, to obtain the appropriate frequency. Secondly, we applied the Gaussian Mixture Model (GMM) to locate the object region. By incorporating the visual attention analysis into object segmentation, our proposed approach is able to narrow the search region for object segmentation, so that the accuracy is increased and the computational complexity is reduced. The experimental results indicate that our proposed approach is efficient for object segmentation in natural images, especially for small objects. Our proposed method significantly outperforms traditional GMM based segmentation.','10.3745/JIPS.2013.9.4.592',2235,317,0,0,NULL,NULL),(290,2013,9,4,602,620,'Automatic Single Document Text Summarization Using Key Concepts in Documents','Automatic Text Summarization, Key Concepts, Keyphrase Extraction','Kamal Sarkar','dlibrary/JIPS_v09_no4_paper7.pdf','Many previous research studies on extractive text summarization consider a subset of words in a document as keywords and use a sentence ranking function that ranks sentences based on their similarities with the list of extracted keywords. But the use of key concepts in automatic text summarization task has received less attention in literature on summarization. The proposed work uses key concepts identified from a document for creating a summary of the document. We view single-word or multi-word keyphrases of a document as the important concepts that a document elaborates on. Our work is based on the hypothesis that an extract is an elaboration of the important concepts to some permissible extent and it is controlled by the given summary length restriction. In other words, our method of text summarization chooses a subset of sentences from a document that maximizes the important concepts in the final summary. To allow diverse information in the summary, for each important concpet, we select one sentence that is the best possible elaboration of the concept. Accordingly, the most important concept will contribute first to the summary, then to the second best concept, and so on. To prove the effectiveness fo our proposed summarization method, we have compared it to some state-of-the art summarization systems and the results show that the proposed method outperforms the existing systems to which it is compared.','10.3745/JIPS.2013.9.4.602',961,286,0,0,NULL,NULL),(291,2013,9,4,621,632,'An Intelligent Automatic Early Detection System of Forest Fire Smoke Signatures using Gaussian Mixture Model','Forest Fire Detection, Gaussian Mixture Models, HSL Color Space, Smoke Signature','Seok-Hwan Yoon and Joonyoung Min','dlibrary/JIPS_v09_no4_paper8.pdf','The most important things for a forest fire detection system are the exact extraction of the smoke from image and being able to clearly distinguish the smoke from those with similar qualities, such as clouds and fog. This research presents an intelligent forest fire detection algorithm via image processing by using the Gaussian Mixture model (GMM), which can be applied to detect smoke at the earliest time possible in a forest. GMMs are usually addressed by making the model adaptive so that its parameters can track changing illuminations and by making the model more complex so that it can represent multimodal backgrounds more accurately for smoke plume segmentation in the forest. Also, in this paper, we suggest a way to classify the smoke plumes via a feature extraction using HSL(Hue, Saturation and Lightness or Luminanace) color space analysis.','10.3745/JIPS.2013.9.4.621',939,429,0,0,NULL,NULL),(292,2013,9,4,633,650,'A Computational Intelligence Based Online Data Imputation Method: An Application For Banking','Data Imputation, General Regression Neural Network (GRNN), Evolving Clustering Method (ECM), Imputation, K-Medoids clustering, K-Means clustering, MLP','Kancherla Jonah Nishanth, and Vadlamani Ravi','dlibrary/JIPS_v09_no4_paper9.pdf','All the imputation techniques proposed so far in literature for data imputation are offline techniques as they require a number of iterations to learn the characteristics of data during training and they also consume a lot of computational time. Hence, these techniques are not suitable for applications that require the imputation to be performed on demand and near real-time. The paper proposes a computational intelligence based architecture for online data imputation and extended versions of an existing offline data imputation method as well. The proposed online imputation technique has 2 stages. In stage 1, Evolving Clustering Method (ECM) is used to replace the missing vlaues with cluster centers, as part of the local learnig strategy Stage 2 refines the resultant approximate values using a Genearal Regression Neural Network (GRNN) as part of the global approximation strategy. We also propose extended versions of an existing offline imputation technique. The offline imputation techniques emploly K-Means or K-Medoids and Multi Layer Perceptron (MLP) or GRNN in Stage-1 and Stage-2 respectively. Several experiments were conducted on 8 benchmark datasets and 4 bank related datasets to assess the effectiveness of the proposed online and offline imputation techniques. In terms of Mean Absolute Percentage Error (MAPE), the results indicate that the difference between the proposed best offline imputation method viz., K-Medoids+GRNN and the proposed online imputation method viz., ECM+GRNN is statistically insignificant at a 1% level of significance. Consequently, the proposed online technique, being less expensive and faster, can be employed for imputation instead of the existing and proposed offline imputation techniques. This is the significant outcome of the study. Furthermore, GRNN in stage-2 uniformly reduced MAPE values in both offline and online imputation methods on all datasets.','10.3745/JIPS.2013.9.4.633',670,486,0,0,NULL,NULL),(293,2013,9,4,651,659,'A Network-Based Handover Scheme in HIP-Based Mobile Networks','HIP, network-based, handover, simulations','Moneeb Gohar and Seok-Joo Koh','dlibrary/JIPS_v09_no4_paper10.pdf','In the Host Identity Protocol (HIP), the existing host-based handovr scheme tends to induce large handover delays and packet loss rates. To deal with this problem, we are proposing a network-based andover scheme for HIP in the mobile networks, in which the access routers of the mobile node will establish a handover tunnel and will perform the route optimization for data transmission. We also discuss how to extend the HIP Update message to use the proposed handover scheme. From ns-2 simulations, we can see that the proposed handover scheme can significantly reduce the handover delay and packet losses during handover, as compared to the existing handover schemes.','10.3745/JIPS.2013.9.4.651',748,278,0,0,NULL,NULL),(294,2013,9,4,660,677,'Discriminatory Projection of Camouflaged Texture Through Line Masks','Camouflage, Line mask, Enhancement, Texture analysis, Distribution pattern, Histogram, Regression line','Nagappa Bhajantri, Pradeep Kumar R, and Nagabhushan P','dlibrary/JIPS_v09_no4_paper11.pdf','The blending of defective texture with the ambiencee texture results in camouflage. The gray value or color distribution pattern of the camouflaged images fails to reflect considerable deviations between the camouflaged object and the sublimating background demands improved strategies for texture analysis. In this research, we propose the implementation of an initial enhancement of the image that employs line masks, which could result in a better discrimination of the camouflaged portion. Finally, the gray value distribution patterns are analyzed in the enhanced image, to fix the camouflaged portions.','10.3745/JIPS.2013.9.4.660',689,282,0,0,NULL,NULL),(295,2014,10,1,1,22,'Janus - Multi Source Event Detection and Collection System for Effective Surveillance of Criminal Activity','Multi-source, Multi-modal Event Detection, Law Enforcement, Criminal Activity, Surveillance, Security, Safety','Cyrus Shahabi, Seon Ho Kim, Luciano Nocera, Giorgos Constantinou, Ying Lu, Yinghao Cai, Gérard Medioni, Ramakant Nevatia and Farnoush Banaei-Kashani','dlibrary/JIPS_v10_no1_paper1.pdf','Recent technological advances provide the opportunity to use large amounts of multimedia data from a multitude of sensors with different modalities (e.g., video, text) for the detection and characterization of criminal activity. Their integration can compensate for sensor and modality deficiencies by using data from other available sensors and modalities. However, building such an integrated system at the scale of neighborhood and cities is challenging due to the large amount of data to be considered and the need to ensure a short response time to potential criminal activity. In this paper, we present a system that enables multi-modal data collection at scale and automates the detection of events of interest for the surveillance and reconnaissance of criminal activity. The proposed system showcases novel analytical tools that fuse multimedia data streams to automatically detect and identify specific criminal events and activities. More specifically, the system detects and analyzes series of incidents (an incident is an occurrence or artifact relevant to a criminal activity extracted from a single media stream) in the spatiotemporal domain to extract events (actual instances of criminal events) while cross-referencing multimodal media streams and incidents in time and space to provide a comprehensive view to a human operator while avoiding information overload. We present several case studies that demonstrate how the proposed system can provide law enforcement personnel with forensic and real time tools to identify and track potential criminal activity.','10.3745/JIPS.2014.10.1.001',3764,520,15,0,NULL,NULL),(296,2014,10,1,23,35,'Trivariate B-spline Approximation of Spherical Solid Objects','Trivariate B-spline Approximation, Volume Mesh Parameterization, Topological Sphere Model, Harmonic Mapping','Junho Kim, Seung-Hyun Yoon, and Yunjin Lee','dlibrary/JIPS_v10_no1_paper2.pdf','Recently, novel application areas in digital geometry processing, such as simulation, dynamics, and medical surgery simulations, have necessitated the representation of not only the surface data but also the interior volume data of a given 3D object. In this paper, we present an efficient framework for the hape approximations of spherical solid objects based on trivariate B-splines. To do this, we first constructed a smooth correspondence between a given object and a unit solid cube by computing their harmonic mapping. We set the unit solid cube as a rectilinear parametric domain for trivariate B-splines and utilized the mapping to approximate the given object with B-splines in a coarse-to-fine manner. Specifically, our framework provides usercontrollability of shape approximations, based on the control of the boundary condition of the harmonic parameterization and the level of B-spline fitting. Experimental results showed that our method is efficient enough to compute trivariate B-splines for several\r\nmodels, each of whose topology is identical to a solid sphere.','10.3745/JIPS.2014.10.1.023',634,440,0,0,NULL,NULL),(297,2014,10,1,36,54,'A Token Based Protocol for Mutual Exclusion in Mobile Ad Hoc Networks','MANET, Inter-Cluster, Intra-Cluster, Mutual Exclusion, Token Ring','Bharti Sharma, Ravinder Singh Bhatia, and Awadhesh Kumar Singh','dlibrary/JIPS_v10_no1_paper3.pdf','Resource sharing is a major advantage of distributed computing. However, a distributed computing system may have some physical or virtual resource that may be accessible by a single process at a time. The mutual exclusion issue is to ensure that no more than one process at a time is allowed to access some shared resource. The article proposes a token-based mutual exclusion algorithm for the clustered mobile ad hoc networks (MANETs). The mechanism that is adapted to handle token passing at the inter-cluster level is different from that at the intra-cluster level. It makes our algorithm message efficient and thus suitable for MANETs. In the interest of efficiency, we implemented a centralized token passing scheme at the intra-cluster level. The centralized schemes are inherently failure prone. Thus, we have presented an intracluster token passing scheme that is able to tolerate a failure. In order to enhance reliability, we applied a distributed token circulation scheme at the inter-cluster level. More importantly, the message complexity of the proposed algorithm is independent of N, which is the total number of nodes in the system. Also, under a heavy load, it turns out to be inversely proportional to n, which is the (average) number of nodes per each cluster. We substantiated our claim with the correctness proof, complexity analysis, and simulation results. In the end, we present a simple approach to make our protocol fault tolerant.','10.3745/JIPS.2014.10.1.036',817,341,0,0,NULL,NULL),(298,2014,10,1,55,68,'Stroke Width-Based Contrast Feature for Document Image Binarization','Degraded Document Image, Binarization, Stroke Width, Contrast Feature, Text Boundary','Le Thi Khue Van and Gueesang Lee','dlibrary/JIPS_v10_no1_paper4.pdf','Automatic segmentation of foreground text from the background in degraded document images is very much essential for the smooth reading of the document content and recognition tasks by machine. In this paper, we present a novel approach to the binarization of degraded document images. The proposed method uses a new local contrast feature extracted based on the stroke width of text. First, a pre-processing method is carried out for noise removal. Text boundary detection is then performed on the image constructed from the contrast feature. Then local estimation follows to extract text from the background. Finally, a refinement procedure is applied to the binarized image as a post-processing step to improve the quality of the final results. Experiments and comparisons of extracting text from degraded handwriting and machine-printed document image against some well-known binarization algorithms demonstrate the effectiveness of the proposed method.','10.3745/JIPS.2014.10.1.055',609,398,0,0,NULL,NULL),(299,2014,10,1,69,80,'The Construction and Viterbi Decoding of New (2k, k, l) Convolutional Codes','Convolutional Codes, Block Codes, Double Loop Cyclic Codes, Matrix Decoding, Viterbi Algorithm','Wanquan Peng and Chengchang Zhang','dlibrary/JIPS_v10_no1_paper5.pdf','The free distance of (n, k, l) convolutional codes has some connection with the memory length, which depends on not only l but also on k. To efficiently obtain a large memory length, we have constructed a new class of (2k, k, l) convolutional codes by (2k, k) block codes and (2, 1, l) convolutional codes, and its encoder and generation function are also given in this paper. With the help of some matrix modules, we designed a single structure Viterbi decoder with a parallel capability, obtained a unified and efficient decoding model for (2k, k, l) convolutional codes, and then give a description of the decoding process in detail. By observing the survivor path memory in a matrix viewer, and testing the role of the max module, we implemented a simulation with (2k, k, l) convolutional codes. The results show that many of them are better than conventional (2, 1, l) convolutional codes.','10.3745/JIPS.2014.10.1.069',492,198,0,0,NULL,NULL),(300,2014,10,1,81,92,'Push-N-Scheme with Timeout for Content Delivery of Social Networking Services','Push Scheme, Content Delivery, SNS, Wait Time','Kyungkoo Jun','dlibrary/JIPS_v10_no1_paper6.pdf','Widely spreading smart devices have become an important information sharing channel in everyday life. In particular, social networking services (SNS) are the hub for content creation and sharing. Users post their contents on SNS servers and receive contents of interest. Contents are delivered in either pull or push. Regarding delivery, cost and wait time are two important factors to be minimized, but they are in a trade-off relationship. The Push-N-scheme (PNS) and timeout-based push scheme (TPS) have been proposed for content delivery. PNS has an advantage in cost over TPS, whereas TPS has an edge in terms of the wait time over PNS. We propose a hybrid push scheme of PNS and TPS, called push-N-scheme with timeout (PNT), to balance the cost and the wait time. We evaluate PNT through simulations, with the results showing that PNT is effective in balancing PNS and TPS.','10.3745/JIPS.2014.10.1.081',557,231,0,0,NULL,NULL),(301,2014,10,1,92,102,'Gesture Input as an Out-of-band Channel','Secure Device Pairing, Out-of-band Channel, Authentication, Gesture Input, Accelerometer','Oyuntungalag Chagnaadorj and Jiro Tanaka','dlibrary/JIPS_v10_no1_paper7.pdf','In recent years, there has been growing interest in secure pairing, which refers to the establishment of a secure communication channel between two mobile devices. There are a number of descriptions of the various types of out-of-band (OOB) channels, through which authentication data can be transferred under a user’s control and involvement. However, none have become widely used due to their lack of adaptability to the variety of mobile devices. In this paper, we introduce a new OOB channel, which uses accelerometer-based gesture input. The gesture-based OOB channel is suitable for all kinds of mobile devices, including input/output constraint devices, as the accelerometer is small and incurs only a small computational overhead. We implemented and evaluated the channel using an Apple iPhone handset. The results demonstrate that the channel is viable with completion times and error rates that are comparable with other OOB channels.','10.3745/JIPS.2014.10.1.092',572,231,0,0,NULL,NULL),(302,2014,10,1,103,118,'Cooperation-Aware VANET Clouds: Providing Secure Cloud Services to Vehicular Ad Hoc Networks','VANET Clouds, Security, Privacy, Traffic Information, Data Dissemination, Cloud Computing','Rasheed Hussain and Heekuck Oh','dlibrary/JIPS_v10_no1_paper8.pdf','Over the last couple of years, traditional VANET (Vehicular Ad Hoc NETwork) evolved into VANET-based clouds. From the VANET standpoint, applications became richer by virtue of the boom in automotive telematics and infotainment technologies. Nevertheless, the research community and industries are concerned about the under-utilization of rich computation, communication, and storage resources in middle and high-end vehicles. This phenomenon became the driving force for the birth of VANET-based clouds. In this paper, we envision a novel application layer of VANET-based clouds based on the cooperation of the moving cars on the road, called CaaS (Cooperation as a Service). CaaS is divided into TIaaS (Traffic Information as a Service), WaaS (Warning as a Service), and IfaaS (Infotainment as a Service). Note, however, that this work focuses only on TIaaS and WaaS. TIaaS provides vehicular nodes, more precisely subscribers, with the fine-grained traffic information constructed by CDM (Cloud Decision Module) as a result of the cooperation of the vehicles on the roads in the form of mobility vectors. On the other hand, WaaS provides subscribers with potential warning messages in case of hazard situations on the road. Communication between the cloud infrastructure and the vehicles is done through GTs (Gateway Terminals), whereas GTs are physically realized through RSUs (Road-Side Units) and vehicles with 4G Internet access. These GTs forward the coarse-grained cooperation from vehicles to cloud and fine-grained traffic information and warnings from cloud to vehicles (subscribers) in a secure, privacy-aware fashion. In our proposed scheme, privacy is conditionally preserved wherein the location and the identity of the cooperators are preserved by leveraging the modified location-based encryption and, in case of any dispute, the node is subject to revocation. To the best of our knowledge, our proposed scheme is the first effort to offshore the extended traffic view construction function and warning messages dissemination function to the cloud.','10.3745/JIPS.2014.10.1.103',676,355,0,0,NULL,NULL),(303,2014,10,1,119,131,'Performance Evaluation of the VoIP Services of the Cognitive Radio System, Based on DTMC','Cognitive Radio, VoIP, DTMC, Cross-layer Analytical Model, M/G/1(m) Traffic, IEEE 802.16e/m','Ummy Habiba, Md. Imdadul Islam, and M. R. Amin','dlibrary/JIPS_v10_no1_paper9.pdf','In recent literature on traffic scheduling, the combination of the twodimensional discrete-time Markov chain (DTMC) and the Markov modulated Poisson process (MMPP) is used to analyze the capacity of VoIP traffic in the cognitive radio system. The performance of the cognitive radio system solely depends on the accuracy of spectrum sensing techniques, the minimization of false alarms, and the scheduling of traffic channels. In this paper, we only emphasize the scheduling of traffic channels (i.e., traffic handling techniques for the primary user [PU] and the secondary user [SU]). We consider the following three different traffic models: the cross-layer analytical model, M/G/1(m) traffic, and the IEEE 802.16e/m scheduling approach to evaluate the performance of the VoIP services of the cognitive radio system from the context of blocking probability and throughput.','10.3745/JIPS.2014.10.1.119',570,227,0,0,NULL,NULL),(304,2014,10,1,132,144,'How to Manage Cloud Risks Based on the BMIS Model','Cloud Risk, Risk Control, Cloud Computing, BMIS, CSFs','Youjin Song and Yasheng Pang','dlibrary/JIPS_v10_no1_paper10.pdf','Information always comes with security and risk problems. There is the saying that, “The tall tree catches much wind,” and the risks from cloud services will absolutely be more varied and more severe. Nowadays, handling these risks is no longer just a technology problem. So far, a good deal of literature that focuses on risk or security management and frameworks in information systems has already been submitted. This paper analyzes the causal risk factors in cloud environments through critical success factors, from a business perspective. We then integrated these critical success factors into a business model for information security by mapping out 10 principles related to cloud risks. Thus, we were able to figure out which aspects should be given more consideration in the actual transactions of cloud services, and were able to make a business-level and general-risk control model for cloud computing.','10.3745/JIPS.2014.10.1.132',596,307,0,0,NULL,NULL),(305,2014,10,1,145,161,'Probabilistic Models for Local Patterns Analysis','Global Pattern, Maximum Entropy Method, Non-derivable Itemset, Itemset Inclusion-exclusion Model','Khiat Salim, Belbachir Hafida, and Rahal Sid Ahmed','dlibrary/JIPS_v10_no1_paper11.pdf','Recently, many large organizations have multiple data sources (MDS’) distributed over different branches of an interstate company. Local patterns analysis has become an effective strategy for MDS mining in national and international organizations. It consists of mining different datasets in order to obtain frequent patterns, which are forwarded to a centralized place for global pattern analysis. Various synthesizing models [2,3,4,5,6,7,8,26] have been proposed to build global patterns from the forwarded patterns. It is desired that the synthesized rules from such forwarded patterns must closely match with the mono-mining results (i.e., the results that would be obtained if all of the databases are put together and mining has been done). When the pattern is present in the site, but fails to satisfy the minimum support threshold value, it is not allowed to take part in the pattern synthesizing process. Therefore, this process can lose some interesting patterns, which can help the decider to make the right decision. In such situations we propose the application of a probabilistic model in the synthesizing process. An adequate choice for a probabilistic model can improve the quality of patterns that have been discovered. In this paper, we perform a comprehensive study on various probabilistic models that can be applied in the synthesizing process and we choose and improve one of them that works to ameliorate the synthesizing results. Finally, some experiments are presented in public database in order to improve the efficiency of our proposed synthesizing method.','10.3745/JIPS.2014.10.1.145',716,258,0,0,NULL,NULL),(306,2014,10,2,163,175,'Non-iterative Bit Loading Algorithm for OFDM in Independent and Correlated fading','Adaptive Modulation, Orthogonal Frequency Division Multiplexing (OFDM), FadingAdaptive Modulation, Orthogonal Frequency Division Multiplexing (OFDM), Fading','John W. Manry and Santosh Nagaraj','dlibrary/JIPS_v10_no2_paper1.pdf','This paper will focus on improving the performance of orthogonal frequency division multiplexing (OFDM) in Rayleigh fading environments. The proposed technique will use a previously published method that has been shown to improve OFDM performance in independent fading, based on ordered sub-carrier selection. Then, a simple non-iterative method for finding the optimal bit-loading allocation was proposed. It was also based on ordered sub-carrier selection. We compared both of these algorithms to an optimal bit-loading solution to determine their effectiveness in a correlated fading environment. The correlated fading was simulated using the JTC channel models. Our intent was not to create an optimal solution, but to create a low complexity solution that can be used in a wireless environment in which the channel conditions change rapidly and that require a simple algorithm for fast bit loading.','10.3745/JIPS.03.0001',656,195,0,0,NULL,NULL),(307,2014,10,2,176,192,'Prioritized Multipath Video Forwarding in WSN','WMSN, H.264, Multiple Paths, Quality of Service','Syed Muhammad Asad Zaidi, Jieun Jung, and Byunghun Song','dlibrary/JIPS_v10_no2_paper2.pdf','The realization of Wireless Multimedia Sensor Networks (WMSNs) has been fostered by the availability of low cost and low power CMOS devices. However, the transmission of bulk video data requires adequate bandwidth, which cannot be promised by single path communication on an intrinsically low resourced sensor network. Moreover, the distortion or artifacts in the video data and the adherence to delay threshold adds to the challenge. In this paper, we propose a two stage Quality of Service (QoS) guaranteeing scheme called Prioritized Multipath WMSN (PMW) for transmitting H.264 encoded video. Multipath selection based on QoS metrics is done in the first stage, while the second stage further prioritizes the paths for sending H.264 encoded video frames on the best available path. PMW uses two composite metrics that are comprised of hop-count, path energy, BER, and end-to-end delay. A colorcoded assisted network maintenance and failure recovery scheme has also been proposed using (a) smart greedy mode, (b) walking back mode, and (c) path switchover. Moreover, feedback controlled adaptive video encoding can smartly tune the encoding parameters based on the perceived video quality. Computer simulation using OPNET validates that the proposed scheme significantly outperforms the conventional approaches on human eye perception and delay.','10.3745/JIPS.03.0002',534,305,0,0,NULL,NULL),(308,2014,10,2,193,214,'Duplication with Task Assignment in Mesh Distributed System','Distributed System(DS), Task Assignment Heuristics, Task Duplication(TD), Directed Acyclic Graph(DAG)','Rashmi Sharma and Nitin','dlibrary/JIPS_v10_no2_paper3.pdf','Load balancing is the major benefit of any distributed system. To facilitate this advantage, task duplication and migration methodologies are employed. As this paper deals with dependent tasks (DAG), we used duplication. Task duplication reduces the overall schedule length of DAG along-with load balancing. This paper proposes a new task duplication algorithm at the time of tasks assignment on various processors. With the intention of conducting proposed algorithm performance computation; simulation has been done on the Netbeans IDE. The mesh topology of a distributed system is simulated at this juncture. For task duplication, overall schedule length of DAG is the main parameter that decides the performance of a proposed duplication algorithm. After obtaining the results we compared our performance with arbitrary task assignment, CAWF and HEFT-TD algorithms. Additionally, we also compared the complexity of the proposed algorithm with the Duplication Based Bottom Up scheduling (DBUS) and Heterogeneous Earliest Finish Time with Task Duplication (HEFT-TD).','10.3745/JIPS.01.0001',507,183,0,0,NULL,NULL),(309,2014,10,2,215,222,'Optical Image Encryption and Decryption Considering Wireless Communication Channels','Optical Encryption and Decryption, Wireless Communication Channels','Myungjin Cho and In-Ho Lee','dlibrary/JIPS_v10_no2_paper4.pdf','In this paper, we discuss optical encryption and decryption considering\r\nwireless communication channels. In wireless communication systems, the wireless channel causes noise and fading effects of the transmitted information. Optical encryption technique such as double-random-phase encryption (DRPE) is used for encrypting transmitted data. When the encrypted data is transmitted, the information may be lost or distorted because there are a lot of factors such as channel noise, propagation fading, etc. Thus, using digital modulation and maximum likelihood (ML) detection, the noise and fading effects are mitigated, and the encrypted data is estimated well at the receiver. To the best of our knowledge, this is the first report that considers the wireless channel characteristics of the optical encryption technique.','10.3745/JIPS.03.0003',494,248,0,0,NULL,NULL),(310,2014,10,2,223,239,'The Design of the IIR Differintegrator and its Application in Edge Detection','Digital integrator, digital differentiator, edge detection and image processing','Madhu Jain, Maneesha Gupta, and N. K. Jain','dlibrary/JIPS_v10_no2_paper5.pdf','New IIR digital differintegrators (differentiator and integrator) with very minor absolute relative errors are presented in this paper. The digital integrator is designed by interpolating some of the existing integrators. The optimum value of the interpolation ratio is obtained through linear programming optimization. Subsequently, by modifying the transfer function of the proposed integrator appropriately, new digital differentiator is obtained. Simulation results demonstrate that the proposed differintegrator are a more accurate approximation of ideal ones, than the existing differintegrators. Furthermore, the proposed differentiator has been tested in an image processing application. Edges characterize boundaries and are, therefore, a problem of fundamental importance in image processing. For comparison purpose Prewitt, Sobel, Roberts, Canny, Laplacian of Gaussian (LOG), Zerocross operators were used and their results are displayed. The results of edge detection by some of the existing differentiators are also provided. The simulation results have shown the superiority of the proposed approach over existing ones.','10.3745/JIPS.02.0001',492,276,0,0,NULL,NULL),(311,2014,10,2,240,255,'Leveraged BMIS Model for Cloud Risk Control','Cloud risk, CSFs, BMIS, Risk control, Leverage point, Effective model','YouJin Song and Yasheng Pang','dlibrary/JIPS_v10_no2_paper6.pdf','Cloud computing has increasingly been drawing attention these days. Each\r\nbig company in IT hurries to get a chunk of meat that promises to be a whopping\r\nmarket in the future. At the same time, information is always associated with security and risk problems. Nowadays, the handling of these risks is no longer just a technology problem, with a good deal of literature focusing on risk or security management and framework in the information system. In this paper, we find the specific business meaning of the BMIS model and try to apply and leverage this model to cloud risk. Through a previous study, we select and determine the causal risk factors in cloud service, which are also known as CSFs (Critical Success Factors) in information management. Subsequently, we distribute all selected CSFs into the BMIS model by mapping with ten principles in cloud risk. Finally, by using the leverage points, we try to leverage the model factors and aim to make a resource-optimized, dynamic, general risk control business model for cloud service providers.','10.3745/JIPS.03.0004',449,179,0,0,NULL,NULL),(312,2014,10,2,256,270,'A High Quality Steganographic Method Using Morphing','Morphed Steganography, Hiding Capacity, Imperceptibility, Stego Image Quality','Anant M.Bagade and Sanjay N.Talbar','dlibrary/JIPS_v10_no2_paper7.pdf','A new morphed steganographic algorithm is proposed in this paper. Image security is a challenging problem these days. Steganography is a method of hiding secret data in cover media. The Least Significant Bit is a standard Steganographic method that has some limitations. The limitations are less capacity to hide data, poor stego image quality, and imperceptibility. The proposed algorithm focuses on these limitations. The morphing concept is being used for image steganography to overcome these limitations. The PSNR and standard deviation are considered as a measure to improve stego image quality and morphed image selection, respectively. The stego keys are generated during the morphed steganographic embedding and extracting process. Stego keys are used to embed and extract the secret image. The experimental results, which are based on hiding capacity and PSNR, are presented in this paper. Our research contributes towards creating an improved steganographic method using image morphing. The experimental result indicates that the proposed algorithm achieves an increase in hiding capacity, stego image quality, and imperceptibility. The experimental results were compared with state of the art steganographic methods.','10.3745/JIPS.03.0005',566,479,0,0,NULL,NULL),(313,2014,10,2,271,282,'Content Modeling Based on Social Network Community Activity','Social network community activities, content model, learning objects, content granularity, content aggregation level','Kyung-Rog Kim and Nammee Moon','dlibrary/JIPS_v10_no2_paper8.pdf','The advancement of knowledge society has enabled the social network community (SNC) to be perceived as another space for learning where individuals produce, share, and apply content in self-directed ways. The content generated within social networks provides information of value for the participants in real time. Thus, this study proposes the social network community activity-based content model (SoACo Model), which takes SNC-based activities and embodies them within learning objects. The SoACo Model consists of content objects, aggregation levels, and information models. Content objects are composed of relationship-building elements, including real-time, changeable activities such as making friends, and participation-activity elements such as “Liking” specific content. Aggregation levels apply one of three granularity levels considering the reusability of elements: activity assets, real-time, changeable learning objects, and content. The SoACo Model is meaningful because it transforms SNC-based activities into learning objects for learning and teaching activities and applies to learning management systems since they organize activities -- such as tweets from Twitter -- depending on the teacher’s intention.','10.3745/JIPS.04.0001',516,185,0,0,NULL,NULL),(314,2014,10,2,283,299,'Skin Segmentation Using YUV and RGB Color Spaces','Skin Segmentation, Thresholding Technique, Skin Detection, Color Space','Zaher Hamid Al-Tairi, Rahmita Wirza Rahmat, M. Iqbal Saripan, and Puteri Suhaiza Sulaiman','dlibrary/JIPS_v10_no2_paper9.pdf','Skin detection is used in many applications, such as face recognition, hand\r\ntracking, and human-computer interaction. There are many skin color detection\r\nalgorithms that are used to extract human skin color regions that are based on the thresholding technique since it is simple and fast for computation. The efficiency of each color space depends on its robustness to the change in lighting and the ability to distinguish skin color pixels in images that have a complex background. For more accurate skin detection, we are proposing a new threshold based on RGB and YUV color spaces. The proposed approach starts by converting the RGB color space to the YUV color model. Then it separates the Y channel, which represents the intensity of the color model from the U and V channels to eliminate the effects of luminance. After that the threshold values are selected based on the testing of the boundary of skin colors with the help of the color histogram. Finally, the threshold was applied to the input image to extract skin parts. The detected skin regions were quantitatively compared to the actual skin parts in the input images to measure the accuracy and to compare the results of our threshold to the results of other\"\'\"s thresholds to prove the efficiency of our approach. The results of the experiment show that the proposed threshold is more robust in terms of dealing with the complex background and light conditions than others.','10.3745/JIPS.02.0002',563,455,0,0,NULL,NULL),(315,2014,10,2,300,313,'Power Consumption Analysis of Prominent Time Synchronization Protocols for Wireless Sensor Networks','Wireless Sensor Networks, Time Synchronization, Energy Efficiency, Power Consumption, Performance, Analysis','Shi-Kyu Bae','dlibrary/JIPS_v10_no2_paper10.pdf','Various Time Synchronization protocols for a Wireless Sensor Network (WSN) have been developed since time synchronization is important in many timecritical WSN applications. Aside from synchronization accuracy, energy constraint should also be considered seriously for time synchronization protocols in WSNs, which typically have limited power environments. This paper performs analysis of prominent WSN time synchronization protocols in terms of power consumption and test by simulation. In the analysis and simulation tests, each protocol shows different performance in terms of power consumption. This result is helpful in choosing or developing an appropriate time synchronization protocol that meets the requirements of synchronization accuracy and power consumption (or network lifetime) for a specific WSN application.','10.3745/JIPS.03.0006',526,341,0,0,NULL,NULL),(316,2014,10,2,314,333,'Default Prediction for Real Estate Companies with Imbalanced Dataset','Default prediction, Imbalanced dataset, Real estate listed companies, Minoritysample generation approach','Yuan-Xiang Dong , Zhi Xiao, and Xue Xiao','dlibrary/JIPS_v10_no2_paper11.pdf','When analyzing default predictions in real estate companies, the number of non-defaulted cases always greatly exceeds the defaulted ones, which creates the twoclass imbalance problem. This lowers the ability of prediction models to distinguish the default sample. In order to avoid this sample selection bias and to improve the prediction model, this paper applies a minority sample generation approach to create new minority samples. The logistic regression, support vector machine (SVM) classification, and neural network (NN) classification use an imbalanced dataset. They were used as benchmarks with a single prediction model that used a balanced dataset corrected by the minority samples generation approach. Instead of using predictionoriented tests and the overall accuracy, the true positive rate (TPR), the true negative rate (TNR), G-mean, and F-score are used to measure the performance of default prediction models for imbalanced dataset. In this paper, we describe an empirical experiment that used a sampling of 14 default and 315 non-default listed real estate companies in China and report that most results using single prediction models with a balanced dataset generated better results than an imbalanced dataset.','10.3745/JIPS.04.0002',482,265,0,0,NULL,NULL),(317,2014,10,3,335,354,'Training-Free Fuzzy Logic Based Human Activity Recognition','Activity Semantic Knowledge, Fuzzy Logic, Human Activity Recognition, Multi-Layer Neural Network','Eunju Kim and Sumi Helal','dlibrary/JIPS_v10_no3_paper1.pdf','The accuracy of training-based activity recognition depends on the training procedure and the extent to which the training dataset comprehensively represents the activity and its varieties. Additionally, training incurs substantial cost and effort in the process of collecting training data. To address these limitations, we have developed a training-free activity recognition approach based on a fuzzy logic algorithm that utilizes a generic activity model and an associated activity semantic knowledge. The approach is validated through experimentation with real activity datasets. Results show that the fuzzy logic based algorithms exhibit comparable or better accuracy than other trainingbased approaches.','10.3745/JIPS.04.0005',1684,347,16,0,NULL,NULL),(318,2014,10,3,355,364,'Improving Database System Performance by Applying NoSQL','Database System Performance, NoSQL, NoSQL Practical Use','Yong-Lak Choi, Woo-Seong Jeon , and Seok-Hwan Yoon','dlibrary/JIPS_v10_no3_paper2.pdf','Internet accessibility has been growing due to the diffusion of smartphones in today’s society. Therefore, people can generate data anywhere and are confronted with the challenge that they should process a large amount of data. Since the appearance of relational database management system (RDBMS), most of the recent information systems are built by utilizing it. RDBMS uses foreign-keys to avoid data duplication. The transactions in the database use attributes, such as atomicity, consistency, isolation, durability (ACID), which ensures that data integrity and processing results are stably managed. The characteristic of RDBMS is that there is high data reliability. However, this results in performance degradation. Meanwhile, from among these information systems, some systems only require high-performance rather than high reliability. In this case, if we only consider performance, the use of NoSQL provides many advantages. It is possible to reduce the maintenance cost of the information system that continues to increase in the use of open source software based NoSQL. And has a huge advantage that is easy to use NoSQL. Therefore, in this study, we prove that the leverage of NoSQL will ensure high performance than RDBMS by applying NoSQL to database systems that implement RDBMS.','10.3745/JIPS.04.0006',541,316,0,0,NULL,NULL),(319,2014,10,3,365,383,'A Novel Framework for Defining and Submitting Workflows to Service-Oriented Systems','Service Composition, Service-Oriented Computing, Service-Oriented Workflow, UML2BPEL, Workflow','Hayat Bendoukha, Yahya Slimani, and Abdelkader Benyettou','dlibrary/JIPS_v10_no3_paper3.pdf','Service-oriented computing offers efficient solutions for executing complex applications in an acceptable amount of time. These solutions provide important computing and storage resources, but they are too difficult for individual users to handle. In fact, Service-oriented architectures are usually sophisticated in terms of design, specifications, and deployment. On the other hand, workflow management systems provide frameworks that help users to manage cooperative and interdependent processes in a convivial manner. In this paper, we propose a workflow-based approach to fully take advantage of new service-oriented architectures that take the users’ skills and the internal complexity of their applications into account. To get to this point, we defined a novel framework named JASMIN, which is responsible for managing service-oriented workflows on distributed systems. JASMIN has two main components: unified modeling language (UML) to specify workflow models and business process execution language (BPEL) to generate and compose Web services. In order to cover both workflow and service concepts, we describe in this paper a refinement of UML activity diagrams and present a set of rules for mapping UML activity diagrams into BPEL specifications.','10.3745/JIPS.02.0003',626,199,0,0,NULL,NULL),(320,2014,10,3,384,394,'Femtocell Subband Selection Method for Managing Cross- and Co-tier Interference in a Femtocell Overlaid Cellular Network','Clustering Method, Femtocell, Frequency Partition, Interference Management','Young Min Kwon, Hyunseung Choo, Tae-Jin Lee, Min Young Chung, and Mihui Kim','dlibrary/JIPS_v10_no3_paper4.pdf','The femtocell overlaid cellular network (FOCN) has been used to enhance the capacity of existing cellular systems. To obtain the desired system performance, both cross-tier interference and co-tier interference in an FOCN need to be managed. This paper proposes an interference management scheme that adaptively constructs a femtocell cluster, which is a group of femtocell base stations that share the same frequency band. The performance evaluation shows that the proposed scheme can enhance the performance of the macrocell-tier and maintain a greater signal to interference-plus-noise ratio than the outage level can for about 99% of femtocell users.','10.3745/JIPS.03.0008',505,265,0,0,NULL,NULL),(321,2014,10,3,395,411,'Imputation of Medical Data Using Subspace Condition Order Degree Polynomials','Imputation, Personal Temporal Data, Polynomial Interpolation','Klaokanlaya Silachan and Panjai Tantatsanawong','dlibrary/JIPS_v10_no3_paper5.pdf','Temporal medical data is often collected during patient treatments that require personal analysis. Each observation recorded in the temporal medical data is associated with measurements and time treatments. A major problem in the analysis of temporal medical data are the missing values that are caused, for example, by patients dropping out of a study before completion. Therefore, the imputation of missing data is an important step during pre-processing and can provide useful information before the data is mined. For each patient and each variable, this imputation replaces the missing data with a value drawn from an estimated distribution of that variable. In this paper, we propose a new method, called Newton’s finite divided difference polynomial interpolation with condition order degree, for dealing with missing values in temporal medical data related to obesity. We compared the new imputation method with three existing subspace estimation techniques, including the k-nearest neighbor, local least squares, and natural cubic spline approaches. The performance of each approach was then evaluated by using the normalized root mean square error and the statistically significant test results. The experimental results have demonstrated that the proposed method provides the best fit with the smallest error and is more accurate than the other methods.','10.3745/JIPS.04.0007',458,338,0,0,NULL,NULL),(322,2014,10,3,412,428,'Ultra Low Power Data Aggregation for Request Oriented Sensor Networks','Data Aggregation, Energy Efficient, Low Power Listening, Medium Access Control, Request Oriented, Sensor Networks','Kwang-il Hwang and In Jang','dlibrary/JIPS_v10_no3_paper6.pdf','Request oriented sensor networks have stricter requirements than conventional event-driven or periodic report models. Therefore, in this paper we propose a minimum energy data aggregation (MEDA), which meets the requirements for request oriented sensor networks by exploiting a low power real-time scheduler, ondemand time synchronization, variable response frame structure, and adaptive retransmission. In addition we introduce a test bed consisting of a number of MEDA prototypes, which support near real-time bidirectional sensor networks. The experimental results also demonstrate that the MEDA guarantees deterministic aggregation time, enables minimum energy operation, and provides a reliable data aggregation service.','10.3745/JIPS.03.0009',490,182,0,0,NULL,NULL),(323,2014,10,3,429,442,'Fault Detection in the Semiconductor Etch Process Using the Seasonal Autoregressive Integrated Moving Average Modeling','Autoregressive Integrated Moving Average, Dynamic Time Warping, Fault Detection, Seasonal Autoregressive Integrated Moving Average, Semiconductor Process, Time Series Modeling','Muhammad Zeeshan Arshad, Javeria Muhammad Nawaz, and Sang Jeen Hong','dlibrary/JIPS_v10_no3_paper7.pdf','In this paper, we investigated the use of seasonal autoregressive integrated moving average (SARIMA) time series models for fault detection in semiconductor etch equipment data. The derivative dynamic time warping algorithm was employed for the synchronization of data. The models were generated using a set of data from healthy runs, and the established models were compared with the experimental runs to find the faulty runs. It has been shown that the SARIMA modeling for this data can detect faults in the etch tool data from the semiconductor industry with an accuracy of 80% and 90% using the parameter-wise error computation and the step-wise error computation, respectively. We found that SARIMA is useful to detect incipient faults in semiconductor fabrication.','10.3745/JIPS.04.0004',451,186,0,0,NULL,NULL),(324,2014,10,3,443,458,'Extreme Learning Machine Ensemble Using Bagging for Facial Expression Recognition','Bagging, Ensemble Learning, Extreme Learning Machine, Facial Expression Recognition, Histogram of Orientation Gradient','Deepak Ghimire and Joonwhoan Lee','dlibrary/JIPS_v10_no3_paper8.pdf','An extreme learning machine (ELM) is a recently proposed learning algorithm for a single-layer feed forward neural network. In this paper we studied the ensemble of ELM by using a bagging algorithm for facial expression recognition (FER). Facial expression analysis is widely used in the behavior interpretation of emotions, for cognitive science, and social interactions. This paper presents a method for FER based on the histogram of orientation gradient (HOG) features using an ELM ensemble. First, the HOG features were extracted from the face image by dividing it into a number of small cells. A bagging algorithm was then used to construct many different bags of training data and each of them was trained by using separate ELMs. To recognize the expression of the input face image, HOG features were fed to each trained ELM and the results were combined by using a majority voting scheme. The ELM ensemble using bagging improves the generalized capability of the network significantly. The two available datasets (JAFFE and CK+) of facial expressions were used to evaluate the performance of the proposed classification system. Even the performance of individual ELM was smaller and the ELM ensemble using a bagging algorithm improved the recognition performance significantly.','10.3745/JIPS.02.0004',542,498,0,0,NULL,NULL),(325,2014,10,3,459,470,'Spectrum Sensing and Data Transmission in a Cognitive Relay Network Considering Spatial False Alarms','Cognitive Network, Conventional False Alarms, Probability of Symbol Error Rate, Spatial False Alarms, Spectrum Sensing','Tasnina A. Tishita, Sumiya Akhter, Md. Imdadul Islam, and M. R. Amin','dlibrary/JIPS_v10_no3_paper9.pdf','In this paper, the average probability of the symbol error rate (SER) and throughput are studied in the presence of joint spectrum sensing and data transmission in a cognitive relay network, which is in the environment of an optimal power allocation strategy. In this investigation, the main component in calculating the secondary throughput is the inclusion of the spatial false alarms, in addition to the conventional false alarms. It has been shown that there exists an optimal secondary power amplification factor at which the probability of SER has a minimum value, whereas the throughput has a maximum value. We performed a Monte-Carlo simulation to validate the analytical results.','10.3745/JIPS.03.0007',644,160,0,0,NULL,NULL),(326,2014,10,3,471,482,'Efficient Greedy Algorithms for Influence Maximization in Social Networks','Greedy Algorithm, Influence Maximization, Social Network','Jiaguo Lv, Jingfeng Guo, and Huixiao Ren','dlibrary/JIPS_v10_no3_paper10.pdf','Influence maximization is an important problem of finding a small subset of nodes in a social network, such that by targeting this set, one will maximize the expected spread of influence in the network. To improve the efficiency of algorithm KK_Greedy proposed by Kempe et al., we propose two improved algorithms, Lv_NewGreedy and Lv_CELF. By combining all of advantages of these two algorithms, we propose a mixed algorithm Lv_MixedGreedy. We conducted experiments on two synthetically datasets and show that our improved algorithms have a matching influence with their benchmark algorithms, while being faster than them.','10.3745/JIPS.04.0003',516,211,0,0,NULL,NULL),(327,2014,10,3,483,490,'Multifactor Authentication Using a QR Code and a One-Time Password','Authentication, One-Time Password, Personal Assurance Message, Quick Response Code','Jyoti Malik, Dhiraj Girdhar, Ratna Dahiya, and G. Sainarayanan','dlibrary/JIPS_v10_no3_paper11.pdf','In today’s world, communication, the sharing of information, and money transactions are all possible to conduct via the Internet, but it is important that it these things are done by the actual person. It is possible via several means that an intruder can access user information. As such, several precautionary measures have to be taken to avoid such instances. The purpose of this paper is to introduce the idea of a one-time password (OTP), which makes unauthorized access difficult for unauthorized users. A OTP can be implemented using smart cards, time-based tokens, and short message service, but hardware based methodologies require maintenance costs and can be misplaced Therefore, the quick response code technique and personal assurance message has been added along with the OTP authentication.','10.3745/JIPS.02.0005',538,259,0,0,NULL,NULL),(328,2014,10,4,491,502,'On the Performance of Oracle Grid Engine Queuing System for Computing Intensive Applications','Benchmarking, Cloud Computing, Computing Intensive Applications, Genetic Algorithms, Grid Computing, Oracle Grid Engine, Scheduling, Simulation','Vladi Kolici, Albert Herrero, and Fatos Xhafa','dlibrary/JIPS_v10_no4_paper1.pdf','In this paper we present some research results on computing intensive applications using modern high performance architectures and from the perspective of high computational needs. Computing intensive applications are an important family of applications in distributed computing domain. They have been object of study using different distributed computing paradigms and infrastructures. Such applications distinguish for their demanding needs for CPU computing, independently of the amount of data associated with the problem instance. Among computing intensive applications, there are applications based on simulations, aiming to maximize system resources for processing large computations for simulation. In this research work, we consider an application that simulates scheduling and resource allocation in a Grid computing system using Genetic Algorithms. In such application, a rather large number of simulations is needed to extract meaningful statistical results about the behavior of the simulation results. We study the performance of Oracle Grid Engine for such application running in a Cluster of high computing capacities. Several scenarios were generated to measure the response time and queuing time under different workloads and number of nodes in the cluster.','10.3745/JIPS.01.0004',1955,327,17,0,NULL,NULL),(329,2014,10,4,503,522,'Graphemes Segmentation for Arabic Online Handwriting Modeling','Baseline Detection, Diacritic Features, Fourier Descriptors, Geometric Parameters, Grapheme Segmentation, Online Arabic Handwriting Modeling','Houcine Boubaker, Najiba Tagougui, Haikal El Abed, Monji Kherallah, and Adel M. Alimi','dlibrary/JIPS_v10_no4_paper2.pdf','In the cursive handwriting recognition process, script trajectory segmentation and modeling represent an important task for large or open lexicon context that becomes more complicated in multi-writer applications. In this paper, we will present a developed system of Arabic online handwriting modeling based on graphemes segmentation and the extraction of its geometric features. The main contribution consists of adapting the Fourier descriptors to model the open trajectory of the segmented graphemes. To segment the trajectory of the handwriting, the system proceeds by first detecting its baseline by checking combined geometric and logic conditions. Then, the detected baseline is used as a topologic reference for the extraction of particular points that delimit the graphemes’ trajectories. Each segmented grapheme is then represented by a set of relevant geometric features that include the vector of the Fourier descriptors for trajectory shape modeling, normalized metric parameters that model the grapheme dimensions, its position in respect to the baseline, and codes for the description of its associated diacritics.','10.3745/JIPS.02.0006',731,174,0,0,NULL,NULL),(330,2014,10,4,523,542,'The Accuracy of the Non-continuous I Test for One- Dimensional Arrays with References Created by Induction Variables','Data Dependence Analysis, Loop Parallelization, Loop Vectorization, Parallelizing/Vectorizing Compilers','Qing Zhang','dlibrary/JIPS_v10_no4_paper3.pdf','One-dimensional arrays with subscripts formed by induction variables in real programs appear quite frequently. For most famous data dependence testing methods, checking if integer-valued solutions exist for one-dimensional arrays with references created by induction variable is very difficult. The I test, which is a refined combination of the GCD and Banerjee tests, is an efficient and precise data dependence testing technique to compute if integer-valued solutions exist for one-dimensional arrays with constant bounds and single increments. In this paper, the non-continuous I test, which is an extension of the I test, is proposed to figure out whether there are integer-valued solutions for one-dimensional arrays with constant bounds and non-sing ularincrements or not. Experiments with the benchmarks that have been cited from Livermore and Vector Loop, reveal that there are definitive results for 67 pairs of one- dimensional arrays that were tested.','10.3745/JIPS.01.0005',524,133,0,0,NULL,NULL),(331,2014,10,4,543,554,'Design and Implementation of a Content Model for m-Learning','Content Model, M-Learning, Requirement Analysis of M-Learning Environment, Segment Content, Supplement Content','Jin Gon Shon and Byoung Wook Kim','dlibrary/JIPS_v10_no4_paper4.pdf','It is difficult for mobile learners to maintain a high level of concentration when learning content for more than an hour while they are on the move. Despite the attention span issue, many m-learning systems still provide their mobile learners with the same content once used in e-learning systems. This has called for an investigation to identify the suitable characteristics of the m-learning environment. With this in mind, we have conducted a survey in hopes of determining the requirements for developing more suitable m-learning content. Based on the results of the survey, we have developed a content model comprised of two types: a segment type and a supplement type. In addition, we have implemented a prototype system of the content model for Apple iPhones and Android smartphones in order to investigate a feasibility study of the model application.','10.3745/JIPS.04.0010',585,161,0,0,NULL,NULL),(332,2014,10,4,555,567,'Multimodal Biometric Using a Hierarchical Fusion of a Person’s Face, Voice, and Online Signature','Hierarchical Fusion, LDA, Multimodal Biometric Fusion, PCA','Youssef Elmir, Zakaria Elberrichi, and Réda Adjoudj','dlibrary/JIPS_v10_no4_paper5.pdf','Biometric performance improvement is a challenging task. In this paper, a hierarchical strategy fusion based on multimodal biometric system is presented. This strategy relies on a combination of several biometric traits using a multi-level biometric fusion hierarchy. The multi-level biometric fusion includes a pre-classification fusion with optimal feature selection and a post-classification fusion that is based on the similarity of the maximum of matching scores. The proposed solution enhances biometric recognition performances based on suitable feature selection and reduction, such as principal component analysis (PCA) and linear discriminant analysis (LDA), as much as not all of the feature vectors components support the performance improvement degree.','10.3745/JIPS.02.0007',559,172,0,0,NULL,NULL),(333,2014,10,4,568,580,'Performance Evaluation of the WiMAX Network under a Complete Partitioned User Group with a Traffic Shaping Algorithm','Blocking Probability, CAC, Complete Partition Scheme, Subscriber Station, Throughput','Jesmin Akhter, Md. Imdadul Islam, and M. R. Amin','dlibrary/JIPS_v10_no4_paper6.pdf','To enhance the utilization of the traffic channels of a network (instead of allocating radio channel to an individual user), a channel or a group of channels are allocated to a user group. The idea behind this is the statistical distribution of traffic arrival rates and the service time for an individual user or a group of users. In this paper, we derive the blocking probability and throughput of a subscriber station of Worldwide Interoperability for Microwave Access (WiMAX) by considering both the connection level and packet-level traffic under a complete partition scheme. The main contribution of the paper is to incorporate the traffic shaping scheme onto the incoming turbulent traffic. Hence, we have also analyzed the impact of the drain rate of the buffer on the blocking probability and throughput.','10.3745/JIPS.03.0016',577,174,0,0,NULL,NULL),(334,2014,10,4,581,588,'An Unified Representation of Context Knowledge Base for Mobile Context-Aware System','Context-Awareness, Knowledge Base, Unified Context Information','Jang-Seop Jeong and Dae-Wook Bang','dlibrary/JIPS_v10_no4_paper7.pdf','To facilitate the implementation of a wide variety of context-aware applications based on mobile devices, general-purpose context-aware framework that applications can use by calling is needed. The context-aware framework is a middleware that performs the sensing, reasoning, and retrieving based on the knowledge base. The knowledge base must systematically represent the information required on the behavior of the context-aware framework, such as context information and reasoning information. It must also provide functions for storage and retrieval. To date, previous research on the representation of the context information have been carried out, but studies on the unified representation of the knowledge base has seen little progress. This study defines the knowledge base as the unified context information, and proposes the UniOWL, which can do a good job of representing it. UniOWL is based on OWL and represents the information that is necessary for the operation of the context-aware framework. Therefore, UniOWL greatly facilitates the implementation of the knowledge base on a context-aware framework.','10.3745/JIPS.01.0002',511,169,0,0,NULL,NULL),(335,2014,10,4,589,601,'An Efficient Color Edge Detection Using the Mahalanobis Distance','Color Image, Edge Detection, Mahalanobis Distance','Kittiya Khongkraphan','dlibrary/JIPS_v10_no4_paper8.pdf','The performance of edge detection often relies on its ability to correctly determine the dissimilarities of connected pixels. For grayscale images, the dissimilarity of two pixels is estimated by a scalar difference of their intensities and for color images, this is done by using the vector difference (color distance) of the three-color components. The Euclidean distance in the RGB color space typically measures a color distance. However, the RGB space is not suitable for edge detection since its color components do not coincide with the information human perception uses to separate objects from backgrounds. In this paper, we propose a novel method for color edge detection by taking advantage of the HSV color space and the Mahalanobis distance. The HSV space models colors in a manner similar to human perception. The Mahalanobis distance independently considers the hue, saturation, and lightness and gives them different degrees of contribution for the measurement of color distances. Therefore, our method is robust against the change of lightness as compared to previous approaches. Furthermore, we will introduce a noise-resistant technique for determining image gradients. Various experiments on simulated and real-world images show that our approach outperforms several existing methods, especially when the images vary in lightness or are corrupted by noise.','10.3745/JIPS.02.0010',618,207,0,0,NULL,NULL),(336,2014,10,4,602,617,'Traffic Analysis of a Cognitive Radio Network Based on the Concept of Medium Access Probability','Blocking Probability, Fading Channel, Path Loss Model, State Transition Chain, Throughput','Risala T. Khan, Md. Imdadul Islam, and M. R. Amin','dlibrary/JIPS_v10_no4_paper9.pdf','The performance of a cognitive radio network (CRN) solely depends on how precisely the secondary users can sense the presence or absence of primary users. The incorporation of a spatial false alarm makes deriving the probability of a correct decision a cumbersome task. Previous literature performed this task for the case of a received signal under a Normal probability density function case. In this paper we enhance the previous work, including the impact of carrier frequency, the gain of antennas on both sides, and antenna heights so as to observe the robustness against noise and interference and to make the correct decision of detection. Three small scale fading channels: Rayleigh, Normal, and Weibull were considered to get the real scenario of a CRN in an urban area. The incorporation of a maximal-ratio combining and selection combing with a variation of the number of received antennas have also been studied in order to achieve the correct decision of spectral sensing, so as to serve the cognitive users. Finally, we applied the above concept to a traffic model of the CRN, which we based on a two-dimensional state transition chain.','10.3745/JIPS.03.0019',536,172,0,0,NULL,NULL),(337,2014,10,4,618,627,'A Step towards User Privacy while Using Location-Based Services','Location Based Services, Location Privacy, Point of Interests','Fizza Abbas and Heekuck Oh','dlibrary/JIPS_v10_no4_paper10.pdf','Nowadays mobile users are using a popular service called Location-Based Services (LBS). LBS is very helpful for a mobile user in finding various Point of Interests (POIs) in their vicinity. To get these services, users must provide their personal information, such as user identity or current location, which severely risks the location privacy of the user. Many researchers are developing schemes that enable a user to use these LBS services anonymously, but these approaches have some limitations (i.e., either the privacy prevention mechanism is weak or the cost of the solution is too much). As such, we are presenting a robust scheme for mobile users that allows them to use LBS anonymously. Our scheme involves a client side application that interacts with an untrusted LBS server to find the nearest POI for a service required by a user. The scheme is not only efficient in its approach, but is also very practical with respect to the computations that are done on a client’s resource constrained device. With our scheme, not only can a client anonymously use LBS without any use of a trusted third party, but also a server’s database is completely secure from the client. We performed experiments by developing and testing an Android-based client side smartphone application to support our argument.','10.3745/JIPS.01.0003',556,181,0,0,NULL,NULL),(338,2014,10,4,628,645,'Cost-Effective Replication Schemes for Query Load Balancing in DHT-Based Peer-to-Peer File Searches','DHT, Load Balancing, Load Reduction, Multi-Keyword Search, Replication','Qi Cao and Satoshi Fujita','dlibrary/JIPS_v10_no4_paper11.pdf','In past few years, distributed hash table (DHT)-based P2P systems have been proven to be a promising way to manage decentralized index information and provide efficient lookup services. However, the skewness o','10.3745/JIPS.03.0020',557,158,0,0,NULL,NULL),(339,2015,11,1,1,21,'Personalizing Information Using Users’ Online Social Networks: A Case Study of CiteULike','CiteULike, Homophily, Information Personalization, Online Social Networks, Social Network-based Recommendations','Danielle Lee','dlibrary/JIPS_v11_no1_paper1.pdf','This paper aims to assess the feasibility of a new and less-focused type of online sociability (the watching network) as a useful information source for personalized recommendations. In this paper, we recommend scientific articles of interests by using the shared interests between target users and their watching connections. Our recommendations are based on one typical social bookmarking system, CiteULike. The watching network-based recommendations, which use a much smaller size of user data, produces suggestions that are as good as the conventional Collaborative Filtering technique. The results demonstrate that the watching network is a useful information source and a feasible foundation for information personalization. Furthermore, the watching network is substitutable for anonymous peers of the Collaborative Filtering recommendations. This study shows the expandability of social network-based recommendations to the new type of online social networks.','10.3745/JIPS.04.0014',942,235,0,0,NULL,'L2hvbWUvdmlydHVhbC9qaXBzL2pvdXJuYWwvdXBsb2FkL3BkZi8uLi9lcHViL2ppcHMtMTEtMS0xLmVwdWI=&filename=amlwcy0xMS0xLTEuZXB1Yg=='),(340,2015,11,1,22,38,'GMM-Based Maghreb Dialect IdentificationSystem','Core-Set, Gaussian Mixture Models (GMM), Kernel Methods, Minimal Enclosing Ball (MEB), Quadratic Programming (QP), Support Vector Machines (SVMs), Universal Background Model (UBM)','Lachachi Nour-Eddine and Adla Abdelkader','dlibrary/JIPS_v11_no1_paper2.pdf','While Modern Standard Arabic is the formal spoken and written language of the Arab world; dialects are the major communication mode for everyday life. Therefore, identifying a speaker’s dialect is critical in the Arabic-speaking world for speech processing tasks, such as automatic speech recognition or identification. In this paper, we examine two approaches that reduce the Universal Background Model (UBM) in the automatic dialect identification system across the five following Arabic Maghreb dialects: Moroccan, Tunisian, and 3 dialects of the western (Oranian), central (Algiersian), and eastern (Constantinian) regions of Algeria. We applied our approaches to the Maghreb dialect detection domain that contains a collection of 10-second utterances and we compared the performance precision gained against the dialect samples from a baseline GMM-UBM system and the ones from our own improved GMM-UBM system that uses a Reduced UBM algorithm. Our experiments show that our approaches significantly improve identification performance over purely acoustic features with an identification rate of 80.49%.','10.3745/JIPS.02.0015',762,182,0,0,NULL,'L2hvbWUvdmlydHVhbC9qaXBzL2pvdXJuYWwvdXBsb2FkL3BkZi8uLi9lcHViL2ppcHMtMTEtMS0yMi5lcHVi&filename=amlwcy0xMS0xLTIyLmVwdWI='),(341,2015,11,1,39,56,'A Real-Time Integrated Hierarchical Temporal Memory Network for the Real-Time Continuous Multi-Interval Prediction of Data Streams','Data Streams, Hierarchical Temporal Memory, Multiple Interval Prediction, Real-Time Prediction','Hyun-Syug Kang','dlibrary/JIPS_v11_no1_paper3.pdf','Continuous multi-interval prediction (CMIP) is used to continuously predict the trend of a data stream based on various intervals simultaneously. The continuous integrated hierarchical temporal memory (CIHTM) network performs well in CMIP. However, it is not suitable for CMIP in real-time mode, especially when the number of prediction intervals is increased. In this paper, we propose a real-time integrated hierarchical temporal memory (RIHTM) network by introducing a new type of node, which is called a Zeta1FirstSpecializedQueueNode (ZFSQNode), for the real-time continuous multi-interval prediction (RCMIP) of data streams. The ZFSQNode is constructed by using a specialized circular queue (sQUEUE) together with the modules of original hierarchical temporal memory (HTM) nodes. By using a simple structure and the easy operation characteristics of the sQUEUE, entire prediction operations are integrated in the ZFSQNode. In particular, we employed only one ZFSQNode in each level of the RIHTM network during the prediction stage to generate different intervals of prediction results. The RIHTM network efficiently reduces the response time. Our performance evaluation showed that the RIHTM was satisfied to continuously predict the trend of data streams with multi-intervals in the real-time mode.','10.3745/JIPS.02.0011',644,164,0,0,NULL,'L2hvbWUvdmlydHVhbC9qaXBzL2pvdXJuYWwvdXBsb2FkL3BkZi8uLi9lcHViL2ppcHMtMTEtMS0zOS5lcHVi&filename=amlwcy0xMS0xLTM5LmVwdWI='),(342,2015,11,1,57,75,'Selection of the Best Two-Hop AF Wireless Link under Multiple Antenna Schemes over a Fading Channel','Ergodic Capacity, OFDM, OSTBC, Space Diversity, TAS, Wideband Slope','Abu Sayed Md. Mostafizur Rahaman, Md. Imdadul Islam, and M.R. Amin','dlibrary/JIPS_v11_no1_paper4.pdf','In evaluating the performance of a dual-hop wireless link, the effects of large and small scale fading has to be considered. To overcome this fading effect, several schemes, such as multiple-input multiple-output (MIMO) with orthogonal space time block codes (OSTBC), different combining schemes at the relay and receiving end, and orthogonal frequency division multiplexing (OFDM) are used in both the transmitting and the relay links. In this paper, we first make compare the performance of a two-hop wireless link under a different combination of space diversity in the first and second hop of the amplify-and-forward (AF) case. Our second task in this paper is to incorporate the weak signal of a direct link and then by applying the channel model of two random variables (one for a direct link and another for a relayed link) we get very impressive result at a low signal-to-noise ratio (SNR) that is comparable with other models at a higher SNR. Our third task is to bring other three schemes under a two-hop wireless link: use of transmit antenna selection (TAS) on both link with weak direct link, distributed Alamouti scheme in two-hop link and single relay antenna with OFDM sub- carrier. Finally, all of the schemes mentioned above are compared to select the best possible model. The main finding of the paper is as follows: the use of MIMO on both hops but application TAS on both links with weak direct link and the full rate OFDM with the sub-carrier for an individual link provide a better result as compared to other models.','10.3745/JIPS.03.0023',617,136,0,0,NULL,'L2hvbWUvdmlydHVhbC9qaXBzL2pvdXJuYWwvdXBsb2FkL3BkZi8uLi9lcHViL2ppcHMtMTEtMS01Ny5lcHVi&filename=amlwcy0xMS0xLTU3LmVwdWI='),(343,2015,11,1,76,94,'Viewer’s Affective Feedback for Video Summarization','Affective Computing, Emotion, FABO, K-NN, Motion Recognition, PCA, Video Summarization','Majdi Dammak, Ali Wali, and Adel M. Alimi','dlibrary/JIPS_v11_no1_paper5.pdf','For different reasons, many viewers like to watch a summary of films without having to waste their time. Traditionally, video film was analyzed manually to provide a summary of it, but this costs an important amount of work time. Therefore, it has become urgent to propose a tool for the automatic video summarization job. The automatic video summarization aims at extracting all of the important moments in which viewers might be interested. All summarization criteria can differ from one video to another. This paper presents how the emotional dimensions issued from real viewers can be used as an important input for computing which part is the most interesting in the total time of a film. Our results, which are based on lab experiments that were carried out, are significant and promising.','10.3745/JIPS.01.0006',666,148,0,0,NULL,'L2hvbWUvdmlydHVhbC9qaXBzL2pvdXJuYWwvdXBsb2FkL3BkZi8uLi9lcHViL2ppcHMtMTEtMS03Ni5lcHVi&filename=amlwcy0xMS0xLTc2LmVwdWI='),(344,2015,11,1,95,103,'A Memory Efficient Anti-Collision Protocol to Identify Memoryless RFID Tags','RFID tag identification, anti-collision protocol, data structure, query tree','Haejae Jung','dlibrary/JIPS_v11_no1_paper6.pdf','This paper presents a memory efficient tree based anti-collision protocol to identify memoryless RFID (Radio Frequency Identification) tags that may be attached to products. The proposed deterministic scheme utilizes two bit arrays instead of stack or queue and requires only ?(n) space, which is better than the earlier schemes that use at least O(n2) space, where n is the length of a tag ID in a bit. Also, the size n of each bit array is independent of the number of tags to identify. Our simulation results show that our bit array scheme consumes much less memory space than the earlier schemes utilizing queue or stack.','10.3745/JIPS.03.0010',623,148,0,0,NULL,'L2hvbWUvdmlydHVhbC9qaXBzL2pvdXJuYWwvdXBsb2FkL3BkZi8uLi9lcHViL2ppcHMtMTEtMS05NS5lcHVi&filename=amlwcy0xMS0xLTk1LmVwdWI='),(345,2015,11,1,104,115,'Penetration Testing and Network Auditing: Linux','Network attack, network auditing, network forensic','Deris Stiawan, Mohd. Yazid Idris, and Abdul Hanan Abdullah','dlibrary/JIPS_v11_no1_paper7.pdf','Along with the evolution of Internet and its new emerging services, the quantity and impact of attacks have been continuously increasing. Currently, the technical capability to attack has tended to decrease. On the contrary, performances of hacking tools are evolving, growing, simple, comprehensive, and accessible to the public. In this work, network penetration testing and auditing of the Redhat operating system (OS) are highlighted as one of the most popular OS for Internet applications. Some types of attacks are from a different side and new attack method have been attempted, such as: scanning for reconnaissance, guessing the password, gaining privileged access, and flooding the victim machine to decrease availability. Some analyses in network auditing and forensic from victim server are also presented in this paper. Our proposed system aims confirmed as hackable or not and we expect for it to be used as a reference for practitioners to protect their systems from cyber-attacks.','10.3745/JIPS.03.0013',615,157,0,0,NULL,'L2hvbWUvdmlydHVhbC9qaXBzL2pvdXJuYWwvdXBsb2FkL3BkZi8uLi9lcHViL2ppcHMtMTEtMS0xMDQuZXB1Yg==&filename=amlwcy0xMS0xLTEwNC5lcHVi'),(346,2015,11,1,116,124,'Energy Consumption Scheduling in\ra Smart Grid Including Renewable Energya Smart Grid Including Renewable Energy','Demand Response, Energy Management, Energy Scheduling, Optimization','Nadia Boumkheld, Mounir Ghogho, and Mohammed El Koutbi','dlibrary/JIPS_v11_no1_paper8.pdf','Smart grids propose new solutions for electricity consumers as a means to help them use energy in an efficient way. In this paper, we consider the demand-side management issue that exists for a group of consumers (houses) that are equipped with renewable energy (wind turbines) and storage units (battery), and we try to find the optimal scheduling for their home appliances, in order to reduce their electricity bills. Our simulation results prove the effectiveness of our approach, as they show a significant reduction in electricity costs when using renewable energy and battery storage.','10.3745/JIPS.03.0022',649,155,0,0,NULL,'L2hvbWUvdmlydHVhbC9qaXBzL2pvdXJuYWwvdXBsb2FkL3BkZi8uLi9lcHViL2ppcHMtMTEtMS0xMTYuZXB1Yg==&filename=amlwcy0xMS0xLTExNi5lcHVi'),(347,2015,11,1,125,133,'Fast Device Discovery for Remote Device Management in Lighting Control Networks','Device Discovery, Partition-Based, RDM','Sang-Il Choi, Sanghun Lee, Seok-Joo Koh, Sang-Kyu Lim, Insu Kim, and Tae-Gyu Kang','dlibrary/JIPS_v11_no1_paper9.pdf','The Remote Device Management (RDM) protocol is used to manage the devices in the lighting control networks. RDM provides bi-directional communications between a controller and many lighting devices over the DMX512-A network. In RDM, using a simple binary search scheme, which is based on the 48-bit unique ID (UID) of each device, discovers the lighting devices. However, the existing binary search scheme tends to require a large delay in the device discovery process. In this paper, we propose a novel partition-based discovery scheme for fast device discovery in RDM. In the proposed scheme, all devices are divided into several partitions as per the device UID, and the controller performs device discovery for each partition by configuring a response timer that each device will use. From numerical simulations, we can see that there is an optimal number of partitions to minimize the device discovery time for a given number of devices in the proposed scheme, and also that the proposed partition-based scheme can reduce the device discovery time, as compared to the existing binary search scheme.','10.3745/JIPS.03.0011',614,148,0,0,NULL,'L2hvbWUvdmlydHVhbC9qaXBzL2pvdXJuYWwvdXBsb2FkL3BkZi8uLi9lcHViL2ppcHMtMTEtMS0xMjUuZXB1Yg==&filename=amlwcy0xMS0xLTEyNS5lcHVi'),(348,2015,11,1,134,147,'Spatial Interpolation of Meteorologic Variables in Vietnam using the Kriging Method','Interpolation, Meteorologic Variables, Kriging','Xuan Thanh Nguyen, Ba Tung Nguyen, Khac Phong Do, Quang Hung Bui, Thi Nhat Thanh Nguyen, Van Quynh Vuong, and Thanh Ha Le','dlibrary/JIPS_v11_no1_paper10.pdf','This paper presents the applications of Kriging spatial interpolation methods for meteorologic variables, including temperature and relative humidity, in regions of Vietnam. Three types of interpolation methods are used, which are as follows: Ordinary Kriging, Universal Kriging, and Universal Kriging plus Digital Elevation model correction. The input meteorologic data was collected from 98 ground weather stations throughout Vietnam and the outputs were interpolated temperature and relative humidity gridded fields, along with their error maps. The experimental results showed that Universal Kriging plus the digital elevation model correction method outperformed the two other methods when applied to temperature. The interpolation effectiveness of Ordinary Kriging and Universal Kriging were almost the same when applied to both temperature and relative humidity.','10.3745/JIPS.02.0016',647,193,0,0,NULL,'L2hvbWUvdmlydHVhbC9qaXBzL2pvdXJuYWwvdXBsb2FkL3BkZi8uLi9lcHViL2ppcHMtMTEtMS0xMzQuZXB1Yg==&filename=amlwcy0xMS0xLTEzNC5lcHVi'),(349,2015,11,1,148,164,'An Energy Efficient Distributed Approach-Based Agent Migration Scheme for Data Aggregation in Wireless Sensor Networks','Agent Migration Protocol, Data Aggregation, Mobile Agent, WSN','Govind P. Gupta, Manoj Misra, and Kumkum Garg','dlibrary/JIPS_v11_no1_paper11.pdf','The use of mobile agents for collaborative processing in wireless sensor network has gained considerable attention. This is when mobile agents are used for data aggregation to exploit redundant and correlated data. The efficiency of agent-based data aggregation depends on the agent migration scheme. However, in general, most of the proposed schemes are centralized approach-based schemes where the sink node determines the migration paths for the agents before dispatching them in the sensor network. The main limitations with such schemes are that they need global network topology information for deriving the migration paths of the agents, which incurs additional communication overhead, since each node has a very limited communication range. In addition, a centralized approach does not provide fault tolerant and adaptive migration paths. In order to solve such problems, we have proposed a distributed approach-based scheme for determining the migration path of the agents where at each hop, the local information is used to decide the migration of the agents. In addition, we also propose a local repair mechanism for dealing with the faulty nodes. The simulation results show that the proposed scheme performs better than existing schemes in the presence of faulty nodes within the networks, and manages to report the aggregated data to the sink faster.','10.3745/JIPS.03.0018',705,155,0,0,NULL,'L2hvbWUvdmlydHVhbC9qaXBzL2pvdXJuYWwvdXBsb2FkL3BkZi8uLi9lcHViL2ppcHMtMTEtMS0xNDguZXB1Yg==&filename=amlwcy0xMS0xLTE0OC5lcHVi'),(350,2015,11,2,165,172,'Learning to Prevent Inactive Student of Indonesia Open University','Educational Data Mining, Ensemble Techniques, Inactive Student, Open University','Bayu Adhi Tama','dlibrary/JIPS_v11_no2_paper1.pdf','The inactive student rate is becoming a major problem in most open universities worldwide. In Indonesia, roughly 36% of students were found to be inactive, in 2005. Data mining had been successfully employed to solve problems in many domains, such as for educational purposes. We are proposing a method for preventing inactive students by mining knowledge from student record systems with several state of the art ensemble methods, such as Bagging, AdaBoost, Random Subspace, Random Forest, and Rotation Forest. The most influential attributes, as well as demographic attributes (marital status and employment), were successfully obtained which were affecting student of being inactive. The complexity and accuracy of classification techniques were also compared and the experimental results show that Rotation Forest, with decision tree as the base-classifier, denotes the best performance compared to other classifiers.','10.3745/JIPS.04.0015',777,217,0,0,NULL,'L2hvbWUvdmlydHVhbC9qaXBzL2pvdXJuYWwvdXBsb2FkL3BkZi8uLi9lcHViL2ppcHMtMTEtMi0xNjUuZXB1Yg==&filename=amlwcy0xMS0yLTE2NS5lcHVi'),(351,2015,11,2,173,183,'Research on the E-Commerce Credit Scoring Model Using the Gaussian Density Function','Abnormal Point, Credit Scoring, Density, E-commerce','Xiao Qiang, He Rui-chun, and Zhang Wei','dlibrary/JIPS_v11_no2_paper2.pdf','At present, it is simple to the electronic commerce credit scoring model, as a brush credit phenomenon in E- commerce has emerged. This phenomenon affects the judgment of consumers and hinders the rapid development of E-commerce. In this paper, that E-commerce credit evaluation model that uses a Gaussian density function is put forward by density test and the analysis for the anomalies of E-commerce credit rating, it can be fond out the abnormal point in credit scoring, these points were calculated by nonlinear credit scoring algorithm, thus it can effectively improve the current E-commerce credit score, and enhance the accuracy of E-commerce credit score.','10.3745/JIPS.04.0012',555,143,0,0,NULL,'L2hvbWUvdmlydHVhbC9qaXBzL2pvdXJuYWwvdXBsb2FkL3BkZi8uLi9lcHViL2ppcHMtMTEtMi0xNzMuZXB1Yg==&filename=amlwcy0xMS0yLTE3My5lcHVi'),(352,2015,11,2,184,204,'A Note on Computing the Crisp Order Context of a Fuzzy Formal Context for Knowledge Reduction','Crisp Context, Concept Lattice, Formal Concept Analysis, Fuzzy Formal Concept, Fuzzy Relation, Knowledge Reduction','Prem Kumar Singh and Ch. Aswani Kumar','dlibrary/JIPS_v11_no2_paper3.pdf','Fuzzy Formal Concept Analysis (FCA) is a mathematical tool for the effective representation of imprecise and vague knowledge. However, with a large number of formal concepts from a fuzzy context, the task of knowledge representation becomes complex. Hence, knowledge reduction is an important issue in FCA with a fuzzy setting. The purpose of this current study is to address this issue by proposing a method that computes the corresponding crisp order for the fuzzy relation in a given fuzzy formal context. The obtained formal context using the proposed method provides a fewer number of concepts when compared to original fuzzy context. The resultant lattice structure is a reduced form of its corresponding fuzzy concept lattice and preserves the specialized and generalized concepts, as well as stability. This study also shows a step-by-step demonstration of the proposed method and its application.','10.3745/JIPS.04.0009',455,104,0,0,NULL,'L2hvbWUvdmlydHVhbC9qaXBzL2pvdXJuYWwvdXBsb2FkL3BkZi8uLi9lcHViL2ppcHMtMTEtMi0xODQuZXB1Yg==&filename=amlwcy0xMS0yLTE4NC5lcHVi'),(353,2015,11,2,205,228,'A Virtual Laboratory to Practice Mobile Wireless Sensor Networks: A Case Study on Energy Efficient and Safe Weighted Clustering Algorithm','Clustering, Energy Efficiency, Practical Work, Security Attacks, Virtual labs, Wireless Sensor Networks','Amine Dahane, Nasr-Eddine Berrached, and Abdelhamid Loukil','dlibrary/JIPS_v11_no2_paper4.pdf','In this paper, we present a virtual laboratory platform (VLP) baptized Mercury allowing students to make practical work (PW) on different aspects of mobile wireless sensor networks (WSNs). Our choice of WSNs is motivated mainly by the use of real experiments needed in most courses about WSNs. These experiments require an expensive investment and a lot of nodes in the classroom. To illustrate our study, we propose a course related to energy efficient and safe weighted clustering algorithm. This algorithm which is coupled with suitable routing protocols, aims to maintain stable clustering structure, to prevent most routing attacks on sensor networks, to guaranty energy saving in order to extend the lifespan of the network. It also offers a better performance in terms of the number of re-affiliations. The platform presented here aims at showing the feasibility, the flexibility and the reduced cost of such a realization. We demonstrate the performance of the proposed algorithms that contribute to the familiarization of the learners in the field of WSNs.','10.3745/JIPS.02.0019',603,149,0,0,NULL,'L2hvbWUvdmlydHVhbC9qaXBzL2pvdXJuYWwvdXBsb2FkL3BkZi8uLi9lcHViL2ppcHMtMTEtMi0yMDUuZXB1Yg==&filename=amlwcy0xMS0yLTIwNS5lcHVi'),(354,2015,11,2,229,238,'WebSHArk 1.0: A Benchmark Collection for Malicious Web Shell Detection','Benchmark Test Collection, Malicious Web Application, Webshell, Web Shell Collection, Web Shell Detection','Jinsuk Kim, Dong-Hoon Yoo, Heejin Jang, and Kimoon Jeong','dlibrary/JIPS_v11_no2_paper5.pdf','Web shells are programs that are written for a specific purpose in Web scripting languages, such as PHP, ASP, ASP.NET, JSP, PERL-CGI, etc. Web shells provide a means to communicate with the server’s operating system via the interpreter of the web scripting languages. Hence, web shells can execute OS specific commands over HTTP. Usually, web attacks by malicious users are made by uploading one of these web shells to compromise the target web servers. Though there have been several approaches to detect such malicious web shells, no standard dataset has been built to compare various web shell detection techniques. In this paper, we present a collection of web shell files, WebSHArk 1.0, as a standard dataset for current and future studies in malicious web shell detection. To provide baseline results for future studies and for the improvement of current tools, we also present some benchmark results by scanning the WebSHArk dataset directory with three web shell scanning tools that are publicly available on the Internet. The WebSHArk 1.0 dataset is only available upon request via email to one of the authors, due to security and legal issues.','10.3745/JIPS.03.0026',444,263,0,0,NULL,'L2hvbWUvdmlydHVhbC9qaXBzL2pvdXJuYWwvdXBsb2FkL3BkZi8uLi9lcHViL2ppcHMtMTEtMi0yMjkuZXB1Yg==&filename=amlwcy0xMS0yLTIyOS5lcHVi'),(355,2015,11,2,239,247,'Genetic Symmetric Key Generation for IDEA','Crossover, IDEA, Genetic Algorithm, Mutation, Symmetric Key Generation','Nandini Malhotra and Geeta Nagpal','dlibrary/JIPS_v11_no2_paper6.pdf','Cryptography aims at transmitting secure data over an unsecure network in coded version so that only the intended recipient can analyze it. Communication through messages, emails, or various other modes requires high security so as to maintain the confidentiality of the content. This paper deals with IDEA’s shortcoming of generating weak keys. If these keys are used for encryption and decryption may result in the easy prediction of ciphertext corresponding to the plaintext. For applying genetic approach, which is well-known optimization technique, to the weak keys, we obtained a definite solution to convert the weaker keys to stronger ones. The chances of generating a weak key in IDEA are very rare, but if it is produced, it could lead to a huge risk of attacks being made on the key, as well as on the information. Hence, measures have been taken to safeguard the key and to ensure the privacy of information.','10.3745/JIPS.03.0017',442,138,0,0,NULL,'L2hvbWUvdmlydHVhbC9qaXBzL2pvdXJuYWwvdXBsb2FkL3BkZi8uLi9lcHViL2ppcHMtMTEtMi0yMzkuZXB1Yg==&filename=amlwcy0xMS0yLTIzOS5lcHVi'),(356,2015,11,2,248,265,'A Maximum Entropy-Based Bio-Molecular Event Extraction Model that Considers Event Generation','Bioinformatics, Event Extraction, Maximum Entropy, Text-Mining','Hyoung-Gyu Lee, So-Young Park, Hae-Chang Rim, Do-Gil Lee, and Hong-Woo Chun','dlibrary/JIPS_v11_no2_paper7.pdf','In this paper, we propose a maximum entropy-based model, which can mathematically explain the bio- molecular event extraction problem. The proposed model generates an event table, which can represent the relationship between an event trigger and its arguments. The complex sentences with distinctive event structures can be also represented by the event table. Previous approaches intuitively designed a pipeline system, which sequentially performs trigger detection and arguments recognition, and thus, did not clearly explain the relationship between identified triggers and arguments. On the other hand, the proposed model generates an event table that can represent triggers, their arguments, and their relationships. The desired events can be easily extracted from the event table. Experimental results show that the proposed model can cover 91.36% of events in the training dataset and that it can achieve a 50.44% recall in the test dataset by using the event table.','10.3745/JIPS.04.0008',450,113,0,0,NULL,'L2hvbWUvdmlydHVhbC9qaXBzL2pvdXJuYWwvdXBsb2FkL3BkZi8uLi9lcHViL2ppcHMtMTEtMi0yNDguZXB1Yg==&filename=amlwcy0xMS0yLTI0OC5lcHVi'),(357,2015,11,2,266,279,'Counter Chain: A New Block Cipher Mode of Operation','Authentication, Block Cipher Mode, Confidentiality, Counter Mode, Counter Chain','Aly Mohamed El-Semary, and Mohamed Mostafa A. Azim,','dlibrary/JIPS_v11_no2_paper8.pdf','In this paper, we propose a novel block cipher mode of operation, which is known as the counter chain (CC) mode. The proposed CC mode integrates the cipher block chaining (CBC) block cipher mode of operation with the counter (CTR) mode in a consistent fashion. In the CC mode, the confidentiality and authenticity of data are assured by the CBC mode, while speed is achieved through the CTR mode. The proposed mode of operation overcomes the parallelization deficiency of the CBC mode and the chaining dependency of the counter mode. Experimental results indicate that the proposed CC mode achieves the encryption speed of the CTR mode, which is exceptionally faster than the encryption speed of the CBC mode. Moreover, our proposed CC mode provides better security over the CBC mode. In summary, the proposed CC block cipher mode of operation takes the advantages of both the Counter mode and the CBC mode, while avoiding their shortcomings.','10.3745/JIPS.03.0031',541,146,0,0,NULL,'L2hvbWUvdmlydHVhbC9qaXBzL2pvdXJuYWwvdXBsb2FkL3BkZi8uLi9lcHViL2ppcHMtMTEtMi0yNjYuZXB1Yg==&filename=amlwcy0xMS0yLTI2Ni5lcHVi'),(358,2015,11,2,280,294,'Biological Infectious Watermarking Model for Video Copyright Protection','Biological Virus Modeling, Copyright Protection, Infectious Watermarking, Video Watermarking','Bong-Joo Jang, Suk-Hwan Lee, SangHun Lim, and Ki-Ryong Kwon','dlibrary/JIPS_v11_no2_paper9.pdf','This paper presents the infectious watermarking model (IWM) for the protection of video contents that are based on biological virus modeling by the infectious route and procedure. Our infectious watermarking is designed as a new paradigm protection for video contents, regarding the hidden watermark for video protection as an infectious virus, video content as host, and codec as contagion medium. We used pathogen, mutant, and contagion as the infectious watermark and defined the techniques of infectious watermark generation and authentication, kernel-based infectious watermarking, and content-based infectious watermarking. We experimented with our watermarking model by using existing watermarking methods as kernel-based infectious watermarking and content-based infectious watermarking medium, and verified the practical applications of our model based on these experiments.','10.3745/JIPS.02.0013',455,115,0,0,NULL,'L2hvbWUvdmlydHVhbC9qaXBzL2pvdXJuYWwvdXBsb2FkL3BkZi8uLi9lcHViL2ppcHMtMTEtMi0yODAuZXB1Yg==&filename=amlwcy0xMS0yLTI4MC5lcHVi'),(359,2015,11,2,295,309,'An Adaptive Superframe Duration Allocation Algorithm for Resource-Efficient Beacon Scheduling','Beacon Scheduling, Energy Efficient, IEEE802.15.4, IEEE802.15.4e, LR-WPAN, Superframe Duration Allocation','Young-Ae Jeon, Sang-Sung Choi, Dae-Young Kim, and Kwang-il Hwang','dlibrary/JIPS_v11_no2_paper10.pdf','Beacon scheduling is considered to be one of the most significant challenges for energy-efficient Low-Rate Wireless Personal Area Network (LR-WPAN) multi-hop networks. The emerging new standard, IEEE802.15.4e, contains a distributed beacon scheduling functionality that utilizes a specific bitmap and multi-superframe structure. However, this new standard does not provide a critical recipe for superframe duration (SD) allocation in beacon scheduling. Therefore, in this paper, we first introduce three different SD allocation approaches, LSB first, MSB first, and random. Via experiments we show that IEEE802.15.4e DSME beacon scheduling performs differently for different SD allocation schemes. Based on our experimental results we propose an adaptive SD allocation (ASDA) algorithm. It utilizes a single indicator, a distributed neighboring slot incrementer (DNSI). The experimental results demonstrate that the ASDA has a superior performance over other methods from the viewpoint of resource efficiency.','10.3745/JIPS.03.0025',485,130,0,0,NULL,'L2hvbWUvdmlydHVhbC9qaXBzL2pvdXJuYWwvdXBsb2FkL3BkZi8uLi9lcHViL2ppcHMtMTEtMi0yOTUuZXB1Yg==&filename=amlwcy0xMS0yLTI5NS5lcHVi'),(360,2015,11,2,310,324,'Improving the Diffusion of the Stream Cipher Salsa20 by Employing a Chaotic Logistic Map','Chaos Theory, Cryptography, Differential Attacks, Hash Function, Logistic Map, Salsa20, Stream Cipher','Mishal Almazrooie, Azman Samsudin, and Manmeet Mahinderjit Singh','dlibrary/JIPS_v11_no2_paper11.pdf','The stream cipher Salsa20 and its reduced versions are among the fastest stream ciphers available today. However, Salsa20/7 is broken and Salsa20/12 is not as safe as before. Therefore, Salsa20 must completely perform all of the four rounds of encryption to achieve a good diffusion in order to resist the known attacks. In this paper, a new variant of Salsa20 that uses the chaos theory and that can achieve diffusion faster than the original Salsa20 is presented. The method has been tested and benchmarked with the original Salsa20 with a series of tests. Most of the tests show that the proposed chaotic Salsa of two rounds is faster than the original four rounds of Salsa20/4, but it offers the same diffusion level.','10.3745/JIPS.02.0024',489,175,0,0,NULL,'L2hvbWUvdmlydHVhbC9qaXBzL2pvdXJuYWwvdXBsb2FkL3BkZi8uLi9lcHViL2ppcHMtMTEtMi0zMTAuZXB1Yg==&filename=amlwcy0xMS0yLTMxMC5lcHVi'),(361,2015,11,3,325,341,'A Dataset of Online Handwritten Assamese Characters','Assamese, Character Recognition, Dataset Collection, Data Verification, Online Handwriting, Support Vector Machine','Udayan Baruah and Shyamanta M. Hazarika','dlibrary/JIPS_v11_no3_paper1.pdf','This paper describes the Tezpur University dataset of online handwritten Assamese characters. The online data acquisition process involves the capturing of data as the text is written on a digitizer with an electronic pen. A sensor picks up the pen-tip movements, as well as pen-up/pen-down switching. The dataset contains 8,235 isolated online handwritten Assamese characters. Preliminary results on the classification of online handwritten Assamese characters using the above dataset are presented in this paper. The use of the support vector machine classifier and the classification accuracy for three different feature vectors are explored in our research.','10.3745/JIPS.02.0008',530,188,0,0,NULL,'L2hvbWUvdmlydHVhbC9qaXBzL2pvdXJuYWwvdXBsb2FkL3BkZi8uLi9lcHViL2ppcHMtMTEtMy0zMjUuZXB1Yg==&filename=amlwcy0xMS0zLTMyNS5lcHVi'),(362,2015,11,3,342,353,'Sparse Channel Estimation of Single Carrier Frequency Division Multiple Access Based on Compressive Sensing','Compressive Sensing, Random Pilot Pattern, SC-FDMA, Sparse Channel Estimation','Yuan-Hong Zhong, Zhi-Yong Huang, Bin Zhu, and Hua Wu','dlibrary/JIPS_v11_no3_paper2.pdf','It is widely accepted that single carrier frequency division multiple access (SC-FDMA) is an excellent candidate for broadband wireless systems. Channel estimation is one of the key challenges in SC-FDMA, since accurate channel estimation can significantly improve equalization at the receiver and, consequently, enhance the communication performances. In this paper, we study the application of compressive sensing for sparse channel estimation in a SC-FDMA system. By skillfully designing pilots, their patterns, and taking advantages of the sparsity of the channel impulse response, the proposed system realizes channel estimation at a low cost. Simulation results show that it can achieve significantly improved performance in a frequency selective fading sparse channel with fewer pilots.','10.3745/JIPS.03.0028',339,111,0,0,NULL,'L2hvbWUvdmlydHVhbC9qaXBzL2pvdXJuYWwvdXBsb2FkL3BkZi8uLi9lcHViL2ppcHMtMTEtMy0zNDIuZXB1Yg==&filename=amlwcy0xMS0zLTM0Mi5lcHVi'),(363,2015,11,3,354,369,'A Review of Fixed-Complexity Vector Perturbation for MU-MIMO','Block Diagonalization, MU-MIMO, Perfect and Imperfect Channel Knowledge, Quantization, Vector Perturbation','Manar Mohaisen','dlibrary/JIPS_v11_no3_paper3.pdf','Recently, there has been an increasing demand of high data rates services, where several multiuser multiple- input multiple-output (MU-MIMO) techniques were introduced to meet these demands. Among these tech- niques, vector perturbation combined with linear precoding techniques, such as zero-forcing and minimum mean-square error, have been proven to be efficient in reducing the transmit power and hence, perform close to the optimum algorithm. In this paper, we review several fixed-complexity vector perturbation techniques and investigate their performance under both perfect and imperfect channel knowledge at the transmitter. Also, we investigate the combination of block diagonalization with vector perturbation outline its merits.','10.3745/JIPS.03.0035',361,134,0,0,NULL,'L2hvbWUvdmlydHVhbC9qaXBzL2pvdXJuYWwvdXBsb2FkL3BkZi8uLi9lcHViL2ppcHMtMTEtMy0zNTQuZXB1Yg==&filename=amlwcy0xMS0zLTM1NC5lcHVi'),(364,2015,11,3,370,388,'Simple Pyramid RAM-Based Neural Network Architecture for Localization of Swarm Robots','Localization Process, RAM-Based Neural Network, Swarm Robots','Siti Nurmaini and Ahmad Zarkasi','dlibrary/JIPS_v11_no3_paper4.pdf','The localization of multi-agents, such as people, animals, or robots, is a requirement to accomplish several tasks. Especially in the case of multi-robotic applications, localization is the process for determining the positions of robots and targets in an unknown environment. Many sensors like GPS, lasers, and cameras are utilized in the localization process. However, these sensors produce a large amount of computational resources to process complex algorithms, because the process requires environmental mapping. Currently, combination multi-robots or swarm robots and sensor networks, as mobile sensor nodes have been widely available in indoor and outdoor environments. They allow for a type of efficient global localization that demands a relatively low amount of computational resources and for the independence of specific environmental features. However, the inherent instability in the wireless signal does not allow for it to be directly used for very accurate position estimations and making difficulty associated with conducting the localization processes of swarm robotics system. Furthermore, these swarm systems are usually highly decentralized, which makes it hard to synthesize and access global maps, it can be decrease its flexibility. In this paper, a simple pyramid RAM-based Neural Network architecture is proposed to improve the localization process of mobile sensor nodes in indoor environments. Our approach uses the capabilities of learning and generalization to reduce the effect of incorrect information and increases the accuracy of the agent’s position. The results show that by using simple pyramid RAM-base Neural Network approach, produces low computational resources, a fast response for processing every changing in environmental situation and mobile sensor nodes have the ability to finish several tasks especially in localization processes in real time.','10.3745/JIPS.01.0008',445,113,0,0,NULL,'L2hvbWUvdmlydHVhbC9qaXBzL2pvdXJuYWwvdXBsb2FkL3BkZi8uLi9lcHViL2ppcHMtMTEtMy0zNzAuZXB1Yg==&filename=amlwcy0xMS0zLTM3MC5lcHVi'),(365,2015,11,3,389,405,'A Column-Aware Index Management Using Flash Memory for Read-Intensive Databases','Column-Aware Index Management, Column-Oriented Databases, Flash Memory Storage, Game Database, Network Database','Si-Woo Byun and Seok-Woo Jang','dlibrary/JIPS_v11_no3_paper5.pdf','Most traditional database systems exploit a record-oriented model where the attributes of a record are placed contiguously in a hard disk to achieve high performance writes. However, for read-mostly data warehouse systems, the column-oriented database has become a proper model because of its superior read performance. Today, flash memory is largely recognized as the preferred storage media for high-speed database systems. In this paper, we introduce a column-oriented database model based on flash memory and then propose a new column-aware flash indexing scheme for the high-speed column-oriented data warehouse systems. Our index management scheme, which uses an enhanced B+-Tree, achieves superior search performance by indexing an embedded segment and packing an unused space in internal and leaf nodes. Based on the performance results of two test databases, we concluded that the column-aware flash index management outperforms the traditional scheme in the respect of the mixed operation throughput and its response time.','10.3745/JIPS.04.0017',323,91,0,0,NULL,'L2hvbWUvdmlydHVhbC9qaXBzL2pvdXJuYWwvdXBsb2FkL3BkZi8uLi9lcHViL2ppcHMtMTEtMy0zODkuZXB1Yg==&filename=amlwcy0xMS0zLTM4OS5lcHVi'),(366,2015,11,3,406,420,'Robust and Reversible Image Watermarking Scheme Using Combined DCT-DWT-SVD Transforms','Image Security, Image Watermarking, Reversible DWT-DCT-SVD Transform','Souad Bekkouch and Kamel Mohamed Faraoun','dlibrary/JIPS_v11_no3_paper6.pdf','We present a secure and robust image watermarking scheme that uses combined reversible DWT-DCT-SVD transformations to increase integrity, authentication, and confidentiality. The proposed scheme uses two different kinds of watermarking images: a reversible watermark, W1, which is used for verification (ensuring integrity and authentication aspects); and a second one, W2, which is defined by a logo image that provides confidentiality. Our proposed scheme is shown to be robust, while its performances are evaluated with respect to the peak signal-to-noise ratio (PSNR), signal-to-noise ratio (SNR), normalized cross-correlation (NCC), and running time. The robustness of the scheme is also evaluated against different attacks, including a compression attack and Salt & Pepper attack.','10.3745/JIPS.02.0021',376,135,0,0,NULL,'L2hvbWUvdmlydHVhbC9qaXBzL2pvdXJuYWwvdXBsb2FkL3BkZi8uLi9lcHViL2ppcHMtMTEtMy00MDYuZXB1Yg==&filename=amlwcy0xMS0zLTQwNi5lcHVi'),(367,2015,11,3,421,437,'Classification of Textured Images Based on Discrete Wavelet Transform and Information Fusion','Discrete Wavelet Transform, Feature Extraction, Fuzzy Set Theory, Information Fusion, Probability Theory, Segmentation, Supervised Classification','Chaimae Anibou, Mohammed Nabil Saidi, and Driss Aboutajdine','dlibrary/JIPS_v11_no3_paper7.pdf','This paper aims to present a supervised classification algorithm based on data fusion for the segmentation of the textured images. The feature extraction method we used is based on discrete wavelet transform (DWT). In the segmentation stage, the estimated feature vector of each pixel is sent to the support vector machine (SVM) classifier for initial labeling. To obtain a more accurate segmentation result, two strategies based on infor- mation fusion were used. We first integrated decision-level fusion strategies by combining decisions made by the SVM classifier within a sliding window. In the second strategy, the fuzzy set theory and rules based on probability theory were used to combine the scores obtained by SVM over a sliding window. Finally, the per- formance of the proposed segmentation algorithm was demonstrated on a variety of synthetic and real images and showed that the proposed data fusion method improved the classification accuracy compared to applying a SVM classifier. The results revealed that the overall accuracies of SVM classification of textured images is 88%, while our fusion methodology obtained an accuracy of up to 96%, depending on the size of the data base.','10.3745/JIPS.02.0028',461,132,0,0,NULL,'L2hvbWUvdmlydHVhbC9qaXBzL2pvdXJuYWwvdXBsb2FkL3BkZi8uLi9lcHViL2ppcHMtMTEtMy00MjEuZXB1Yg==&filename=amlwcy0xMS0zLTQyMS5lcHVi'),(368,2015,11,3,438,449,'A Lightweight and Effective Music Score Recognition on Mobile Phones','Mobile Camera, Music Score, SVM, Symbol Classification','Tam Nguyen and Gueesang Lee','dlibrary/JIPS_v11_no3_paper8.pdf','Recognition systems for scanned or printed music scores that have been implemented on personal computers have received attention from numerous scientists and have achieved significant results over many years. A modern trend with music scores being captured and played directly on mobile devices has become more interesting to researchers. The limitation of resources and the effects of illumination, distortion, and inclination on input images are still challenges to these recognition systems. In this paper, we introduce a novel approach for recognizing music scores captured by mobile cameras. To reduce the complexity, as well as the computational time of the system, we grouped all of the symbols extracted from music scores into ten main classes. We then applied each major class to SVM to classify the musical symbols separately. The experimental results showed that our proposed method could be applied to real time applications and that its performance is competitive with other methods.','10.3745/JIPS.02.0023',443,111,0,0,NULL,'L2hvbWUvdmlydHVhbC9qaXBzL2pvdXJuYWwvdXBsb2FkL3BkZi8uLi9lcHViL2ppcHMtMTEtMy00MzguZXB1Yg==&filename=amlwcy0xMS0zLTQzOC5lcHVi'),(369,2015,11,3,450,464,'Comparative Study of Various Persian Stemmers in the Field of Information Retrieval','Lookup Table Stemmer, Stemmer, Statistical Stemmer, Structural Stemmer','Fatemeh Momenipour Moghadam and MohammadReza Keyvanpour','dlibrary/JIPS_v11_no3_paper9.pdf','In linguistics, stemming is the operation of reducing words to their more general form, which is called the ‘stem’. Stemming is an important step in information retrieval systems, natural language processing, and text mining. Information retrieval systems are evaluated by metrics like precision and recall and the fundamental superiority of an information retrieval system over another one is measured by them. Stemmers decrease the indexed file, increase the speed of information retrieval systems, and improve the performance of these sys- tems by boosting precision and recall. There are few Persian stemmers and most of them work based on mor- phological rules. In this paper we carefully study Persian stemmers, which are classified into three main clas- ses: structural stemmers, lookup table stemmers, and statistical stemmers. We describe the algorithms of each class carefully and present the weaknesses and strengths of each Persian stemmer. We also propose some metrics to compare and evaluate each stemmer by them.','10.3745/JIPS.04.0020',312,117,0,0,NULL,'L2hvbWUvdmlydHVhbC9qaXBzL2pvdXJuYWwvdXBsb2FkL3BkZi8uLi9lcHViL2ppcHMtMTEtMy00NTAuZXB1Yg==&filename=amlwcy0xMS0zLTQ1MC5lcHVi'),(370,2015,11,3,465,482,'An Enhanced Message Priority Mechanism in IEEE 802.11p Based Vehicular Networks','Contention Window, IEEE 802.11p, MAC Layer, Message Priority, Vehicular Network','Chang Liu, Sang-Hwa Chung, Han-You Jeong, and Ik-Joo Jung','dlibrary/JIPS_v11_no3_paper10.pdf','IEEE 802.11p is a standard MAC protocol for wireless access in vehicular environments (WAVEs). If a packet collision happens when a safety message is sent out, IEEE 802.11p chooses a random back-off counter value in a fixed-size contention window. However, depending on the random choice of back-off counter value, it is still possible that less important messages are sent out first while more important messages are delayed longer until sent out. In this paper, we present a new scheme for safety message scheduling, called the enhanced message priority mechanism (EMPM). It consists of the following two components: the benefit-value algorithm, which calculates the priority of the messages depending on the speed, deceleration, and message lifetime; and the back-off counter selection algorithm, which chooses the non-uniform back-off counter value in order to reduce the collision probability and to enhance the throughput of the highly beneficial messages. Numerical results show that the EMPM can significantly improve the throughput and delay of messages with high benefits when compared with existing MAC protocols. Consequently, the EMPM can provide better QoS support for the more important and urgent messages.','10.3745/JIPS.03.0027',335,106,0,0,NULL,'L2hvbWUvdmlydHVhbC9qaXBzL2pvdXJuYWwvdXBsb2FkL3BkZi8uLi9lcHViL2ppcHMtMTEtMy00NjUuZXB1Yg==&filename=amlwcy0xMS0zLTQ2NS5lcHVi'),(371,2015,11,3,483,494,'Performance Comparison of HEVC and H.264/AVC Standards in Broadcasting Environments','Complexity, Compression Efficiency, HEVC, H.264/AVC, Latency','Maheshi B. Dissanayake and Dilanga L. B. Abeyrathna','dlibrary/JIPS_v11_no3_paper11.pdf','High Efficiency Video Coding (HEVC) is the most recent video codec standard of the ITU-T Video Coding Experts Group and the ISO/IEC Moving Picture Experts Group. The main goal of this newly introduced standard is for catering to high-resolution video in low bandwidth environments with a higher compression ratio. This paper provides a performance comparison between HEVC and H.264/AVC video compression standards in terms of objective quality, delay, and complexity in the broadcasting environment. The experimental investigation was carried out using six test sequences in the random access configuration of the HEVC test model (HM), the HEVC reference software. This was also carried out in similar configuration settings of the Joint Scalable Video Module (JSVM), the official scalable H.264/AVC reference implementation, running on a single layer mode. According to the results obtained, the HM achieves more than double the compression ratio compared to that of JSVM and delivers the same video quality at half the bitrate. Yet, the HM encodes two times slower (at most) than JSVM. Hence, it can be concluded that the application scenarios of HM and JSVM should be judiciously selected considering the availability of system resources. For instance, HM is not suitable for low delay applications, but it can be used effectively in low bandwidth environments.','10.3745/JIPS.03.0036',400,171,0,0,NULL,'L2hvbWUvdmlydHVhbC9qaXBzL2pvdXJuYWwvdXBsb2FkL3BkZi8uLi9lcHViL2ppcHMtMTEtMy00ODMuZXB1Yg==&filename=amlwcy0xMS0zLTQ4My5lcHVi'),(80000,0,0,0,0,0,'A Novel Framework for Defining and Submitting Workflows to Service-Oriented Systems','Service Composition, Service-Oriented Computing, Service-Oriented Workflow, UML2BPEL, Workflow','Hayat Bendoukha, Yahya Slimani, and Abdelkader Benyettou','dlibrary/JIPS_OF_paper1.pdf','Service-oriented computing offers efficient solutions for executing complex applications in an acceptable amount of time. These solutions provide important computing and storage resources, but they are too difficult for individual users to handle. In fact, Service-oriented architectures are usually sophisticated in terms of design, specifications, and deployment. On the other hand, workflow management systems provide frameworks that help users to manage cooperative and interdependent processes in a convivial manner. In this paper, we propose a workflow-based approach to fully take advantage of new service-oriented architectures that take the users’ skills and the internal complexity of their applications into account. To get to this point, we defined a novel framework named JASMIN, which is responsible for managing service-oriented workflows on distributed systems. JASMIN has two main components: unified modeling language (UML) to specify workflow models and business process execution language (BPEL) to generate and compose Web services. In order to cover both workflow and service concepts, we describe in this paper a refinement of UML activity diagrams and present a set of rules for mapping UML activity diagrams into BPEL specifications.','10.3745/JIPS.02.0003',695,147,0,1,'2014-08-25',NULL),(80001,0,0,0,0,0,'Spectrum Sensing and Data Transmission in a Cognitive Relay Network Considering Spatial False Alarms','Cognitive Network, Conventional False Alarms, Probability of Symbol Error Rate, Spatial False Alarms, Spectrum Sensing','Tasnina A. Tishita, Sumiya Akhter, Md. Imdadul Islam, and M. R. Amin','dlibrary/JIPS_OF_paper2.pdf','In this paper, the average probability of the symbol error rate (SER) and throughput are studied in the presence of joint spectrum sensing and data transmission in a cognitive relay network, which is in the environment of an optimal power allocation strategy. In this investigation, the main component in calculating the secondary throughput is the inclusion of the spatial false alarms, in addition to the conventional false alarms. It has been shown that there exists an optimal secondary power amplification factor at which the probability of SER has a minimum value, whereas the throughput has a maximum value. We performed a Monte-Carlo simulation to validate the analytical results.','10.3745/JIPS.03.0007',433,125,0,2,'2014-08-25',NULL),(80002,0,0,0,0,0,'Femtocell Subband Selection Method for Managing Cross- and Co-tier Interference in a Femtocell Overlaid Cellular Network','Clustering Method, Femtocell, Frequency Partition, Interference Management','Young Min Kwon, Hyunseung Choo, Tae-Jin Lee, Min Young Chung, and Mihui Kim','dlibrary/JIPS_OF_paper3.pdf','The femtocell overlaid cellular network (FOCN) has been used to enhance the capacity of existing cellular systems. To obtain the desired system performance, both cross-tier interference and co-tier interference in an FOCN need to be managed. This paper proposes an interference management scheme that adaptively constructs a femtocell cluster, which is a group of femtocell base stations that share the same frequency band. The performance evaluation shows that the proposed scheme can enhance the performance of the macrocell-tier and maintain a greater signal to interference-plus-noise ratio than the outage level can for about 99% of femtocell users.','10.3745/JIPS.03.0008',385,281,0,3,'2014-08-25',NULL),(80003,0,0,0,0,0,'Ultra Low Power Data Aggregation for Request Oriented Sensor Networks','Data Aggregation, Energy Efficient, Low Power Listening, Medium Access Control, Request Oriented, Sensor Networks','Kwang-il Hwang and In Jang','dlibrary/JIPS_OF_paper4.pdf','Request oriented sensor networks have stricter requirements than conventional event-driven or periodic report models. Therefore, in this paper we propose a minimum energy data aggregation (MEDA), which meets the requirements for request oriented sensor networks by exploiting a low power real-time scheduler, ondemand time synchronization, variable response frame structure, and adaptive retransmission. In addition we introduce a test bed consisting of a number of MEDA prototypes, which support near real-time bidirectional sensor networks. The experimental results also demonstrate that the MEDA guarantees deterministic aggregation time, enables minimum energy operation, and provides a reliable data aggregation service.','10.3745/JIPS.03.0009',380,132,0,4,'2014-08-25',NULL),(80004,0,0,0,0,0,'Efficient Greedy Algorithms for Influence Maximization in Social Networks','Greedy Algorithm, Influence Maximization, Social Network','Jiaguo Lv, Jingfeng Guo, and Huixiao Ren','dlibrary/JIPS_OF_paper5.pdf','Influence maximization is an important problem of finding a small subset of nodes in a social network, such that by targeting this set, one will maximize the expected spread of influence in the network. To improve the efficiency of algorithm KK_Greedy proposed by Kempe et al., we propose two improved algorithms, Lv_NewGreedy and Lv_CELF. By combining all of advantages of these two algorithms, we propose a mixed algorithm Lv_MixedGreedy. We conducted experiments on two synthetically datasets and show that our improved algorithms have a matching influence with their benchmark algorithms, while being faster than them.','10.3745/JIPS.04.0003',397,194,0,5,'2014-08-25',NULL),(80005,0,0,0,0,0,'Fault Detection in the Semiconductor Etch Process Using the Seasonal Autoregressive Integrated Moving Average Modeling','Autoregressive Integrated Moving Average, Dynamic Time Warping, Fault Detection, Seasonal Autoregressive Integrated Moving Average, Semiconductor Process, Time Series Modeling','Muhammad Zeeshan Arshad, Javeria Muhammad Nawaz, and Sang Jeen Hong','dlibrary/JIPS_OF_paper6.pdf','In this paper, we investigated the use of seasonal autoregressive integrated moving average (SARIMA) time series models for fault detection in semiconductor etch equipment data. The derivative dynamic time warping algorithm was employed for the synchronization of data. The models were generated using a set of data from healthy runs, and the established models were compared with the experimental runs to find the faulty runs. It has been shown that the SARIMA modeling for this data can detect faults in the etch tool data from the semiconductor industry with an accuracy of 80% and 90% using the parameter-wise error computation and the step-wise error computation, respectively. We found that SARIMA is useful to detect incipient faults in semiconductor fabrication.','10.3745/JIPS.04.0004',424,185,0,6,'2014-08-25',NULL),(80006,0,0,0,0,0,'A Memory Efficient Anti-Collision Protocol to Identify Memoryless RFID Tags','RFID tag identification, anti-collision protocol, data structure, query tree','Haejae Jung','dlibrary/JIPS_OF_paper7.pdf','This paper presents a memory efficient tree based anti-collision protocol to identify memoryless RFID (Radio Frequency Identification) tags that may be attached to products. The proposed deterministic scheme utilizes two bit arrays instead of stack or queue and requires only ?(n) space, which is better than the earlier schemes that use at least O(n2) space, where n is the length of a tag ID in a bit. Also, the size n of each bit array is independent of the number of tags to identify. Our simulation results show that our bit array scheme consumes much less memory space than the earlier schemes utilizing queue or stack.','10.3745/JIPS.03.0010',379,192,0,7,'2014-10-07',NULL),(80007,0,0,0,0,0,'Fast Device Discovery for Remote Device Management in Lighting Control Networks','Device Discovery, Partition-Based, RDM','Sang-Il Choi, Sanghun Lee, Seok-Joo Koh, Sang-Kyu Lim, Insu Kim, and Tae-Gyu Kang','dlibrary/JIPS_OF_paper8.pdf','The Remote Device Management (RDM) protocol is used to manage the devices in the lighting control networks. RDM provides bi-directional communications between a controller and many lighting devices over the DMX512-A network. In RDM, using a simple binary search scheme, which is based on the 48-bit unique ID (UID) of each device, discovers the lighting devices. However, the existing binary search scheme tends to require a large delay in the device discovery process. In this paper, we propose a novel partition-based discovery scheme for fast device discovery in RDM. In the proposed scheme, all devices are divided into several partitions as per the device UID, and the controller performs device discovery for each partition by configuring a response timer that each device will use. From numerical simulations, we can see that there is an optimal number of partitions to minimize the device discovery time for a given number of devices in the proposed scheme, and also that the proposed partition-based scheme can reduce the device discovery time, as compared to the existing binary search scheme.','10.3745/JIPS.03.0011',412,158,0,8,'2014-10-07',NULL),(80008,0,0,0,0,0,'A Maximum Entropy-Based Bio-Molecular Event Extraction Model that Considers Event Generation','Bioinformatics, Text-Mining, Event Extraction, Maximum Entropy','Hyoung-Gyu Lee, So-Young Park, Hae-Chang Rim, Do-Gil Lee, and Hong-Woo Chun','dlibrary/JIPS_OF_paper9.pdf','In this paper, we propose a maximum entropy-based model, which can mathematically explain the bio-molecular event extraction problem. The proposed model generates an event table, which can represent the relationship between an event trigger and its arguments. The complex sentences with distinctive event structures can be also represented by the event table. Previous approaches intuitively designed a pipeline system, which sequentially performs trigger detection and arguments recognition, and thus, did not clearly explain the relationship between identified triggers and arguments. On the other hand, the proposed model generates an event table that can represent triggers, their arguments, and their relationships. The desired events can be easily extracted from the event table. Experimental results show that the proposed model can cover 91.36% of events in the training dataset and that it can achieve a 50.44% recall in the test dataset by using the event table.','10.3745/JIPS.04.0008',470,162,0,9,'2014-10-07',NULL),(80009,0,0,0,0,0,'Graphemes Segmentation for Arabic Online Handwriting Modeling','Baseline Detection, Diacritic Features, Grapheme Segmentation, Fourier Descriptors, Geometric Parameters, Online Arabic Handwriting Modeling','Houcine Boubaker, Najiba Tagougui, Haikal El Abed, Monji Kherallah, and Adel M. Alimi','dlibrary/JIPS_OF_paper10.pdf','In the cursive handwriting recognition process, script trajectory segmentation and modeling represent an important task for large or open lexicon context that becomes more complicated in multi-writer applications. In this paper, we will present a developed system of Arabic online handwriting modeling based on graphemes segmentation and the extraction of its geometric features. The main contribution consists of adapting the Fourier descriptors to model the open trajectory of the segmented graphemes. To segment the trajectory of the handwriting, the system proceeds by first detecting its baseline by checking the combined geometric and logic conditions. Then, the detected baseline is used as a topologic reference for the extraction of particular points that delimit the graphemes’ trajectories. The segmented graphemes are then represented by a set of relevant geometric features that include the vector of the Fourier descriptors for trajectory shape modeling, normalized metric parameters that model the grapheme dimensions, its positions in respect to the baseline, and the codes for the description of associated diacritics.','10.3745/JIPS.02.0006',492,159,0,10,'2014-10-07',NULL),(80010,0,0,0,0,0,'A Dataset of Online Handwritten Assamese Characters','Assamese, Character Recognition, Dataset Collection, Data Verification, Online Handwriting, Support Vector Machine','Udayan Baruah and Shyamanta M. Hazarika','dlibrary/JIPS_OF_paper11.pdf','This paper describes the Tezpur University dataset of online handwritten Assamese characters. The online data acquisition process involves the capturing of data as the text is written on a digitizer with an electronic pen. A sensor picks up the pen-tip movements, as well as pen-up/pen-down switching. The dataset contains 8,235 isolated online handwritten Assamese characters. Preliminary results on the classification of online handwritten Assamese characters using the above dataset are presented in this paper. The use of the support vector machine classifier and the classification accuracy for three different feature vectors are explored in our research.','10.3745/JIPS.02.0008',549,494,0,11,'2014-10-20',NULL),(80011,0,0,0,0,0,'Multimodal Biometric Using a Hierarchical Fusion of a Person’s Face, Voice, and Online Signature','Hierarchical Fusion, LDA, Multimodal Biometric Fusion, PCA','Youssef Elmir, Zakaria Elberrichi, and Réda Adjoudj','dlibrary/JIPS_OF_paper12.pdf','Biometric performance improvement is a challenging task. In this paper, a hierarchical strategy fusion based on multimodal biometric system is presented. This strategy relies on a combination of several biometric traits using a multi-level biometric fusion hierarchy. The multi-level biometric fusion includes a pre-classification fusion with optimal feature selection and a post-classification fusion that is based on the similarity of the maximum of matching scores. The proposed solution enhances biometric recognition performances based on suitable feature selection and reduction, such as principal component analysis (PCA) and linear discriminant analysis (LDA), as much as not all of the feature vectors components support the performance improvement degree.','10.3745/JIPS.02.0007',393,216,0,12,'2014-10-20',NULL),(80012,0,0,0,0,0,'Resilient Packet Transmission (RPT) for Buffer Based Routing (BBR) Protocol','WMN, Resiliency, BBR, Routing, RPT','Geetanjali Rathee and Nitin Rakesh','dlibrary/JIPS_OF_paper13.pdf','To provide effective communication in Wireless Mesh Network (WMN), several algorithms have been proposed. Since, the possibilities of numerous failures always exist during communication; resiliency has been proved to be an important aspect for WMN to recover from these failures. Resiliency in general is the diligence of reliability and availability in network. Several types of resiliency based routing algorithms have been proposed i.e. Resilient Multicast, ROMER etc. Resilient Multicast establishes two-node disjoint path and ROMER uses credit based approach to provide resiliency in the network. However these proposed approaches have some disadvantages in terms of network throughput and network congestion. Previously Buffer Based Routing (BBR) approach has been proposed to overcome these disadvantages. We have proved earlier that BBR is more efficient w.r.t throughput, network performance and reliability. In this paper we have considered the node/link failure issues and analogous performance of BBR. For this we have proposed Resilient Packet Transmission (RPT) algorithm as a remedy for BBR during such failures. Further we have shown the comparative performance analysis of previous approaches with our proposed approach. Network throughput, network congestion and resiliency against node/link failure are particular performance metrics which are examined over different sized WMN.','10.3745/JIPS.03.0014',367,174,0,13,'2014-10-20',NULL),(80013,0,0,0,0,0,'Content Based Dynamic Texture Analysis and Synthesis Based on SPIHT with GPU','Discrete Wavelet Transform, Dynamic Texture, GPU, SPIHT, SVD','Premanand P Ghadekar and Nilkanth B Chopade','dlibrary/JIPS_OF_paper14.pdf','Dynamic textures are videos that exhibit a stationary property with respect to time (i.e., they have patterns that repeat themselves over a large number of frames). These patterns can easily be tracked by a linear dynamic system. In this paper, a model that identifies the underlying linear dynamic system using wavelet coefficients, rather than a raw sequence, is proposed. Content based threshold filtering based on Set Partitioning in a Hierarchical Tree (SPIHT) helps to get another representation of the same frames that only have low frequency components. The main idea of this paper is to apply SPIHT based threshold filtering on different bands of wavelet transform so as to have more significant information in fewer parameters for singular value decomposition (SVD). In this case, more flexibility is given for the component selection, as SVD is independently applied to the different bands of frames of a dynamic texture. To minimize the time complexity, the proposed model is implemented on a graphics processing unit (GPU). Test results show that the proposed dynamic system, along with a discrete wavelet and SPIHT, achieve a highly compact model with better visual quality, than the available LDS, Fourier descriptor model, and higher-order SVD (HOSVD).','10.3745/JIPS.02.0009',493,222,0,14,'2014-10-28',NULL),(80014,0,0,0,0,0,'Performance Evaluation of the WiMAX Network under a Complete Partitioned User Group with a Traffic Shaping Algorithm','Blocking Probability, CAC, Complete Partition Scheme, Subscriber Station, Throughput','Jesmin Akhter, Md. Imdadul Islam, and M. R. Amin','dlibrary/JIPS_OF_paper15.pdf','To enhance the utilization of the traffic channels of a network (instead of allocating radio channel to an individual user), a channel or a group of channels are allocated to a user group. The idea behind this is the statistical distribution of traffic arrival rates and the service time for an individual user or a group of users. In this paper, we derive the blocking probability and throughput of a subscriber station of Worldwide Interoperability for Microwave Access (WiMAX) by considering both the connection level and packet-level traffic under a complete partition scheme. The main contribution of the paper is to incorporate the traffic shaping scheme onto the incoming turbulent traffic. Hence, we have also analyzed the impact of the drain rate of the buffer on the blocking probability and throughput.','10.3745/JIPS.03.0016',336,142,0,15,'2014-10-28',NULL),(80015,0,0,0,0,0,'An Energy Efficient Distributed Approach-Based Agent Migration Scheme for Data Aggregation in Wireless Sensor Networks','Agent Migration Protocol, Data Aggregation, Mobile Agent, WSN','Govind P. Gupta, Manoj Misra, and Kumkum Garg','dlibrary/JIPS_OF_paper16.pdf','The use of mobile agents for collaborative processing in wireless sensor network has gained considerable attention. This is when mobile agents are used for data aggregation to exploit redundant and correlated data. The efficiency of agentbased data aggregation depends on the agent migration scheme. However, in general, most of the proposed schemes are centralized approach-based schemes where the sink node determines the migration paths for the agents before dispatching them in the sensor network. The main limitations with such schemes are that they need global network topology information for deriving the migration paths of the agents, which incurs additional communication overhead, since each node has a very limited communication range. In addition, a centralized approach does not provide fault tolerant and adaptive migration paths. In order to solve such problems, we have proposed a distributed approach-based scheme for determining the migration path of the agents where at each hop, the local information is used to decide the migration of the agents. In addition, we also propose a local repair mechanism for dealing with the faulty nodes. The simulation results show that the proposed scheme performs better than existing schemes in the presence of faulty nodes within the networks, and manages to report the aggregated data to the sink faster.','10.3745/JIPS.03.0018',375,157,0,16,'2014-10-28',NULL),(80016,0,0,0,0,0,'Genetic Symmetric Key Generation for IDEA','Crossover, IDEA, Genetic Algorithm, Mutation, Symmetric Key Generation','Nandini Malhotra and Geeta Nagpal','dlibrary/JIPS_OF_paper17.pdf','Cryptography aims at transmitting secure data over an unsecure network in coded version so that only the intended recipient can analyze it. Communication through messages, emails, or various other modes requires high security so as to maintain the confidentiality of the content. This paper deals with IDEA’s shortcoming of generating weak keys. If these keys are used for encryption and decryption may result in the easy prediction of ciphertext corresponding to the plaintext. For applying genetic approach, which is well-known optimization technique, to the weak keys, we obtained a definite solution to convert the weaker keys to stronger ones. The chances of generating a weak key in IDEA are very rare, but if it is produced, it could lead to a huge risk of attacks being made on the key, as well as on the information. Hence, measures have been taken to safeguard the key and to ensure the privacy of information.','10.3745/JIPS.03.0017',399,209,0,17,'2014-10-28',NULL),(80017,0,0,0,0,0,'Seamless Mobility of Heterogeneous Networks Based on Markov Decision Process','Action, Heterogeneous Handoff, MDP, Policy iteration, State','G.A. Preethi and Dr. C. Chandrasekar','dlibrary/JIPS_OF_paper18.pdf','A Mobile terminal will expect a number of handoffs within its call duration. In the event of a Mobile call, when a mobile node moves from one cell to another, it should connect to another access point within its range. In case of lack of support of its own network, it must changeover to another base station. In the event of moving on to another network, Quality of Service parameters need to be considered. Here we have given Markov Decision Process approach for seamless handoff. In which it gives optimum results for selecting a network when compared to other Multiple Attribute Decision Making processes. We have used Network cost function for selecting the network for handoff and Connection reward function which is based on the values of Quality of service parameters. We have also examined the Constant Bit Rate and Transmission Control Protocol Packet delivery ratio. The Policy iteration Algorithm is used for determining the optimal policy. Our enhanced handoff algorithm outperforms other previous Multiple Attribute Decision Making methods.','10.3745/JIPS.03.0015',371,207,0,18,'2014-10-28',NULL),(80018,0,0,0,0,0,'Penetration Testing and Network Auditing: Linux','Network attack, network auditing, network forensic','Deris Stiawan, Mohd. Yazid Idris, and Abdul Hanan Abdullah','dlibrary/JIPS_OF_paper19.pdf','Along with the evolution of Internet and its new emerging services, the quantity and impact of attacks have been continuously increasing. Currently, the technical capability to attack has tended to decrease. On the contrary, performances of hacking tools are evolving, growing, simple, comprehensive, and accessible to the public. In this work, network penetration testing and auditing of the Redhat operating system (OS) are highlighted as one of the most popular OS for Internet applications. Some types of attacks are from a different side and new attack method have been attempted, such as: scanning for reconnaissance, guessing the password, gaining privileged access, and flooding the victim machine to decrease availability. Some analyses in network auditing and forensic from victim server are also presented in this paper. Our proposed system aims confirmed as hackable or not and we expect for it to be used as a reference for practitioners to protect their systems from cyber-attacks.','10.3745/JIPS.03.0013',340,245,0,19,'2014-11-07',NULL),(80019,0,0,0,0,0,'A Note on Computing the Crisp Order Context of a Fuzzy Formal Context for Knowledge Reduction','Crisp Context, Concept Lattice, Formal Concept Analysis, Fuzzy Formal Concept, Fuzzy Relation, Knowledge Reduction','Prem Kumar Singh and Ch. Aswani Kumar','dlibrary/JIPS_OF_paper20.pdf','Fuzzy Formal Concept Analysis (FCA) is a mathematical tool for the effective representation of imprecise and vague knowledge. However, with a large number of formal concepts from a fuzzy context, the task of knowledge representation becomes complex. Hence, knowledge reduction is an important issue in FCA with a fuzzy setting. The purpose of this current study is to address this issue by proposing a method that computes the corresponding crisp order for the fuzzy relation in a given fuzzy formal context. The obtained formal context using the proposed method provides a fewer number of concepts when compared to original fuzzy context. The resultant lattice structure is a reduced form of its corresponding fuzzy concept lattice and preserves the specialized and generalized concepts, as well as stability. This study also shows a step-by-step demonstration of the proposed method and its application.','10.3745/JIPS.04.0009',506,149,0,20,'2014-11-07',NULL),(80020,0,0,0,0,0,'An Unified Representation of Context Knowledge Base for Mobile Context-Aware System','Context-Awareness, Knowledge Base, Unified Context Information','Jang-Seop Jeong and Dae-Wook Bang','dlibrary/JIPS_OF_paper21.pdf','To facilitate the implementation of a wide variety of context-aware applications based on mobile devices, general-purpose context-aware framework that applications can use by calling is needed. The context-aware framework is a middleware that performs the sensing, reasoning, and retrieving based on the knowledge base. The knowledge base must systematically represent the information required on the behavior of the context-aware framework, such as context information and reasoning information. It must also provide functions for storage and retrieval. To date, previous research on the representation of the context information have been carried out, but studies on the unified representation of the knowledge base has seen little progress. This study defines the knowledge base as the unified context information, and proposes the UniOWL, which can do a good job of representing it. UniOWL is based on OWL and represents the information that is necessary for the operation of the context-aware framework. Therefore, UniOWL greatly facilitates the implementation of the knowledge base on a context-aware framework.','10.3745/JIPS.01.0002',287,141,0,21,'2014-11-27',NULL),(80021,0,0,0,0,0,'A Step towards User Privacy while Using Location-Based Services','Location Based Services, Location Privacy, Point of Interests','Fizza Abbas and Heekuck Oh','dlibrary/JIPS_OF_paper22.pdf','Nowadays mobile users are using a popular service called Location-Based Services (LBS). LBS is very helpful for a mobile user in finding various Point of Interests (POIs) in their vicinity. To get these services, users must provide their personal information, such as user identity or current location, which severely risks the location privacy of the user. Many researchers are developing schemes that enable a user to use these LBS services anonymously, but these approaches have some limitations (i.e., either the privacy prevention mechanism is weak or the cost of the solution is too much). As such, we are presenting a robust scheme for mobile users that allows them to use LBS anonymously. Our scheme involves a client side application that interacts with an untrusted LBS server to find the nearest POI for a service required by a user. The scheme is not only efficient in its approach, but is also very practical with respect to the computations that are done on a client’s resource constrained device. With our scheme, not only can a client anonymously use LBS without any use of a trusted third party, but also a server’s database is completely secure from the client. We performed experiments by developing and testing an Android-based client side smartphone application to support our argument.','10.3745/JIPS.01.0003',324,184,0,22,'2014-11-27',NULL),(80022,0,0,0,0,0,'A Real-Time Integrated Hierarchical Temporal Memory Network for the Real-Time Continuous Multi-Interval Prediction of Data Streams','Data Streams, Hierarchical Temporal Memory, Multiple Interval Prediction, Real-Time Prediction','Hyun-Syug Kang','dlibrary/JIPS_OF_paper23.pdf','Continuous multi-interval prediction (CMIP) is used to continuously predict the trend of a data stream based on various intervals simultaneously. The continuous integrated hierarchical temporal memory (CIHTM) network performs well in CMIP. However, it is not suitable for CMIP in real-time mode, especially when the number of prediction intervals is increased. In this paper, we propose a real-time integrated hierarchical temporal memory (RIHTM) network by introducing a new type of node, which is called a Zeta1FirstSpecializedQueueNode (ZFSQNode), for the real-time continuous multi-interval prediction (RCMIP) of data streams. The ZFSQNode is constructed by using a specialized circular queue (sQUEUE) together with the modules of original hierarchical temporal memory (HTM) nodes. By using a simple structure and the easy operation characteristics of the sQUEUE, entire prediction operations are integrated in the ZFSQNode. In particular, we employed only one ZFSQNode in each level of the RIHTM network during the prediction stage to generate different intervals of prediction results. The RIHTM network efficiently reduces the response time. Our performance evaluation showed that the RIHTM was satisfied to continuously predict the trend of data streams with multi-intervals in the real-time mode.','10.3745/JIPS.02.0011',307,142,0,23,'2014-12-31',NULL),(80023,0,0,0,0,0,'Practical (Second) Preimage Attacks on the TCS_SHA-3 Family of Cryptographic Hash Functions','Cryptanalysis, Hash Function, (Second) Preimage Attack','Gautham Sekar and Soumyadeep Bhattacharya','dlibrary/JIPS_OF_paper24.pdf','TCS_SHA-3 is a family of four cryptographic hash functions that are covered by a United States patent (US 2009/0262925). The digest sizes are 224, 256, 384 and 512 bits. The hash functions use bijective functions in place of the standard compression functions. In this paper we describe first and second preimage attacks on the full hash functions. The second preimage attack requires negligible time and the first preimage attack requires O(236) time. In addition to these attacks, we also present a negligible time second preimage attack on a strengthened variant of the TCS_SHA-3. All the attacks have negligible memory requirements. To the best of our knowledge, there is no prior cryptanalysis of any member of the TCS_SHA-3 family in the hash function literature.','10.3745/JIPS.03.0021',282,108,0,24,'2014-12-31',NULL),(80024,0,0,0,0,0,'An Intuitionistic Fuzzy Approach to Classify the User Based on an Assessment of the Learner’s\rKnowledge Level in E-Learning Decision-Making','Domain Model, E-Learning, E-Learning Environment, Fuzzy Rules, Intuitionistic Fuzzy Set, User Modeling','Mukta Goyal, Divakar Yadav, and Alka Tripathi','dlibrary/JIPS_OF_paper25.pdf','In this paper, Atanassov’s intuitionistic fuzzy set theory is used to handle the uncertainty of students’ knowledge on domain concepts in an E-learning system. Their knowledge on these domain concepts has been collected from tests that were conducted during their learning phase. Atanassov’s intuitionistic fuzzy user model is proposed to deal with vagueness in the user’s knowledge description in domain concepts. The user model uses Atanassov’s intuitionistic fuzzy sets for knowledge representation and linguistic rules for updating the user model. The scores obtained by each student were collected in this model and the decision about the students’ knowledge acquisition for each concept whether completely learned, completely known, partially known or completely unknown were placed into the information table. Finally, it has been found that the proposed scheme is more appropriate than the fuzzy scheme.','10.3745/JIPS.04.0011',325,157,0,25,'2014-12-31',NULL),(80025,0,0,0,0,0,'A Contour Descriptors-Based Generalized Scheme for Handwritten Odia Numerals Recognition','Contour Features, Handwritten Character, Neural Classifier, Numeral Recognition, OCR, Odia.','Tusar Kanti Mishra, Banshidhar Majhi, and Ratnakar Dash','dlibrary/JIPS_OF_paper26.pdf','In this paper, we propose a novel feature for recognizing handwritten Odia numerals. By using polygonal approximation, each numeral is segmented into seg ments of equal pixel counts where the centroid of the character is kept as the or igin. Three primitive contour features namely, distance (l), angle (?), and arc-to-ch ord ratio (r), are extracted from these segments. These features are used in a neural classifier so that the numerals are recognized. Other existing features are also considered for being recognized in the neural classifier, in order to perform a comparative analysis. We carried out a simulation on a large data set and conducted a comparative analysis with other features with respect to recognition accuracy and time requirements. Furthermore, we also applied the feature to the numeral recognition of two other languages—Bangla and English. In general, we observed that our proposed contour features outperform other schemes.','10.3745/JIPS.02.0012',319,142,0,26,'2014-12-31',NULL),(80026,0,0,0,0,0,'Biological Infectious Watermarking Model for Video Copyright Protection','Biological Virus Modeling, Copyright Protection, Infectious Watermarking, Video Watermarking','Bong-Joo Jang, Suk-Hwan Lee, SangHun Lim, and Ki-Ryong Kwon','dlibrary/JIPS_OF_paper27.pdf','This paper presents the infectious watermarking model (IWM) for the protection of video contents that are based on biological virus modeling by the infectious route and procedure. Our infectious watermarking is designed as a new paradigm protection for video contents, regarding the hidden watermark for video protection as an infectious virus, video content as host, and codec as contagion medium. We used pathogen, mutant, and contagion as the infectious watermark and defined the techniques of infectious watermark generation and authentication, kernel-based infectious watermarking, and content-based infectious watermarking. We experimented with our watermarking model by using existing watermarking methods as kernel-based infectious watermarking and content-based infectious watermarking medium, and verified the practical applications of our model based on these experiments.','10.3745/JIPS.02.0013',383,153,0,27,'2014-12-31',NULL),(80027,0,0,0,0,0,'Research on the E-Commerce Credit Scoring Model Using the Gaussian Density Function','Abnormal Point, Credit Scoring, Density, E-commerce','Xiao Qiang, He Rui-chun, and Zhang Wei','dlibrary/JIPS_OF_paper28.pdf','At present, it is simple to the electronic commerce credit scoring model, as a brush credit phenomenon in E-commerce has emerged. This phenomenon affects the judgment of consumers and hinders the rapid development of E-commerce. In this paper, that E-commerce credit evaluation model that uses a Gaussian density function is put forward by density test and the analysis for the anomalies of E-commerce credit rating, it can be fond out the abnormal point in credit scoring, these points were calculated by nonlinear credit scoring algorithm, thus it can effectively improve the current E-commerce credit score, and enhance the accuracy of E-commerce credit score.','10.3745/JIPS.04.0012',373,187,0,28,'2014-12-31',NULL),(80028,0,0,0,0,0,'Energy Consumption Scheduling in a Smart Grid Including Renewable Energy','Energy Consumption Scheduling in a Smart Grid Including Renewable Energy','Nadia Boumkheld, Mounir Ghogho, and Mohammed El Koutbi','dlibrary/JIPS_OF_paper29.pdf','Smart grids propose new solutions for electricity consumers as a means to help them use energy in an efficient way. In this paper, we consider the demand-side management issue that exists for a group of consumers (houses) that are equipped with renewable energy (wind turbines) and storage units (battery), and we try to find the optimal scheduling for their home appliances, in order to reduce their electricity bills. Our simulation results prove the effectiveness of our approach, as they show a significant reduction in electricity costs when using renewable energy and battery storage.','10.3745/JIPS.03.0022',366,134,0,29,'2015-01-28',NULL),(80029,0,0,0,0,0,'Prediction & Assessment of Change Prone Classes Using Statistical & Machine Learning Techniques','Change Proneness, Empirical Validation, Machine Learning Techniques, Software Quality','Ruchika Malhotra and Ravi Jangra','dlibrary/JIPS_OF_paper30.pdf','Software today has become an inseparable part of our life. In order to achieve the ever demanding needs of customers, it has to rapidly evolve and include a number of changes. In this paper, our aim is to study the relationship of object oriented metrics with change proneness attribute of a class. Prediction models based on this study can help us in identifying change prone classes of a software. We can then focus our efforts on these change prone classes during testing to yield a better quality software. Previously, researchers have used statistical methods for predicting change prone classes. But machine learning methods are rarely used for identification of change prone classes. In our study, we evaluate and compare the performances of ten machine learning methods with the statistical method. This evaluation is based on two open source software systems developed in Java language. We also validated the developed prediction models using other software data set in the same domain (3D modelling). The performance of the predicted models was evaluated using receiver operating characteristic analysis. The results indicate that the machine learning methods are at par with the statistical method for prediction of change prone classes. Another analysis showed that the models constructed for a software can also be used to predict change prone nature of classes of another software in the same domain. This study would help developers in performing effective regression testing at low cost and effort. It will also help the developers to design an effective model that results in less change prone classes, hence better maintenance.','10.3745/JIPS.04.0013',385,149,0,30,'2015-01-28',NULL),(80030,0,0,0,0,0,'Viewer’s Affective Feedback for Video Summarization','Affective Computing, Emotion, FABO, K-NN, Motion Recognition, PCA, Video Summarization','Majdi Dammak, Ali Wali, and Adel M. Alimi','dlibrary/JIPS_OF_paper31.pdf','For different reasons, many viewers like to watch a summary of films without having to waste their time. Traditionally, video film was analyzed manually to provide a summary of it, but this costs an important amount of work time. Therefore, it has become urgent to propose a tool for the automatic video summarization job. The automatic video summarization aims at extracting all of the important moments in which viewers might be interested. All summarization criteria can differ from one video to another. This paper presents how the emotional dimensions issued from real viewers can be used as an important input for computing which part is the most interesting in the total time of a film. Our results, which are based on lab experiments that were carried out, are significant and promising.','10.3745/JIPS.01.0006',340,124,0,31,'2015-01-28',NULL),(80031,0,0,0,0,0,'An Improved Algorithm for Redundancy Detection Using Global Value Numbering','Equivalent Expression, Global Value Numbering, Herbrand Equivalence, Strong Equivalence Dag','Nabizath Saleena and Vineeth Paleri','dlibrary/JIPS_OF_paper32.pdf','Global value numbering (GVN) is a method for detecting equivalent expressions in programs. Most of the GVN algorithms concentrate on detecting equalities among variables and hence, are limited in their ability to identify value-based redundancies. In this paper, we suggest improvements by which the efficient GVN algorithm by Gulwani and Necula (2007) can be made to detect expression equivalences that are required for identifying value based redundancies. The basic idea for doing so is to use an anticipability-based Join algorithm to compute more precise equivalence information at join points. We provide a proof of correctness of the improved algorithm and show that its running time is a polynomial in the number of expressions in the program.','10.3745/JIPS.02.0014',386,150,0,32,'2015-01-28',NULL),(80032,0,0,0,0,0,'An Enhanced Message Priority Mechanism in IEEE 802.11p Based Vehicular Networks','Contention Window, IEEE 802.11p, MAC Layer, Message Priority, Vehicular Network','Chang Liu, Sang-Hwa Chung, Han-You Jeong, and Ik-Joo Jung','dlibrary/JIPS_OF_paper33.pdf','IEEE 802.11p is a standard MAC protocol for wireless access in vehicular environments (WAVEs). If a packet collision happens when a safety message is sent out, IEEE 802.11p chooses a random back-off counter value in a fixed-size contention window. However, depending on the random choice of back-off counter value, it is still possible that less important messages are sent out first while more important messages are delayed longer until sent out. In this paper, we present a new scheme for safety message scheduling, called the enhanced message priority mechanism (EMPM). It consists of the following two components: the benefit-value algorithm, which calculates the priority of the messages depending on the speed, deceleration, and message lifetime; and the back-off counter selection algorithm, which chooses the non-uniform back-off counter value in order to reduce the collision probability and to enhance the throughput of the highly beneficial messages. Numerical results show that the EMPM can significantly improve the throughput and delay of messages with high benefits when compared with existing MAC protocols. Consequently, the EMPM can provide better QoS support for the more important and urgent messages.','10.3745/JIPS.03.0027',332,120,0,33,'2015-03-25',NULL),(80033,0,0,0,0,0,'A Survey on the Detection of SQL Injection Attacks and Their Countermeasures','Dynamic Analysis, Detection, Prevention, SQL Injection Attack, Static Analysis, Vulnerabilities','Bharti Nagpal, Naresh Chauhan, and Nanhay Singh','dlibrary/JIPS_OF_paper34.pdf','The Structured Query Language (SQL) Injection continues to be one of greatest security risks in the world according to the Open Web Application Security Project’s (OWASP)[1] Top 10 Security vulnerabilities 2013. The ease of exploitability and severe impact puts this attack at the top. As the countermeasures become more sophisticated, SOL Injection Attacks also continue to evolve, thus thwarting the attempt to eliminate this attack completely. The vulnerable data is a source of worry for government and financial institutions. In this paper, a detailed survey of different types of SQL Injection and proposed methods and theories are presented, along with various tools and their efficiency in intercepting and preventing SQL attacks.','10.3745/JIPS.03.0024',304,249,0,34,'2015-04-20',NULL),(80034,0,0,0,0,0,'Learning to Prevent Inactive Student of Indonesia Open University','Educational Data Mining, Ensemble Techniques, Inactive Student, Open University','Bayu Adhi Tama','dlibrary/JIPS_OF_paper35.pdf','The inactive student rate is becoming a major problem in most open universities worldwide. In Indonesia, roughly 36% of students were found to be inactive, in 2005. Data mining had been successfully employed to solve problems in many domains, such as for educational purposes. We are proposing a method for preventing inactive students by mining knowledge from student record systems with several state of the art ensemble methods, such as Bagging, AdaBoost, Random Subspace, Random Forest, and Rotation Forest. The most influential attributes, as well as demographic attributes (marital status and employment), were successfully obtained which were affecting student of being inactive. The complexity and accuracy of classification techniques were also compared and the experimental results show that Rotation Forest, with decision tree as the base-classifier, denotes the best performance compared to other classifiers.','10.3745/JIPS.04.0015',295,91,0,35,'2015-04-20',NULL),(80035,0,0,0,0,0,'An Adaptive Superframe Duration Allocation Algorithm for Resource-Efficient Beacon Scheduling','Beacon Scheduling, Energy Efficient, IEEE802.15.4, IEEE802.15.4e, LR-WPAN, Superframe Duration Allocation','Young-Ae Jeon, Sang-Sung Choi, Dae-Young Kim, and Kwang-il Hwang','dlibrary/JIPS_OF_paper36.pdf','Beacon scheduling is considered to be one of the most significant challenges for energy-efficient Low-Rate Wireless Personal Area Network (LR-WPAN) multi-hop networks. The emerging new standard, IEEE802.15.4e, contains a distributed beacon scheduling functionality that utilizes a specific bitmap and multi-superframe structure. However, this new standard does not provide a critical recipe for superframe duration (SD) allocation in beacon scheduling. Therefore, in this paper, we first introduce three different SD allocation approaches, LSB first, MSB first, and random. Via experiments we show that IEEE802.15.4e DSME beacon scheduling performs differently for different SD allocation schemes. Based on our experimental results we propose an adaptive SD allocation (ASDA) algorithm. It utilizes a single indicator, a distributed neighboring slot incrementer (DNSI). The experimental results demonstrate that the ASDA has a superior performance over other methods from the viewpoint of resource efficiency.','10.3745/JIPS.03.0025',279,191,0,36,'2015-04-20',NULL),(80036,0,0,0,0,0,'A Virtual Laboratory to Practice Mobile Wireless Sensor Networks: A Case Study on Energy Efficient and Safe Weighted Clustering Algorithm','Clustering, Energy Efficiency, Practical Work, Security Attacks, Virtual labs, Wireless Sensor Networks','Amine Dahane, Nasr-Eddine Berrached, and Abdelhamid Loukil','dlibrary/JIPS_OF_paper37.pdf','In this paper, we present a virtual laboratory platform (VLP) baptized Mercury allowing students to make practical work (PW) on different aspects of mobile wireless sensor networks (WSNs). Our choice of WSNs is motivated mainly by the use of real experiments needed in most courses about WSNs. These experiments require an expensive investment and a lot of nodes in the classroom. To illustrate our study, we propose a course related to energy efficient and safe weighted clustering algorithm. This algorithm which is coupled with suitable routing protocols, aims to maintain stable clustering structure, to prevent most routing attacks on sensor networks, to guaranty energy saving in order to extend the lifespan of the network. It also offers a better performance in terms of the number of re-affiliations. The platform presented here aims at showing the feasibility, the flexibility and the reduced cost of such a realization. We demonstrate the performance of the proposed algorithms that contribute to the familiarization of the learners in the field of WSNs.','10.3745/JIPS.02.0019',487,158,0,37,'2015-04-20',NULL),(80037,0,0,0,0,0,'WebSHArk 1.0: A Benchmark Collection for Malicious Web Shell Detection','Benchmark Test Collection, Malicious Web Application, Webshell, Web Shell Collection, Web Shell Detection','Jinsuk Kim, Dong-Hoon Yoo, Heejin Jang, and Kimoon Jeong','dlibrary/JIPS_OF_paper38.pdf','Web shells are programs that are written for a specific purpose in Web scripting languages, such as PHP, ASP, ASP.NET, JSP, PERL-CGI, etc. Web shells provide a means to communicate with the server’s operating system via the interpreter of the web scripting languages. Hence, web shells can execute OS specific commands over HTTP. Usually, web attacks by malicious users are made by uploading one of these web shells to compromise the target web servers. Though there have been several approaches to detect such malicious web shells, no standard dataset has been built to compare various web shell detection techniques. In this paper, we present a collection of web shell files, WebSHArk 1.0, as a standard dataset for current and future studies in malicious web shell detection. To provide baseline results for future studies and for the improvement of current tools, we also present some benchmark results by scanning the WebSHArk dataset directory with three web shell scanning tools that are publicly available on the Internet. The WebSHArk 1.0 dataset is only available upon request via email to one of the authors, due to security and legal issues.','10.3745/JIPS.03.0026',319,368,0,38,'2015-04-20',NULL),(80038,0,0,0,0,0,'Fuzzy-Membership Based Writer Identification from Handwritten Devnagari Script','CPAR-2012, Devnagari, Fuzzy Membership, Handwritten Script, Writer Identification','Rajiv Kumar, Kiran Kumar Ravulakollu, and Rajesh Bhat','dlibrary/JIPS_OF_paper39.pdf','The handwriting based person identification systems use their designer’s perceived structural properties of handwriting as features. In this paper, we present a system that uses those structural properties as features that graphologists and expert handwriting analyzers use for determining the writer’s personality traits and for making other assessments. The advantage of these features is that their definition is based on sound historical knowledge (i.e., the knowledge discovered by graphologists, psychiatrists, forensic experts, and experts of other domains in analyzing the relationships between handwritten stroke characteristics and the phenomena that imbeds individuality in stroke). Hence, each stroke characteristic reflects a personality trait. We have measured the effectiveness of these features on a subset of handwritten Devnagari and Latin script datasets from the Center for Pattern Analysis and Recognition (CPAR-2012), which were written by 100 people where each person wrote three samples of the Devnagari and Latin text that we have designed for our experiments. The experiment yielded 100% correct identification on the training set. However, we observed an 88% and 89% correct identification rate when we experimented with 200 training samples and 100 test samples on handwritten Devnagari and Latin text. By introducing the majority voting based rejection criteria, the identification accuracy increased to 97% on both script sets.','10.3745/JIPS.02.0018',316,123,0,39,'2015-04-20',NULL),(80039,0,0,0,0,0,'Fingerprint Matching Based on Dimension Reduced DCT Feature Vectors','Biometric, Discrete Cosine Transform, Fingerprint Identification, Similarity Measure','Sangita Bharkad and Manesh Kokare','dlibrary/JIPS_OF_paper40.pdf','In this work a Discrete Cosine Transform (DCT)-based feature dimensionality reduced approach for fingerprint matching is proposed. The DCT is applied on a small region around the core point of fingerprint image. The performance of our proposed method is evaluated on a small database of Bologna University and two large databases of FVC2000. A dimensionally reduced feature vector is formed using only approximately 19%, 7%, and 6% DCT coefficients for the three databases from Bologna University and FVC2000, respectively. We compared the results of our proposed method with the discrete wavelet transform (DWT) method, the rotated wavelet filters (RWFs) method, and a combination of DWT+RWF and DWT+(HL+LH) subbands of RWF. The proposed method reduces the false acceptance rate from approximately 18% to 4% on DB1 (Database of Bologna University), approximately 29% to 16% on DB2 (FVC2000), and approximately 26% to 17% on DB3 (FVC2000) over the DWT based feature extraction method.','10.3745/JIPS.02.0017',270,124,0,40,'2015-04-28',NULL),(80040,0,0,0,0,0,'A Robust Fingerprint Matching System Using Orientation Features','Circular ROI, Core Point Detection, Image-Based Fingerprint Matching, Orientation Features','Ravinder Kumar, Pravin Chandra, and Madasu Hanmandlu','dlibrary/JIPS_OF_paper41.pdf','The latest research on the image-based fingerprint matching approaches indicates that they are less complex than the minutiae-based approaches when it comes to dealing with low quality images. Most of the approaches in the literature are not robust to fingerprint rotation and translation. In this paper, we develop a robust fingerprint matching system by extracting the circular region of interest (ROI) of a radius of 50 pixels centered at the core point. Maximizing their orientation correlation aligns two fingerprints that are to be matched. The modified Euclidean distance computed between the extracted orientation features of the sample and query images is used for matching. Extensive experiments were conducted over four benchmark fingerprint datasets of FVC2002 and two other proprietary databases of RFVC 2002 and the AITDB. The experimental results show the superiority of our proposed method over the well-known image-based approaches in the literature.','10.3745/JIPS.02.0020',220,131,0,41,'2015-05-21',NULL),(80041,0,0,0,0,0,'Sparse Channel Estimation of Single Carrier Frequency Division Multiple Access Based on Compressive Sensing','Compressive Sensing, Random Pilot Pattern, SC-FDMA, Sparse Channel Estimation','Yuan-Hong Zhong, Zhi-Yong Huang, Bin Zhu, and Hua Wu','dlibrary/JIPS_OF_paper42.pdf','It is widely accepted that single carrier frequency division multiple access (SC-FDMA) is an excellent candidate for broadband wireless systems. Channel estimation is one of the key challenges in SC-FDMA, since accurate channel estimation can significantly improve equalization at the receiver and, consequently, enhance the communication performances. In this paper, we study the application of compressive sensing for sparse channel estimation in a SC-FDMA system. By skillfully designing pilots, their patterns, and taking advantages of the sparsity of the channel impulse response, the proposed system realizes channel estimation at a low cost. Simulation results show that it can achieve significantly improved performance in a frequency selective fading sparse channel with fewer pilots.','10.3745/JIPS.03.0028',225,168,0,42,'2015-05-21',NULL),(80042,0,0,0,0,0,'CLB-ECC: Certificateless Blind Signature Using ECC','Authentication, Blind Signature, Certificateless Cryptography, Elliptic Curve Cryptography, E-cash','Sanjeet Kumar Nayak, Sujata Mohanty, and Banshidhar Majhi','dlibrary/JIPS_OF_paper43.pdf','Certificateless public key cryptography (CL-PKC) is a new benchmark in modern cryptography. It not only simplifies the certificate management problem of PKC, but also avoids the key escrow problem of the identity based cryptosystem (ID-PKC). In this article, we propose a certificateless blind signature protocol which is based on elliptic curve cryptography (CLB-ECC). The scheme is suitable for the wireless communication environment because of smaller parameter size. The proposed scheme is proven to be secure against attacks by two different kinds of adversaries. CLB-ECC is efficient in terms of computation compared to the other existing conventional schemes. CLB-ECC can withstand forgery attack, key only attack, and known message attack. An e-cash framework, which is based on CLB-ECC, has also been proposed. As a result, the proposed CLB-ECC scheme seems to be more effective for applying to real life applications like e-shopping, e-voting, etc., in handheld devices.','10.3745/JIPS.03.0029',255,127,0,43,'2015-05-21',NULL),(80043,0,0,0,0,0,'Counter Chain: A New Block Cipher Mode of Operation','Authentication, Block Cipher Mode, Confidentiality, Counter Mode, Counter Chain','Aly Mohamed El-Semary, and Mohamed Mostafa A. Azim. ','dlibrary/JIPS_OF_paper44.pdf','In this paper, we propose a novel block cipher mode of operation, which is known as the counter chain (CC) mode. The proposed CC mode integrates the cipher block chaining (CBC) block cipher mode of operation with the counter (CTR) mode in a consistent fashion. In the CC mode, the confidentiality and authenticity of data are assured by the CBC mode, while speed is achieved through the CTR mode. The proposed mode of operation overcomes the parallelization deficiency of the CBC mode and the chaining dependency of the counter mode. Experimental results indicate that the proposed CC mode achieves the encryption speed of the CTR mode, which is exceptionally faster than the encryption speed of the CBC mode. Moreover, our proposed CC mode provides better security over the CBC mode. In summary, the proposed CC block cipher mode of operation takes the advantages of both the Counter mode and the CBC mode, while avoiding their shortcomings.','10.3745/JIPS.03.0031',322,108,0,44,'2015-05-21',NULL),(80044,0,0,0,0,0,'Robust and Reversible Image Watermarking Scheme Using Combined DCT-DWT-SVD Transforms','Image Security, Image Watermarking, Reversible DWT-DCT-SVD Transform','Souad Bekkouch and Kamel Mohamed Faraoun','dlibrary/JIPS_OF_paper45.pdf','We present a secure and robust image watermarking scheme that uses combined reversible DWT-DCT-SVD transformations to increase integrity, authentication, and confidentiality. The proposed scheme uses two different kinds of watermarking images: a reversible watermark, W1, which is used for verification (ensuring integrity and authentication aspects); and a second one, W2, which is defined by a logo image that provides confidentiality. Our proposed scheme is shown to be robust, while its performances are evaluated with respect to the peak signal-to-noise ratio (PSNR), signal-to-noise ratio (SNR), normalized cross-correlation (NCC), and running time. The robustness of the scheme is also evaluated against different attacks, including a compression attack and Salt & Pepper attack.','10.3745/JIPS.02.0021',271,97,0,45,'2015-06-02',NULL),(80045,0,0,0,0,0,'An Improved Cat Swarm Optimization Algorithm Based on Opposition-Based Learning and Cauchy Operator for Clustering','Cat Swarm Optimization, Cauchy Mutation Operator, Clustering, Opposition-Based Learning, Particle Swarm Optimization','Yugal Kumar and G. Sahoo','dlibrary/JIPS_OF_paper46.pdf','Clustering is a NP-hard problem that is used to find the relationship between patterns in a given set of patterns. It is an unsupervised technique that is applied to obtain the optimal cluster centers, especially in partitioned based clustering algorithms. On the other hand, cat swarm optimization (CSO) is a new meta- heuristic algorithm that has been applied to solve various optimization problems and it provides better results in comparison to other similar types of algorithms. However, this algorithm suffers from diversity and local optima problems. To overcome these problems, we are proposing an improved version of the CSO algorithm by using opposition-based learning and the Cauchy mutation operator. We applied the opposition-based learning method to enhance the diversity of the CSO algorithm and we used the Cauchy mutation operator to prevent the CSO algorithm from trapping in local optima. The performance of our proposed algorithm was tested with several artificial and real datasets and compared with existing methods like K-means, particle swarm optimization, and CSO. The experimental results show the applicability of our proposed method.','10.3745/JIPS.02.0022',201,120,0,46,'2015-06-02',NULL),(80046,0,0,0,0,0,'Improved Dynamic Subjective Logic Model with Evidence Driven','Dynamic Weight, Evidence Driven, Subjective Logic','Jiao-Hong Qiang, Wang-Xin Xin, and Tian-Jun Feng','dlibrary/JIPS_OF_paper47.pdf','In Jøsang’s subjective logic, the fusion operator is not able to fuse three or more opinions at a time and it cannot consider the effect of time factors on fusion. Also, the base rate (a) and non-informative prior weight (C) could not change dynamically. In this paper, we propose an Improved Subjective Logic Model with Evidence Driven (ISLM-ED) that expands and enriches the subjective logic theory. It includes the multi-agent unified fusion operator and the dynamic function for the base rate (a) and the non-informative prior weight (C) through the changes in evidence. The multi-agent unified fusion operator not only meets the commutative and associative law but is also consistent with the researchers’s cognitive rules. A strict mathematical proof was given by this paper. Finally, through the simulation experiments, the results show that the ISLM-ED is more reasonable and effective and that it can be better adapted to the changing environment.','10.3745/JIPS.03.0030',225,87,0,47,'2015-06-02',NULL),(80047,0,0,0,0,0,'A Lightweight and Effective Music Score Recognition on Mobile Phones','Mobile Camera, Music Score, SVM, Symbol Classification','Tam Nguyen and Gueesang Lee','dlibrary/JIPS_OF_paper48.pdf','Recognition systems for scanned or printed music scores that have been implemented on personal computers have received attention from numerous scientists and have achieved significant results over many years. A modern trend with music scores being captured and played directly on mobile devices has become more interesting to researchers. The limitation of resources and the effects of illumination, distortion, and inclination on input images are still challenges to these recognition systems. In this paper, we introduce a novel approach for recognizing music scores captured by mobile cameras. To reduce the complexity, as well as the computational time of the system, we grouped all of the symbols extracted from music scores into ten main classes. We then applied each major class to SVM to classify the musical symbols separately. The experimental results showed that our proposed method could be applied to real time applications and that its performance is competitive with other methods.','10.3745/JIPS.02.0023',172,76,0,48,'2015-07-08',NULL),(80048,0,0,0,0,0,'Using Mobile Data Collectors to Enhance Energy Efficiency and Reliability in Delay Tolerant Wireless Sensor Networks','Data Collection, MDCs, Mobility Model, Mobile Relay, Mobile Sink, Simulation, WSNs','Yasmine-Derdour, Bouabdellah-Kechar, and Mohammed Fayçal-Khelfi','dlibrary/JIPS_OF_paper49.pdf','A primary task in wireless sensor networks (WSNs) is data collection. The main objective of this task is to collect sensor readings from sensor fields at predetermined sinks using routing protocols without conducting network processing at intermediate nodes, which have been proved as being inefficient in many research studies using a static sink. The major drawback is that sensor nodes near a data sink are prone to dissipate more energy power than those far away due to their role as relay nodes. Recently, novel WSN architectures based on mobile sinks and mobile relay nodes, which are able to move inside the region of a deployed WSN, which has been developed in most research works related to mobile WSN mainly exploit mobility to reduce and balance energy consumption to enhance communication reliability among sensor nodes. Our main purpose in this paper is to propose a solution to the problem of deploying mobile data collectors for alleviating the high traffic load and resulting bottleneck in a sink’s vicinity, which are caused by static approaches. For this reason, several WSNs based on mobile elements have been proposed. We studied two key issues in WSN mobility: the impact of the mobile element (sink or relay nodes) and the impact of the mobility model on WSN based on its performance expressed in terms of energy efficiency and reliability. We conducted an extensive set of simulation experiments. The results obtained reveal that the collection approach based on relay nodes and the mobility model based on stochastic perform better.','10.3745/JIPS.03.0032',167,69,0,49,'2015-07-31',NULL),(80049,0,0,0,0,0,'A Joint Channel Estimation and Data Detection for a MIMO Wireless Communication System via Sphere Decoding','Maximum Likelihood Decoding, Multiple Input Multiple Output, Normalized Mean Square Error,\rTraining Based Channel Estimation, Semi-Blind Channel Estimation, Spatial Multiplexing, Sphere Decoding','Gajanan R. Patil and Vishwanath K. Kokate','dlibrary/JIPS_OF_paper50.pdf','A joint channel estimation and data detection technique for a multiple input multiple output (MIMO) wireless communication system is proposed. It combines the least square (LS) training based channel estimation (TBCE) scheme with sphere decoding. In this new approach, channel estimation is enhanced with the help of blind symbols, which are selected based on their correctness. The correctness is determined via sphere decoding. The performance of the new scheme is studied through simulation in terms of the bit error rate (BER). The results show that the proposed channel estimation has comparable performance and better computational complexity over the existing semi-blind channel estimation (SBCE) method.','10.3745/JIPS.03.0033',149,60,0,50,'2015-07-31',NULL),(80050,0,0,0,0,0,'Combination of Classifiers Decisions for Multilingual Speaker Identification','Classifier Combination, Cross-lingual, Monolingual, Multilingual, Speaker Identification','B. G. Nagaraja and H. S. Jayanna','dlibrary/JIPS_OF_paper51.pdf','State-of-the-art speaker recognition systems may work better for the English language. However, if the same system is used for recognizing those who speak different languages, the systems may yield a poor performance. In this work, the decisions of a Gaussian mixture model-universal background model (GMM- UBM) and a learning vector quantization (LVQ) are combined to improve the recognition performance of a multilingual speaker identification system. The difference between these classifiers is in their modeling techniques. The former one is based on probabilistic approach and the latter one is based on the fine-tuning of neurons. Since the approaches are different, each modeling technique identifies different sets of speakers for the same database set. Therefore, the decisions of the classifiers may be used to improve the performance. In this study, multitaper mel-frequency cepstral coefficients (MFCCs) are used as the features and the monolingual and cross-lingual speaker identification studies are conducted using NIST-2003 and our own database. The experimental results show that the combined system improves the performance by nearly 10% compared with that of the individual classifier.','10.3745/JIPS.02.0025',127,59,0,51,'2015-08-10',NULL),(80051,0,0,0,0,0,'Detection of Microcalcification Using the Wavelet Based Adaptive Sigmoid Function and Neural Network','Cascade-Forward Back Propagation Technique, Computer-Aided Diagnosis (CAD), Contrast Limited Adaptive Histogram Equalization (CLAHE), Gray-Level Co-Occurrence Matrix (GLCM), Mammographic Image Analysis Society (MIAS) Database, Modified Sigmoid Function','Sanjeev Kumar and Mahesh Chandra','dlibrary/JIPS_OF_paper52.pdf','Mammogram images are sensitive in nature and even a minor change in the environment affects the quality of the images. Due to the lack of expert radiologists, it is difficult to interpret the mammogram images. In this paper an algorithm is proposed for a computer-aided diagnosis system, which is based on the wavelet based adaptive sigmoid function. The cascade feed-forward back propagation technique has been used for training and testing purposes. Due to the poor contrast in digital mammogram images it is difficult to process the images directly. Thus, the images were first processed using the wavelet based adaptive sigmoid function and then the suspicious regions were selected to extract the features. A combination of texture features and gray- level co-occurrence matrix features were extracted and used for training and testing purposes. The system was trained with 150 images, while a total 100 mammogram images were used for testing. A classification accuracy of more than 95% was obtained with our proposed method.','10.3745/JIPS.01.0007',130,57,0,52,'2015-08-10',NULL),(80052,0,0,0,0,0,'A Column-Aware Index Management Using Flash Memory for Read-Intensive Databases','Column-Aware Index Management, Column-Oriented Databases, Flash Memory Storage, Game Database, Network Database','Si-Woo Byun and Seok-Woo Jang','dlibrary/JIPS_OF_paper53.pdf','Most traditional database systems exploit a record-oriented model where the attributes of a record are placed contiguously in a hard disk to achieve high performance writes. However, for read-mostly data warehouse systems, the column-oriented database has become a proper model because of its superior read performance. Today, flash memory is largely recognized as the preferred storage media for high-speed database systems. In this paper, we introduce a column-oriented database model based on flash memory and then propose a new column-aware flash indexing scheme for the high-speed column-oriented data warehouse systems. Our index management scheme, which uses an enhanced B+-Tree, achieves superior search performance by indexing an embedded segment and packing an unused space in internal and leaf nodes. Based on the performance results of two test databases, we concluded that the column-aware flash index management outperforms the traditional scheme in the respect of the mixed operation throughput and its response time.','10.3745/JIPS.04.0017',148,63,0,53,'2015-08-10',NULL),(80053,0,0,0,0,0,'Text Detection in Scene Images Based on Interest Points','Connected Component, Interest Point, Tensor Voting, Text Detection','Minh Hieu Nguyen and Gueesang Lee','dlibrary/JIPS_OF_paper54.pdf','Text in images is one of the most important cues for understanding a scene. In this paper, we propose a novel approach based on interest points to localize text in natural scene images. The main ideas of this approach are as follows: first we used interest point detection techniques, which extract the corner points of characters and center points of edge connected components, to select candidate regions. Second, these candidate regions were verified by using tensor voting, which is capable of extracting perceptual structures from noisy data. Finally, area, orientation, and aspect ratio were used to filter out non-text regions. The proposed method was tested on the ICDAR 2003 dataset and images of wine labels. The experiment results show the validity of this approach.','10.3745/JIPS.02.0026',131,69,0,54,'2015-08-10',NULL),(80054,0,0,0,0,0,'Simple Pyramid RAM-Based Neural Network Architecture for Localization of Swarm Robots','Localization Process, RAM-Based Neural Network, Swarm Robots','Siti Nurmaini and Ahmad Zarkasi','dlibrary/JIPS_OF_paper55.pdf','The localization of multi-agents, such as people, animals, or robots, is a requirement to accomplish several tasks. Especially in the case of multi-robotic applications, localization is the process for determining the positions of robots and targets in an unknown environment. Many sensors like GPS, lasers, and cameras are utilized in the localization process. However, these sensors produce a large amount of computational resources to process complex algorithms, because the process requires environmental mapping. Currently, combination multi-robots or swarm robots and sensor networks, as mobile sensor nodes have been widely available in indoor and outdoor environments. They allow for a type of efficient global localization that demands a relatively low amount of computational resources and for the independence of specific environmental features. However, the inherent instability in the wireless signal does not allow for it to be directly used for very accurate position estimations and making difficulty associated with conducting the localization processes of swarm robotics system. Furthermore, these swarm systems are usually highly decentralized, which makes it hard to synthesize and access global maps, it can be decrease its flexibility. In this paper, a simple pyramid RAM-based Neural Network architecture is proposed to improve the localization process of mobile sensor nodes in indoor environments. Our approach uses the capabilities of learning and generalization to reduce the effect of incorrect information and increases the accuracy of the agent’s position. The results show that by using simple pyramid RAM-base Neural Network approach, produces low computational resources, a fast response for processing every changing in environmental situation and mobile sensor nodes have the ability to finish several tasks especially in localization processes in real time.','10.3745/JIPS.01.0008',173,69,0,55,'2015-08-10',NULL),(80055,0,0,0,0,0,'Rotational Wireless Video Sensor Networks with Obstacle Avoidance Capability for Improving Disaster Area Coverage','Coverage, Fault Tolerance, Field of View, Obstacles Avoidance, Scheduling, Simulation, Wireless Video Sensor Networks','Nawel Bendimerad and Bouabdellah Kechar','dlibrary/JIPS_OF_paper56.pdf','Wireless Video Sensor Networks (WVSNs) have become a leading solution in many important applications, such as disaster recovery. By using WVSNs in disaster scenarios, the main goal is achieving a successful immediate response including search, location, and rescue operations. The achievement of such an objective in the presence of obstacles and the risk of sensor damage being caused by disasters is a challenging task. In this paper, we propose a fault tolerance model of WVSN for efficient post-disaster management in order to assist rescue and preparedness operations. To get an overview of the monitored area, we used video sensors with a rotation capability that enables them to switch to the best direction for getting better multimedia coverage of the disaster area, while minimizing the effect of occlusions. By constructing different cover sets based on the field of view redundancy, we can provide a robust fault tolerance to the network. We demonstrate by simulating the benefits of our proposal in terms of reliability and high coverage.','10.3745/JIPS.03.0034',155,80,0,56,'2015-08-17',NULL),(80056,0,0,0,0,0,'Viewpoint Unconstrained Face Recognition Based on Affine Local Descriptors and Probabilistic Similarity','Affine Scale Invariant Feature Transform, Face Recognition, Probabilistic Similarity','Yongbin Gao and Hyo Jong Lee.','dlibrary/JIPS_OF_paper57.pdf','Face recognition under controlled settings, such as limited viewpoint and illumination change, can achieve good performance nowadays. However, real world application for face recognition is still challenging. In this paper, we propose using the combination of Affine Scale Invariant Feature Transform (SIFT) and Probabilistic Similarity for face recognition under a large viewpoint change. Affine SIFT is an extension of SIFT algorithm to detect affine invariant local descriptors. Affine SIFT generates a series of different viewpoints using affine transformation. In this way, it allows for a viewpoint difference between the gallery face and probe face. However, the human face is not planar as it contains significant 3D depth. Affine SIFT does not work well for significant change in pose. To complement this, we combined it with probabilistic similarity, which gets the log likelihood between the probe and gallery face based on sum of squared difference (SSD) distribution in an offline learning process. Our experiment results show that our framework achieves impressive better recognition accuracy than other algorithms compared on the FERET database.','10.3745/JIPS.02.0027',115,58,0,57,'2015-08-17',NULL),(80057,0,0,0,0,0,'Test Set Generation for Pairwise Testing Using Genetic Algorithms','Combinatorial Testing, Genetic Algorithm, Mixed Covering Arrays, Pairwise Testing, Test Set, t-way Testing','Sangeeta Sabharwal and Manuj Aggarwal','dlibrary/JIPS_OF_paper58.pdf','In software systems, it has been observed that a fault is often caused by an interaction between a small number of input parameters. Even for moderately sized software systems, exhaustive testing is practically impossible to achieve. This is either due to time or cost constraints. Combinatorial (t-way) testing provides a technique to select a subset of exhaustive test cases covering all of the t-way interactions, without much of a loss to the fault detection capability. In this paper, an approach is proposed to generate 2-way (pairwise) test sets using genetic algorithms. The performance of the algorithm is improved by creating an initial solution using the overlap coefficient (a similarity matrix). Two mutation strategies have also been modified to improve their efficiency. Furthermore, the mutation operator is improved by using a combination of three mutation strategies. A comparative survey of the techniques to generate t-way test sets using genetic algorithms was also conducted. It has been shown experimentally that the proposed approach generates faster results by achieving higher percentage coverage in a fewer number of generations. Additionally, the size of the mixed covering arrays was reduced in one of the six benchmark problems examined.','10.3745/JIPS.04.0019',155,96,0,58,'2015-08-17',NULL),(80058,0,0,0,0,0,'Soft Set Theory Oriented Forecast Combination Method for Business Failure Prediction','Business Failure Prediction, Combined Forecasting Method, Qualitative Analysis, Quantitative Analysis, Receiver Operating Characteristic Curve, Soft Set Theory','Wei Xu and Zhi Xiao','dlibrary/JIPS_OF_paper59.pdf','This paper presents a new combined forecasting method that is guided by the soft set theory (CFBSS) to predict business failures with different sample sizes. The proposed method combines both qualitative analysis and quantitative analysis to improve forecasting performance. We considered an expert system (ES), logistic regression (LR), and support vector machine (SVM) as forecasting components whose weights are determined by the receiver operating characteristic (ROC) curve. The proposed procedure was applied to real data sets from Chinese listed firms. For performance comparison, single ES, LR, and SVM methods, the combined forecasting method based on equal weights (CFBEWs), the combined forecasting method based on neural networks (CFBNNs), and the combined forecasting method based on rough sets and the D-S theory (CFBRSDS) were also included in the empirical experiment. CFBSS obtains the highest forecasting accuracy and the second-best forecasting stability. The empirical results demonstrate the superior forecasting performance of our method in terms of accuracy and stability.','10.3745/JIPS.04.0016',130,76,0,59,'2015-08-17',NULL),(80059,0,0,0,0,0,'Word Similarity Calculation by Using the Edit Distance Metrics with Consonant Normalization','Consonant Normalization, Edit Distance, Korean Character, Normalization Factor','Seung-Shik Kang','dlibrary/JIPS_OF_paper60.pdf','Edit distance metrics are widely used for many applications such as string comparison and spelling error corrections. Hamming distance is a metric for two equal length strings and Damerau-Levenshtein distance is a well-known metrics for making spelling corrections through string-to-string comparison. Previous distance metrics seems to be appropriate for alphabetic languages like English and European languages. However, the conventional edit distance criterion is not the best method for agglutinative languages like Korean. The reason is that two or more letter units make a Korean character, which is called as a syllable. This mechanism of syllable-based word construction in the Korean language causes an edit distance calculation to be inefficient. As such, we have explored a new edit distance method by using consonant normalization and the normalization factor.','10.3745/JIPS.04.0018',187,118,0,60,'2015-08-17',NULL),(80060,0,0,0,0,0,'X-Ray Image Enhancement Using a Boundary Division Wiener Filter and Wavelet-Based Image Fusion Approach','Image Enhancement, Image Fusion, Poisson/Impulse Noise, Sharpening, Wavelet Transform','Sajid Ullah Khan, Wang Yin Chai, Chai Soo See, and Amjad Khan','dlibrary/JIPS_OF_paper61.pdf','To resolve the problems of Poisson/impulse noise, blurriness, and sharpness in degraded X-ray images, a novel and efficient enhancement algorithm based on X-ray image fusion using a discrete wavelet transform is proposed in this paper. The proposed algorithm consists of two basics. First, it applies the techniques of boundary division to detect Poisson and impulse noise corrupted pixels and then uses the Wiener filter approach to restore those corrupted pixels. Second, it applies the sharpening technique to the same degraded X-ray image. Thus, it has two source X-ray images, which individually preserve the enhancement effects. The details and approximations of these sources X-ray images are fused via different fusion rules in the wavelet domain. The results of the experiment show that the proposed algorithm successfully combines the merits of the Wiener filter and sharpening and achieves a significant proficiency in the enhancement of degraded X-ray images exhibiting Poisson noise, blurriness, and edge details.','10.3745/JIPS.02.0029',91,49,0,61,'2015-11-11',NULL),(80061,0,0,0,0,0,'Inter-Domain Mobility Management Based on the Proxy Mobile IP in Mobile Networks','Comparison, HIP, LTE, LISP, MIP, Mobility Management, PMIP, SAE','Moneeb Gohar and Seok-Joo Koh','dlibrary/JIPS_OF_paper62.pdf','System Architecture Evolution (SAE) with Long Term Evolution (LTE) has been used as the key technology for the next generation mobile networks. To support mobility in the LTE/SAE-based mobile networks, the Proxy Mobile IPv6 (PMIP), in which the Mobile Access Gateway (MAG) of the PMIP is deployed at the Serving Gateway (S-GW) of LTE/SAE and the Local Mobility Anchor (LMA) of PMIP is employed at the PDN Gateway (P-GW) of LTE/SAE, is being considered. In the meantime, the Host Identity Protocol (HIP) and the Locator Identifier Separation Protocol (LISP) have recently been proposed with the identifier-locator separation principle, and they can be used for mobility management over the global-scale networks. In this paper, we discuss how to provide the inter-domain mobility management over PMIP-based LTE/SAE networks by investigating three possible scenarios: mobile IP with PMIP (denoted by MIP-PMIP-LTE/SAE), HIP with PMIP (denoted by HIP-PMIP-LTE/SAE), and LISP with PMIP (denoted by LISP-PMIP-LTE/SAE). For performance analysis of the candidate inter-domain mobility management schemes, we analyzed the traffic overhead at a central agent and the total transmission delay required for control and data packet delivery. From the numerical results, we can see that HIP-PMIP-LTE/SAE and LISP-PMIP-LTE/SAE are preferred to MIP-PMIP-LTE/SAE in terms of traffic overhead; whereas, LISP-PMIP-LTE/SAE is preferred to HIP-PMIP-LTE/SAE and MIP-PMIP-LTE/SAE in the viewpoint of total transmission delay.','10.3745/JIPS.03.0037',38,20,0,62,'2015-11-30',NULL),(80062,0,0,0,0,0,'IDMMAC: Interference Aware Distributed Multi-Channel MAC Protocol for WSAN','Actor, BCH, IDMMAC, Interference, Multichannel, PRR','Jagadeesh Kakarla, Banshidhar Majhi, and Ramesh Babu Battula','dlibrary/JIPS_OF_paper63.pdf','In this paper, an interference aware distributed multi-channel MAC (IDMMAC) protocol is proposed for wireless sensor and actor networks (WSANs). The WSAN consists of a huge number of sensors and ample amount of actors. Hence, in the IDMMAC protocol a lightweight channel selection mechanism is proposed to enhance the sensor\'s lifetime. The IDMMAC protocol divides the beacon interval into two phases (i.e., the ad- hoc traffic indication message (ATIM) window phase and data transmission phase). When a sensor wants to transmit event information to the actor, it negotiates the maximum packet reception ratio (PRR) and the capacity channel in the ATIM window with its 1-hop sensors. The channel negotiation takes place via a control channel. To improve the packet delivery ratio of the IDMMAC protocol, each actor selects a backup cluster head (BCH) from its cluster members. The BCH is elected based on its residual energy and node degree. The BCH selection phase takes place whenever an actor wants to perform actions in the event area or it leaves the cluster to help a neighbor actor. Furthermore, an interference and throughput aware multi- channel MAC protocol is also proposed for actor-actor coordination. An actor selects a minimum interference and maximum throughput channel among the available channels to communicate with the destination actor. The performance of the proposed IDMMAC protocol is analyzed using standard network parameters, such as packet delivery ratio, end-to-end delay, and energy dissipation, in the network. The obtained simulation results indicate that the IDMMAC protocol performs well compared to the existing MAC protocols.','10.3745/JIPS.03.0038',42,19,0,63,'2015-11-30',NULL),(80063,0,0,0,0,0,'Spatial Interpolation and Assimilation Methods for Satellite and Ground Meteorological Data in Vietnam','Assimilation, Interpolation, Meteorological Variables, Kriging, Vietnam','Khac Phong Do, Ba Tung Nguyen, Xuan Thanh Nguyen, Quang Hung Bui, Nguyen Le Tran, Thi Nhat Thanh Nguyen, Van Quynh Vuong, Huy Lai Nguyen, and Thanh Ha Le','dlibrary/JIPS_OF_paper64.pdf','This paper presents the applications of spatial interpolation and assimilation methods for satellite and ground meteorological data, including temperature, relative humidity, and precipitation in regions of Vietnam. In this work, Universal Kriging is used for spatially interpolating ground data and its interpolated results are assimilated with corresponding satellite data to anticipate better gridded data. The input meteorological data was collected from 98 ground weather stations located all over Vietnam; whereas, the satellite data consists of the MODIS Atmospheric Profiles product (MOD07), the ASTER Global Digital Elevation Map (ASTER DEM), and the Tropical Rainfall Measuring Mission (TRMM) in six years. The outputs are gridded fields of temperature, relative humidity, and precipitation. The empirical results were evaluated by using the Root mean square error (RMSE) and the mean percent error (MPE), which illustrate that Universal Kriging interpolation obtains higher accuracy than other forms of Kriging; whereas, the assimilation for precipitation gradually reduces RMSE and significantly MPE. It also reveals that the accuracy of temperature and humidity when employing assimilation that is not significantly improved because of low MODIS retrieval due to cloud contamination.','10.3745/JIPS.02.0030',35,13,0,64,'2015-12-07',NULL),(80064,0,0,0,0,0,'The Effect of Multiple Energy Detector on Evidence Theory Based Cooperative Spectrum Sensing Scheme for Cognitive Radio Networks','Cognitive Radio, Contention-Aware Reporting, Cooperative Spectrum Sensing, Evidence Theory (D-S Theory), Multiple Energy Detector, Sequential Data Fusion','Muhammad Sajjad Khan and Insoo Koo','dlibrary/JIPS_OF_paper65.pdf','Spectrum sensing is an essential function that enables cognitive radio technology to explore spectral holes and resourcefully access them without any harmful interference to the licenses user. Spectrum sensing done by a single node is highly affected by fading and shadowing. Thus, to overcome this, cooperative spectrum sensing was introduced. Currently, the advancements in multiple antennas have given a new dimension to cognitive radio research. In this paper, we propose a multiple energy detector for cooperative spectrum sensing schemes based on the evidence theory. Also, we propose a reporting mechanism for multiple energy detectors. With our proposed system, we show that a multiple energy detector using a cooperative spectrum sensing scheme based on evidence theory increases the reliability of the system, which ultimately increases the spectrum sensing and reduces the reporting time. Also in simulation results, we show the probability of error for the proposed system. Our simulation results show that our proposed system outperforms the conventional energy detector system.','10.3745/JIPS.03.0040',54,21,0,65,'2015-12-07',NULL),(80065,0,0,0,0,0,'Robust ROI Watermarking Scheme Based on Visual Cryptography: Application on Mammograms','Copyright Protection, Mammograms, Medical Image, Robust Watermarking, Visual Cryptography','Meryem Benyoussef, Samira Mabtoul, Mohamed El Marraki, and Driss Aboutajdine','dlibrary/JIPS_OF_paper66.pdf','Inthis paper, a novel robust medical images watermarking scheme is proposed. In traditional methods, the added watermark may alter the host medical image in an irreversible manner and may mask subtle details. Consequently, we propose a method for medical image copyright protection that may remedy this problem by embedding the watermark without modifying the original host image. The proposed method is based on the visual cryptography concept and the dominant blocks of wavelet coefficients. The logic in using the blocks dominants map is that local features, such as contours or edges, are unique to each image. The experimental results show that the proposed method can withstand several image processing attacks such as cropping, filtering, compression, etc.','10.3745/JIPS.02.0032',41,17,0,66,'2015-12-07',NULL),(80066,0,0,0,0,0,'SDN-Based Enterprise and Campus Networks: A Case of VLAN Management','Campus Network, Enterprise Network, OpenFlow, Software Defined Networking (SDN), VLAN Management','Van-Giang Nguyen and Young-Han Kim','dlibrary/JIPS_OF_paper67.pdf','The Virtual Local Area Network (VLAN) has been used for a long time in campus and enterprise networks as the most popular network virtualization solution. Due to the benefits and advantages achieved by using VLAN, network operators and administrators have been using it for constructing their networks up until now and have even extended it to manage the networking in a cloud computing system. However, their configuration is a complex, tedious, time-consuming, and error-prone process. Since Software Defined Networking (SDN) features the centralized network management and network programmability, it is a promising solution for handling the aforementioned challenges in VLAN management. In this paper, we first introduce a new architecture for campus and enterprise networks by leveraging SDN and OpenFlow. Next, we have designed and implemented an application for easily managing and flexibly troubleshooting the VLANs in this architecture. This application supports both static VLAN and dynamic VLAN configurations. In addition, we discuss the hybrid-mode operation where the packet processing is involved by both the OpenFlow control plane and the traditional control plane. By deploying a real test-bed prototype, we illustrate how our system works and then evaluate the network latency in dynamic VLAN operation.','10.3745/JIPS.03.0039',34,20,0,67,'2015-12-07',NULL),(80067,0,0,0,0,0,'Image Restoration and Object Removal Using Prioritized Adaptive Patch-Based Inpainting in a Wavelet Domain','Image Inpainting, Object Removal, Region Filling, Texture and Structure Propagation, Wavelet Inpainting','Rajesh P. Borole and Sanjiv V. Bonde','dlibrary/JIPS_OF_paper68.pdf','Image restoration has been carried out by texture synthesis mostly for large regions and inpainting algorithms for small cracks in images. In this paper, we propose a new approach that allows for the simultaneous fill-in of different structures and textures by processing in a wavelet domain. A combination of structure inpainting and patch-based texture synthesis is carried out, which is known as patch-based inpainting, for filling and updating the target region. The wavelet transform is used for its very good multiresolution capabilities. The proposed algorithm uses the wavelet domain subbands to resolve the structure and texture components in smooth approximation and high frequency structural details. The subbands are processed separately by the prioritized patch-based inpainting with isophote energy driven texture synthesis at the core. The algorithm automatically estimates the wavelet coefficients of the target regions of various subbands using optimized patches from the surrounding DWT coefficients. The suggested performance improvement drastically improves execution speed over the existing algorithm. The proposed patch optimization strategy improves the quality of the fill. The fill-in is done with higher priority to structures and isophotes arriving at target boundaries. The effectiveness of the algorithm is demonstrated with natural and textured images with varying textural complexions.','10.3745/JIPS.02.0031',54,26,0,68,'2015-12-07',NULL),(80068,0,0,0,0,0,'An Experimental Implementation of a Cross-Layer Approach for Improving TCP Performance over Cognitive Radio Networks','Cognitive Radio Networks, Congestion Control, TCP, USRP','Sang-Seon Byun','dlibrary/JIPS_OF_paper69.pdf','In cognitive radio networks (CRNs), the performance of the transmission control protocol (TCP) at the secondary user (SU) severely drops due to the mistrigger of congestion control. A long disruption is caused by the transmission of primary user, leading to the mistrigger. In this paper, we propose a cross-layer approach, called a CR-aware scheme that enhances TCP performance at the SU. The scheme is a sender side addition to the standard TCP (i.e., TCP-NewReno), and utilizes an explicit cross-layer signal delivered from a physical (or link) layer and the signal gives an indication of detecting the primary transmission (i.e., transmission of the primary user). We evaluated our scheme by implementing it onto a software radio platform, the Universal Software Radio Peripheral (USRP), where many parts of lower layer operations (i.e., operations in a link or physical layer) run as user processes. In our implementation, we ran our CR-aware scheme over IEEE 802.15.4. Furthermore, for the purpose of comparison, we implemented a selective ACK-based local recovery scheme that helps TCP isolate congestive loss from a random loss in a wireless section.','10.3745/JIPS.03.0041',29,14,0,69,'2015-12-11',NULL),(80069,0,0,0,0,0,'Analysis of Semantic Relations Between Multimodal Medical Images Based on Coronary Anatomy for Acute Myocardial Infarction','Acute Myocardial Infarction, Coronary Anatomy, Coronary Angiography, Data Model, Echocardiography, Medical Images, Multimodality, Semantic Features','Yeseul Park, Meeyeon Lee, Myung-Hee Kim, and Jung-Won Lee','dlibrary/JIPS_OF_paper70.pdf','Acute myocardial infarction (AMI) is one of the three emergency diseases that require urgent diagnosis and treatment in the golden hour. It is important to identify the status of the coronary artery in AMI due to the nature of disease. Therefore, multi-modal medical images, which can effectively show the status of the coronary artery, have been widely used to diagnose AMI. However, the legacy system has provided multi- modal medical images with flat and unstructured data. It has a lack of semantic information between multi- modal images, which are distributed and stored individually. If we can see the status of the coronary artery all at once by integrating the core information extracted from multi-modal medical images, the time for diagnosis and treatment will be reduced. In this paper, we analyze semantic relations between multi-modal medical images based on coronary anatomy for AMI. First, we selected a coronary arteriogram, coronary angiography, and echocardiography as the representative medical images for AMI and extracted semantic features from them, respectively. We then analyzed the semantic relations between them and defined the convergence data model for AMI. As a result, we show that the data model can present core information from multi-modal medical images and enable to diagnose through the united view of AMI intuitively.','10.3745/JIPS.04.0021',38,21,0,70,'2015-12-11',NULL),(80070,0,0,0,0,0,'Speech Query Recognition for Tamil Language Using Wavelet and Wavelet Packets','De-noising, Feature Extraction, Speech Recognition, Support Vector Machine, Wavelet Packet','P. Iswarya and V. Radha','dlibrary/JIPS_OF_paper71.pdf','Speech recognition is one of the fascinating fields in the area of Computer science. Accuracy of speech recognition system may reduce due to the presence of noise present in speech signal. Therefore noise removal is an essential step in Automatic Speech Recognition (ASR) system and this paper proposes a new technique called combined thresholding for noise removal. Feature extraction is process of converting acoustic signal into most valuable set of parameters. This paper also concentrates on improving Mel Frequency Cepstral Coefficients (MFCC) features by introducing Discrete Wavelet Packet Transform (DWPT) in the place of Discrete Fourier Transformation (DFT) block to provide an efficient signal analysis. The feature vector is varied in size, for choosing the correct length of feature vector Self Organizing Map (SOM) is used. As a single classifier does not provide enough accuracy, so this research proposes an Ensemble Support Vector Machine (ESVM) classifier where the fixed length feature vector from SOM is given as input, termed as ESVM_SOM. The experimental results showed that the proposed methods provide better results than the existing methods.','10.3745/JIPS.02.0033',12,7,0,71,'2015-12-17',NULL),(80071,0,0,0,0,0,'Boosting the Reasoning-Based Approach by Applying Structural Metrics for Ontology Alignment','Description Logics Inference, Intra-Taxonomy Measures, Ontology Alignment, Semantic Interoperability, Semantic Web, Structural Similarity','Abderrahmane Khiat and Moussa Benaissa','dlibrary/JIPS_OF_paper72.pdf','The amount of sources of information available on the web using ontologies as support continues to increase and is often heterogeneous and distributed. Ontology alignment is the solution to ensure semantic inter- operability. In this paper, we describe a new ontology alignment approach, which consists of combining structure-based and reasoning-based approaches in order to discover new semantic correspondences between entities of different ontologies. We used the biblio test of the benchmark series and anatomy series of the Ontology Alignment Evaluation Initiative (OAEI) 2012 evaluation campaign to evaluate the performance of our approach. We compared our approach successively with LogMap and YAM++ systems. We also analyzed the contribution of our method compared to structural and semantic methods. The results obtained show that our performance provides good performance. Indeed, these results are better than those of the LogMap system in terms of precision, recall, and F-measure. Our approach has also been proven to be more relevant than YAM++ for certain types of ontologies and significantly improves the structure-based and reasoning- based methods.','10.3745/JIPS.02.0034',20,7,0,72,'2015-12-17',NULL),(80072,0,0,0,0,0,'Event Detection on Motion Activities Using a Dynamic Grid','Dynamic Grid Feature, Event Detection, Event Patterns, Pedestrian Activities','Jitdumrong Preechasuk and Punpiti Piamsa-nga','dlibrary/JIPS_OF_paper73.pdf','Event detection based on using features from a static grid can give poor results from the viewpoint of two main aspects: the position of the camera and the position of the event that is occurring in the scene. The former causes problems when training and test events are at different distances from the camera to the actual position of the event. The latter can be a source of problems when training events take place in any position in the scene, and the test events take place in a position different from the training events. Both issues degrade the accuracy of the static grid method. Therefore, this work proposes a method called a dynamic grid for event detection, which can tackle both aspects of the problem. In our experiment, we used the dynamic grid method to detect four types of event patterns: implosion, explosion, two-way, and one-way using a Multimedia Analysis and Discovery (MAD) pedestrian dataset. The experimental results show that the proposed method can detect the four types of event patterns with high accuracy. Additionally, the performance of the proposed method is better than the static grid method and the proposed method achieves higher accuracy than the previous method regarding the aforementioned aspects.','10.3745/JIPS.02.0035',19,11,0,73,'2015-12-17',NULL),(80073,0,0,0,0,0,'Data Hiding Algorithm for Images Using Discrete Wavelet Transform and Arnold Transform','Arnold Transform, DWT, JPEG, JPEG2000, PSNR, SIM','Geeta Kasana, Kulbir Singh, and Satvinder Singh Bhatia','dlibrary/JIPS_OF_paper74.pdf','In this paper, data hiding algorithm using Discrete Wavelet Transform (DWT) and Arnold Transform is proposed. The secret data is scrambled using Arnold Transform to make it secure. Wavelet subbands of a cover image are obtained using DWT. The scrambled secret data is embedded into significant wavelet coefficients of subbands of a cover image. The proposed algorithm is robust to a variety of attacks like JPEG and JPEG2000 compression, image cropping and median filtering. Experimental results show that the PSNR of the composite image is 1.05 dB higher than the PSNR of existing algorithms and capacity is 25% higher than the capacity of existing algorithms.','10.3745/JIPS.03.0042',1,1,0,74,'2015-12-17',NULL),(80074,0,0,0,0,0,'Uniform Fractional Band CAC Scheme for QoS Provisioning in Wireless Networks','Acceptance Factor, Call Admission Control (CAC), Call Blocking Probability (CBP), Call Dropping Probability (CDP), Channel Utilization, Uniform Fractional Band (UFB), Quality of Service (QoS)','Md. Asadur Rahman, Mostafa Zaman Chowdhury, and Yeong Min Jang','dlibrary/JIPS_OF_paper75.pdf','Generally, the wireless network provides priority to handover calls instead of new calls to maintain its quality of service (QoS). Because of this QoS provisioning, a call admission control (CAC) scheme is essential for the suitable management of limited radio resources of wireless networks to uphold different factors, such as new call blocking probability, handover call dropping probability, channel utilization, etc. Designing an optimal CAC scheme is still a challenging task due to having a number of considerable factors, such as new call blocking probability, handover call dropping probability, channel utilization, traffic rate, etc. Among existing CAC schemes such as, fixed guard band (FGB), fractional guard channel (FGC), limited fractional channel (LFC), and Uniform Fractional Channel (UFC), the LFC scheme is optimal considering the new call blocking and handover call dropping probability. However, this scheme does not consider channel utilization. In this paper, a CAC scheme, which is termed by a uniform fractional band (UFB) to overcome the limitations of existing schemes, is proposed. This scheme is oriented by priority and non-priority guard channels with a set of fractional channels instead of fractionizing the total channels like FGC and UFC schemes. These fractional channels in the UFB scheme accept new calls with a predefined uniform acceptance factor and assist the network in utilizing more channels. The mathematical models, operational benefits, and the limitations of existing CAC schemes are also discussed. Subsequently, we prepared a comparative study between the existing and proposed scheme in terms of the aforementioned QoS related factors. The numerical results we have obtained so far show that the proposed UFB scheme is an optimal CAC scheme in terms of QoS and resource utilization as compared to the existing schemes.','10.3745/JIPS.03.0043',1,1,0,75,'2015-12-17',NULL);
/*!40000 ALTER TABLE `jipsdb` ENABLE KEYS */;
UNLOCK TABLES;
/*!40103 SET TIME_ZONE=@OLD_TIME_ZONE */;

/*!40101 SET SQL_MODE=@OLD_SQL_MODE */;
/*!40014 SET FOREIGN_KEY_CHECKS=@OLD_FOREIGN_KEY_CHECKS */;
/*!40014 SET UNIQUE_CHECKS=@OLD_UNIQUE_CHECKS */;
/*!40101 SET CHARACTER_SET_CLIENT=@OLD_CHARACTER_SET_CLIENT */;
/*!40101 SET CHARACTER_SET_RESULTS=@OLD_CHARACTER_SET_RESULTS */;
/*!40101 SET COLLATION_CONNECTION=@OLD_COLLATION_CONNECTION */;
/*!40111 SET SQL_NOTES=@OLD_SQL_NOTES */;

-- Dump completed on 2015-12-21 22:12:57
